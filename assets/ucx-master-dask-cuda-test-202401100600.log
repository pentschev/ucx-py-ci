============================= test session starts ==============================
platform linux -- Python 3.9.18, pytest-7.4.4, pluggy-1.3.0 -- /opt/conda/envs/gdf/bin/python3.9
cachedir: .pytest_cache
rootdir: /usr/src/dask-cuda
configfile: pyproject.toml
plugins: asyncio-0.23.3
asyncio: mode=strict
collecting ... collected 1246 items

dask_cuda/tests/test_cudf_builtin_spilling.py::test_is_spillable_object_when_cudf_spilling_disabled PASSED
dask_cuda/tests/test_cudf_builtin_spilling.py::test_is_spillable_object_when_cudf_spilling_enabled PASSED
dask_cuda/tests/test_cudf_builtin_spilling.py::test_device_host_file_when_cudf_spilling_is_disabled PASSED
dask_cuda/tests/test_cudf_builtin_spilling.py::test_device_host_file_step_by_step PASSED
dask_cuda/tests/test_cudf_builtin_spilling.py::test_proxify_host_file PASSED
dask_cuda/tests/test_dask_cuda_worker.py::test_cuda_visible_devices_and_memory_limit_and_nthreads 2024-01-10 06:34:34,940 - distributed.scheduler - INFO - -----------------------------------------------
2024-01-10 06:34:34,945 - distributed.http.proxy - INFO - To route to workers diagnostics web server please install jupyter-server-proxy: python -m pip install jupyter-server-proxy
/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 34429 instead
  warnings.warn(
2024-01-10 06:34:34,948 - distributed.scheduler - INFO - State start
2024-01-10 06:34:34,971 - distributed.scheduler - INFO - -----------------------------------------------
2024-01-10 06:34:34,972 - distributed.scheduler - INFO -   Scheduler at:  tcp://10.33.227.163:9359
2024-01-10 06:34:34,973 - distributed.scheduler - INFO -   dashboard at:  http://10.33.227.163:34429/status
2024-01-10 06:34:34,973 - distributed.scheduler - INFO - Registering Worker plugin shuffle
2024-01-10 06:34:35,137 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:45097'
2024-01-10 06:34:35,160 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:35979'
2024-01-10 06:34:35,163 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:38381'
2024-01-10 06:34:35,171 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:36513'
2024-01-10 06:34:37,016 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2024-01-10 06:34:37,016 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2024-01-10 06:34:37,020 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2024-01-10 06:34:37,021 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:42271
2024-01-10 06:34:37,021 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:42271
2024-01-10 06:34:37,021 - distributed.worker - INFO -          dashboard at:            127.0.0.1:40241
2024-01-10 06:34:37,021 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9359
2024-01-10 06:34:37,021 - distributed.worker - INFO - -------------------------------------------------
2024-01-10 06:34:37,021 - distributed.worker - INFO -               Threads:                          4
2024-01-10 06:34:37,021 - distributed.worker - INFO -                Memory:                 251.94 GiB
2024-01-10 06:34:37,021 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/mockworker-q3d5er0l
2024-01-10 06:34:37,021 - distributed.worker - INFO - Starting Worker plugin RMMSetup-ff08feca-ec6e-4076-8446-0a7c2452a71a
2024-01-10 06:34:37,022 - distributed.worker - INFO - Starting Worker plugin PreImport-965afde3-f838-4f60-b8d0-f7285523bde5
2024-01-10 06:34:37,022 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-e8ccf879-4a9e-4c57-882d-e57190f7b176
2024-01-10 06:34:37,022 - distributed.worker - INFO - -------------------------------------------------
2024-01-10 06:34:37,030 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2024-01-10 06:34:37,030 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2024-01-10 06:34:37,030 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2024-01-10 06:34:37,030 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2024-01-10 06:34:37,034 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2024-01-10 06:34:37,034 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2024-01-10 06:34:37,035 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:41007
2024-01-10 06:34:37,035 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:44435
2024-01-10 06:34:37,035 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:41007
2024-01-10 06:34:37,035 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:44435
2024-01-10 06:34:37,035 - distributed.worker - INFO -          dashboard at:            127.0.0.1:37099
2024-01-10 06:34:37,035 - distributed.worker - INFO -          dashboard at:            127.0.0.1:35055
2024-01-10 06:34:37,035 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9359
2024-01-10 06:34:37,035 - distributed.worker - INFO - -------------------------------------------------
2024-01-10 06:34:37,035 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9359
2024-01-10 06:34:37,035 - distributed.worker - INFO -               Threads:                          4
2024-01-10 06:34:37,035 - distributed.worker - INFO - -------------------------------------------------
2024-01-10 06:34:37,035 - distributed.worker - INFO -                Memory:                 251.94 GiB
2024-01-10 06:34:37,035 - distributed.worker - INFO -               Threads:                          4
2024-01-10 06:34:37,035 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/mockworker-xdwhsea0
2024-01-10 06:34:37,035 - distributed.worker - INFO -                Memory:                 251.94 GiB
2024-01-10 06:34:37,035 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/mockworker-_nc0umwh
2024-01-10 06:34:37,035 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2024-01-10 06:34:37,035 - distributed.worker - INFO - Starting Worker plugin PreImport-ab2c2b6c-8f44-409a-be7d-e42f647ba373
2024-01-10 06:34:37,035 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2024-01-10 06:34:37,035 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-fca846cb-ddee-44fd-b087-3dae73f975a0
2024-01-10 06:34:37,035 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-85019722-4cf4-4826-bb4b-7577fbef30e0
2024-01-10 06:34:37,036 - distributed.worker - INFO - Starting Worker plugin PreImport-5cffe79c-279d-4b80-846e-da859d499b43
2024-01-10 06:34:37,036 - distributed.worker - INFO - Starting Worker plugin RMMSetup-7972fae1-d1c7-4082-8e1f-d93b3bc0a137
2024-01-10 06:34:37,036 - distributed.worker - INFO - -------------------------------------------------
2024-01-10 06:34:37,039 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2024-01-10 06:34:37,039 - distributed.worker - INFO - Starting Worker plugin RMMSetup-1f62b2d0-9dde-42bd-a0ae-e293a5a81104
2024-01-10 06:34:37,040 - distributed.worker - INFO - -------------------------------------------------
2024-01-10 06:34:37,040 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:40101
2024-01-10 06:34:37,040 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:40101
2024-01-10 06:34:37,040 - distributed.worker - INFO -          dashboard at:            127.0.0.1:46199
2024-01-10 06:34:37,040 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9359
2024-01-10 06:34:37,040 - distributed.worker - INFO - -------------------------------------------------
2024-01-10 06:34:37,040 - distributed.worker - INFO -               Threads:                          4
2024-01-10 06:34:37,040 - distributed.worker - INFO -                Memory:                 251.94 GiB
2024-01-10 06:34:37,041 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/mockworker-bz07zax5
2024-01-10 06:34:37,041 - distributed.worker - INFO - Starting Worker plugin RMMSetup-5e775580-8c81-4ed5-8f46-2eb2ab7c5cd8
2024-01-10 06:34:37,041 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-442b85c1-25b9-41c9-ac67-6c146593cbd2
2024-01-10 06:34:37,041 - distributed.worker - INFO - Starting Worker plugin PreImport-d2fb568c-8b73-4428-948e-158c83e002af
2024-01-10 06:34:37,041 - distributed.worker - INFO - -------------------------------------------------
2024-01-10 06:34:37,103 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:42271', status: init, memory: 0, processing: 0>
2024-01-10 06:34:37,116 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:42271
2024-01-10 06:34:37,116 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:50554
2024-01-10 06:34:37,117 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-01-10 06:34:37,118 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9359
2024-01-10 06:34:37,118 - distributed.worker - INFO - -------------------------------------------------
2024-01-10 06:34:37,119 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9359
2024-01-10 06:34:37,170 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:40101', status: init, memory: 0, processing: 0>
2024-01-10 06:34:37,171 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:40101
2024-01-10 06:34:37,171 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:50588
2024-01-10 06:34:37,172 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-01-10 06:34:37,172 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:44435', status: init, memory: 0, processing: 0>
2024-01-10 06:34:37,172 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:44435
2024-01-10 06:34:37,172 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:50568
2024-01-10 06:34:37,172 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9359
2024-01-10 06:34:37,173 - distributed.worker - INFO - -------------------------------------------------
2024-01-10 06:34:37,173 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-01-10 06:34:37,174 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9359
2024-01-10 06:34:37,174 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9359
2024-01-10 06:34:37,174 - distributed.worker - INFO - -------------------------------------------------
2024-01-10 06:34:37,174 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:41007', status: init, memory: 0, processing: 0>
2024-01-10 06:34:37,175 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:41007
2024-01-10 06:34:37,175 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:50574
2024-01-10 06:34:37,175 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9359
2024-01-10 06:34:37,176 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-01-10 06:34:37,177 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9359
2024-01-10 06:34:37,177 - distributed.worker - INFO - -------------------------------------------------
2024-01-10 06:34:37,178 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9359
2024-01-10 06:34:38,666 - distributed.scheduler - INFO - Receive client connection: Client-50c38e9a-af82-11ee-9743-d8c49764f6bb
2024-01-10 06:34:38,667 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:50640
2024-01-10 06:34:38,680 - distributed.worker - INFO - Run out-of-band function 'get_visible_devices'
2024-01-10 06:34:38,680 - distributed.worker - INFO - Run out-of-band function 'get_visible_devices'
2024-01-10 06:34:38,681 - distributed.worker - INFO - Run out-of-band function 'get_visible_devices'
2024-01-10 06:34:38,706 - distributed.worker - INFO - Run out-of-band function 'get_visible_devices'
2024-01-10 06:34:38,711 - distributed.scheduler - INFO - Remove client Client-50c38e9a-af82-11ee-9743-d8c49764f6bb
2024-01-10 06:34:38,711 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:50640; closing.
2024-01-10 06:34:38,712 - distributed.scheduler - INFO - Remove client Client-50c38e9a-af82-11ee-9743-d8c49764f6bb
2024-01-10 06:34:38,712 - distributed.scheduler - INFO - Close client connection: Client-50c38e9a-af82-11ee-9743-d8c49764f6bb
2024-01-10 06:34:38,713 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:45097'. Reason: nanny-close
2024-01-10 06:34:38,713 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2024-01-10 06:34:38,713 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:35979'. Reason: nanny-close
2024-01-10 06:34:38,714 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2024-01-10 06:34:38,714 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:38381'. Reason: nanny-close
2024-01-10 06:34:38,714 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:41007. Reason: nanny-close
2024-01-10 06:34:38,714 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2024-01-10 06:34:38,714 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:36513'. Reason: nanny-close
2024-01-10 06:34:38,715 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:42271. Reason: nanny-close
2024-01-10 06:34:38,715 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2024-01-10 06:34:38,716 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:40101. Reason: nanny-close
2024-01-10 06:34:38,716 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:44435. Reason: nanny-close
2024-01-10 06:34:38,716 - distributed.core - INFO - Connection to tcp://127.0.0.1:9359 has been closed.
2024-01-10 06:34:38,716 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:50574; closing.
2024-01-10 06:34:38,717 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:41007', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1704868478.7171423')
2024-01-10 06:34:38,717 - distributed.core - INFO - Connection to tcp://127.0.0.1:9359 has been closed.
2024-01-10 06:34:38,718 - distributed.nanny - INFO - Worker closed
2024-01-10 06:34:38,718 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:50554; closing.
2024-01-10 06:34:38,718 - distributed.nanny - INFO - Worker closed
2024-01-10 06:34:38,719 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:50588; closing.
2024-01-10 06:34:38,719 - distributed.core - INFO - Connection to tcp://127.0.0.1:9359 has been closed.
2024-01-10 06:34:38,719 - distributed.core - INFO - Connection to tcp://127.0.0.1:9359 has been closed.
2024-01-10 06:34:38,719 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:42271', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1704868478.7197666')
2024-01-10 06:34:38,720 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:50568; closing.
2024-01-10 06:34:38,720 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:40101', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1704868478.7205205')
2024-01-10 06:34:38,721 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:44435', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1704868478.7209203')
2024-01-10 06:34:38,721 - distributed.scheduler - INFO - Lost all workers
2024-01-10 06:34:38,721 - distributed.nanny - INFO - Worker closed
2024-01-10 06:34:38,721 - distributed.nanny - INFO - Worker closed
2024-01-10 06:34:39,529 - distributed._signals - INFO - Received signal SIGINT (2)
2024-01-10 06:34:39,529 - distributed.scheduler - INFO - Scheduler closing due to signal-2...
2024-01-10 06:34:39,530 - distributed.scheduler - INFO - Scheduler closing all comms
2024-01-10 06:34:39,531 - distributed.scheduler - INFO - Stopped scheduler at 'tcp://10.33.227.163:9359'
2024-01-10 06:34:39,531 - distributed.scheduler - INFO - End scheduler
PASSED
dask_cuda/tests/test_dask_cuda_worker.py::test_rmm_pool 2024-01-10 06:34:41,758 - distributed.scheduler - INFO - -----------------------------------------------
2024-01-10 06:34:41,763 - distributed.http.proxy - INFO - To route to workers diagnostics web server please install jupyter-server-proxy: python -m pip install jupyter-server-proxy
/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 46625 instead
  warnings.warn(
2024-01-10 06:34:41,767 - distributed.scheduler - INFO - State start
2024-01-10 06:34:42,050 - distributed.scheduler - INFO - -----------------------------------------------
2024-01-10 06:34:42,051 - distributed.scheduler - INFO -   Scheduler at:  tcp://10.33.227.163:9369
2024-01-10 06:34:42,052 - distributed.scheduler - INFO -   dashboard at:  http://10.33.227.163:46625/status
2024-01-10 06:34:42,053 - distributed.scheduler - INFO - Registering Worker plugin shuffle
2024-01-10 06:34:42,989 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:45819'
2024-01-10 06:34:43,003 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:42735'
2024-01-10 06:34:43,018 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:35547'
2024-01-10 06:34:43,021 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:36077'
2024-01-10 06:34:43,028 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:33361'
2024-01-10 06:34:43,038 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:37595'
2024-01-10 06:34:43,048 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:33937'
2024-01-10 06:34:43,056 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:35035'
2024-01-10 06:34:44,455 - distributed.scheduler - INFO - Receive client connection: Client-54ddcd09-af82-11ee-9743-d8c49764f6bb
2024-01-10 06:34:44,470 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:46244
2024-01-10 06:34:45,020 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2024-01-10 06:34:45,021 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2024-01-10 06:34:45,021 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2024-01-10 06:34:45,021 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2024-01-10 06:34:45,025 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2024-01-10 06:34:45,026 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2024-01-10 06:34:45,026 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:33727
2024-01-10 06:34:45,026 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:33727
2024-01-10 06:34:45,026 - distributed.worker - INFO -          dashboard at:            127.0.0.1:41483
2024-01-10 06:34:45,026 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2024-01-10 06:34:45,026 - distributed.worker - INFO - -------------------------------------------------
2024-01-10 06:34:45,026 - distributed.worker - INFO -               Threads:                          1
2024-01-10 06:34:45,026 - distributed.worker - INFO -                Memory:                 125.97 GiB
2024-01-10 06:34:45,026 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-44z9ui6c
2024-01-10 06:34:45,027 - distributed.worker - INFO - Starting Worker plugin RMMSetup-2747f053-50ff-40ad-a443-b6539817bdc8
2024-01-10 06:34:45,027 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:33733
2024-01-10 06:34:45,027 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:33733
2024-01-10 06:34:45,027 - distributed.worker - INFO -          dashboard at:            127.0.0.1:39493
2024-01-10 06:34:45,027 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2024-01-10 06:34:45,027 - distributed.worker - INFO - -------------------------------------------------
2024-01-10 06:34:45,027 - distributed.worker - INFO -               Threads:                          1
2024-01-10 06:34:45,027 - distributed.worker - INFO -                Memory:                 125.97 GiB
2024-01-10 06:34:45,027 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-3bsskeeh
2024-01-10 06:34:45,027 - distributed.worker - INFO - Starting Worker plugin RMMSetup-8a54bb0c-bf8b-4a3d-a823-7c42bba5e966
2024-01-10 06:34:45,035 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2024-01-10 06:34:45,036 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2024-01-10 06:34:45,037 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2024-01-10 06:34:45,037 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2024-01-10 06:34:45,038 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2024-01-10 06:34:45,038 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2024-01-10 06:34:45,038 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2024-01-10 06:34:45,038 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2024-01-10 06:34:45,039 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2024-01-10 06:34:45,039 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2024-01-10 06:34:45,040 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2024-01-10 06:34:45,041 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:37065
2024-01-10 06:34:45,041 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:37065
2024-01-10 06:34:45,041 - distributed.worker - INFO -          dashboard at:            127.0.0.1:41347
2024-01-10 06:34:45,041 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2024-01-10 06:34:45,041 - distributed.worker - INFO - -------------------------------------------------
2024-01-10 06:34:45,041 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2024-01-10 06:34:45,041 - distributed.worker - INFO -               Threads:                          1
2024-01-10 06:34:45,041 - distributed.worker - INFO -                Memory:                 125.97 GiB
2024-01-10 06:34:45,041 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-f86p0ijh
2024-01-10 06:34:45,042 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-6b814f2d-f746-41df-8d63-fc27815d85fa
2024-01-10 06:34:45,042 - distributed.worker - INFO - Starting Worker plugin PreImport-1836054d-77d0-4cd9-a893-811dbe4bcb24
2024-01-10 06:34:45,042 - distributed.worker - INFO - Starting Worker plugin RMMSetup-4553635e-8c26-41a3-b47a-997d966f18b7
2024-01-10 06:34:45,042 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:39557
2024-01-10 06:34:45,042 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:39557
2024-01-10 06:34:45,042 - distributed.worker - INFO -          dashboard at:            127.0.0.1:38027
2024-01-10 06:34:45,042 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2024-01-10 06:34:45,042 - distributed.worker - INFO - -------------------------------------------------
2024-01-10 06:34:45,042 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2024-01-10 06:34:45,042 - distributed.worker - INFO -               Threads:                          1
2024-01-10 06:34:45,042 - distributed.worker - INFO -                Memory:                 125.97 GiB
2024-01-10 06:34:45,042 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-wlu3h_u8
2024-01-10 06:34:45,043 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2024-01-10 06:34:45,043 - distributed.worker - INFO - Starting Worker plugin RMMSetup-287c3d68-7b29-466a-98da-08e33893f409
2024-01-10 06:34:45,043 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:37363
2024-01-10 06:34:45,043 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:37363
2024-01-10 06:34:45,043 - distributed.worker - INFO -          dashboard at:            127.0.0.1:45673
2024-01-10 06:34:45,043 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2024-01-10 06:34:45,043 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2024-01-10 06:34:45,043 - distributed.worker - INFO - -------------------------------------------------
2024-01-10 06:34:45,043 - distributed.worker - INFO -               Threads:                          1
2024-01-10 06:34:45,043 - distributed.worker - INFO -                Memory:                 125.97 GiB
2024-01-10 06:34:45,043 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:46809
2024-01-10 06:34:45,043 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-svpvn3ep
2024-01-10 06:34:45,043 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:46809
2024-01-10 06:34:45,044 - distributed.worker - INFO -          dashboard at:            127.0.0.1:33163
2024-01-10 06:34:45,044 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2024-01-10 06:34:45,044 - distributed.worker - INFO - -------------------------------------------------
2024-01-10 06:34:45,044 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-2e405882-8a6d-4875-a391-bfe1c2d6fe70
2024-01-10 06:34:45,044 - distributed.worker - INFO -               Threads:                          1
2024-01-10 06:34:45,044 - distributed.worker - INFO -                Memory:                 125.97 GiB
2024-01-10 06:34:45,044 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-2rbr89i9
2024-01-10 06:34:45,044 - distributed.worker - INFO - Starting Worker plugin PreImport-ef77796a-0ca3-4af2-9834-ab092203faf1
2024-01-10 06:34:45,044 - distributed.worker - INFO - Starting Worker plugin RMMSetup-d535f3e0-9043-4c41-a86b-dab33d5e9d87
2024-01-10 06:34:45,044 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-a7eaba3d-1f86-45c8-a20a-6d3d228ff5b6
2024-01-10 06:34:45,044 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:36551
2024-01-10 06:34:45,044 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:36551
2024-01-10 06:34:45,044 - distributed.worker - INFO -          dashboard at:            127.0.0.1:35745
2024-01-10 06:34:45,044 - distributed.worker - INFO - Starting Worker plugin PreImport-01699519-f4da-4b58-a88b-933d31bc5248
2024-01-10 06:34:45,044 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2024-01-10 06:34:45,044 - distributed.worker - INFO - Starting Worker plugin RMMSetup-b71e22d4-04a5-4187-8e42-183e68accacc
2024-01-10 06:34:45,044 - distributed.worker - INFO - -------------------------------------------------
2024-01-10 06:34:45,044 - distributed.worker - INFO -               Threads:                          1
2024-01-10 06:34:45,044 - distributed.worker - INFO -                Memory:                 125.97 GiB
2024-01-10 06:34:45,044 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-r81s6ke2
2024-01-10 06:34:45,045 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-8563823e-5854-461c-a2c7-f0101a22a497
2024-01-10 06:34:45,045 - distributed.worker - INFO - Starting Worker plugin PreImport-6f6760cc-b048-4ed2-9316-fbe61a19caaa
2024-01-10 06:34:45,045 - distributed.worker - INFO - Starting Worker plugin RMMSetup-9e6464cd-a83c-4dd5-aaa4-639195ef5f91
2024-01-10 06:34:45,291 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2024-01-10 06:34:45,291 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2024-01-10 06:34:45,296 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2024-01-10 06:34:45,297 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:35085
2024-01-10 06:34:45,297 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:35085
2024-01-10 06:34:45,297 - distributed.worker - INFO -          dashboard at:            127.0.0.1:45465
2024-01-10 06:34:45,297 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2024-01-10 06:34:45,297 - distributed.worker - INFO - -------------------------------------------------
2024-01-10 06:34:45,297 - distributed.worker - INFO -               Threads:                          1
2024-01-10 06:34:45,297 - distributed.worker - INFO -                Memory:                 125.97 GiB
2024-01-10 06:34:45,297 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-n8ge4g82
2024-01-10 06:34:45,297 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-3706e661-083d-46a4-ad6e-5ec7a3ca3d08
2024-01-10 06:34:45,297 - distributed.worker - INFO - Starting Worker plugin PreImport-02bc1d0e-9e9a-4dd7-99f4-25470646aedf
2024-01-10 06:34:45,298 - distributed.worker - INFO - Starting Worker plugin RMMSetup-e216440b-f17b-420b-9637-e492d36b7d24
2024-01-10 06:34:47,526 - distributed.worker - INFO - Starting Worker plugin PreImport-78da2ee7-ca89-40ed-995d-6ac565e4cf09
2024-01-10 06:34:47,526 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-576b05b2-68d8-4df0-9007-26332d44c72a
2024-01-10 06:34:47,528 - distributed.worker - INFO - -------------------------------------------------
2024-01-10 06:34:47,546 - distributed.worker - INFO - -------------------------------------------------
2024-01-10 06:34:47,551 - distributed.worker - INFO - -------------------------------------------------
2024-01-10 06:34:47,571 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:33727', status: init, memory: 0, processing: 0>
2024-01-10 06:34:47,573 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:33727
2024-01-10 06:34:47,574 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:46258
2024-01-10 06:34:47,573 - distributed.worker - INFO - -------------------------------------------------
2024-01-10 06:34:47,575 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:37363', status: init, memory: 0, processing: 0>
2024-01-10 06:34:47,575 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:37363
2024-01-10 06:34:47,575 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:46268
2024-01-10 06:34:47,575 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-01-10 06:34:47,576 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-01-10 06:34:47,577 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2024-01-10 06:34:47,577 - distributed.worker - INFO - -------------------------------------------------
2024-01-10 06:34:47,577 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2024-01-10 06:34:47,577 - distributed.worker - INFO - -------------------------------------------------
2024-01-10 06:34:47,579 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2024-01-10 06:34:47,578 - distributed.worker - INFO - -------------------------------------------------
2024-01-10 06:34:47,579 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2024-01-10 06:34:47,582 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:36551', status: init, memory: 0, processing: 0>
2024-01-10 06:34:47,582 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:36551
2024-01-10 06:34:47,582 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:46280
2024-01-10 06:34:47,583 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-01-10 06:34:47,584 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2024-01-10 06:34:47,584 - distributed.worker - INFO - -------------------------------------------------
2024-01-10 06:34:47,586 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2024-01-10 06:34:47,589 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-13fc9354-5088-4758-a2ab-22b5f656d093
2024-01-10 06:34:47,590 - distributed.worker - INFO - Starting Worker plugin PreImport-c28e7b90-3155-47c3-9f6c-badc290fba88
2024-01-10 06:34:47,592 - distributed.worker - INFO - -------------------------------------------------
2024-01-10 06:34:47,595 - distributed.worker - INFO - Starting Worker plugin PreImport-f28b0ff9-795d-4d10-8007-89ee1abf7346
2024-01-10 06:34:47,596 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-475d654b-2633-4eb5-80d3-0d0304304bb4
2024-01-10 06:34:47,598 - distributed.worker - INFO - -------------------------------------------------
2024-01-10 06:34:47,598 - distributed.worker - INFO - -------------------------------------------------
2024-01-10 06:34:47,606 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:46809', status: init, memory: 0, processing: 0>
2024-01-10 06:34:47,606 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:46809
2024-01-10 06:34:47,606 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:46290
2024-01-10 06:34:47,607 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:37065', status: init, memory: 0, processing: 0>
2024-01-10 06:34:47,608 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-01-10 06:34:47,608 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:37065
2024-01-10 06:34:47,608 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:46300
2024-01-10 06:34:47,609 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2024-01-10 06:34:47,609 - distributed.worker - INFO - -------------------------------------------------
2024-01-10 06:34:47,610 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-01-10 06:34:47,611 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2024-01-10 06:34:47,611 - distributed.worker - INFO - -------------------------------------------------
2024-01-10 06:34:47,611 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2024-01-10 06:34:47,612 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2024-01-10 06:34:47,624 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:39557', status: init, memory: 0, processing: 0>
2024-01-10 06:34:47,625 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:39557
2024-01-10 06:34:47,625 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:46314
2024-01-10 06:34:47,626 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-01-10 06:34:47,627 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:35085', status: init, memory: 0, processing: 0>
2024-01-10 06:34:47,627 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2024-01-10 06:34:47,628 - distributed.worker - INFO - -------------------------------------------------
2024-01-10 06:34:47,628 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:35085
2024-01-10 06:34:47,628 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:46328
2024-01-10 06:34:47,629 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-01-10 06:34:47,629 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:33733', status: init, memory: 0, processing: 0>
2024-01-10 06:34:47,629 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2024-01-10 06:34:47,630 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:33733
2024-01-10 06:34:47,630 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:46338
2024-01-10 06:34:47,630 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2024-01-10 06:34:47,630 - distributed.worker - INFO - -------------------------------------------------
2024-01-10 06:34:47,631 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-01-10 06:34:47,632 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2024-01-10 06:34:47,632 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2024-01-10 06:34:47,632 - distributed.worker - INFO - -------------------------------------------------
2024-01-10 06:34:47,633 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2024-01-10 06:34:47,681 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2024-01-10 06:34:47,681 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2024-01-10 06:34:47,682 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2024-01-10 06:34:47,682 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2024-01-10 06:34:47,682 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2024-01-10 06:34:47,682 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2024-01-10 06:34:47,683 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2024-01-10 06:34:47,683 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2024-01-10 06:34:47,687 - distributed.scheduler - INFO - Remove client Client-54ddcd09-af82-11ee-9743-d8c49764f6bb
2024-01-10 06:34:47,688 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:46244; closing.
2024-01-10 06:34:47,688 - distributed.scheduler - INFO - Remove client Client-54ddcd09-af82-11ee-9743-d8c49764f6bb
2024-01-10 06:34:47,688 - distributed.scheduler - INFO - Close client connection: Client-54ddcd09-af82-11ee-9743-d8c49764f6bb
2024-01-10 06:34:47,689 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:45819'. Reason: nanny-close
2024-01-10 06:34:47,690 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2024-01-10 06:34:47,690 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:42735'. Reason: nanny-close
2024-01-10 06:34:47,690 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2024-01-10 06:34:47,691 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:35547'. Reason: nanny-close
2024-01-10 06:34:47,691 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:37065. Reason: nanny-close
2024-01-10 06:34:47,691 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2024-01-10 06:34:47,691 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:36077'. Reason: nanny-close
2024-01-10 06:34:47,691 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:33733. Reason: nanny-close
2024-01-10 06:34:47,691 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2024-01-10 06:34:47,691 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:33361'. Reason: nanny-close
2024-01-10 06:34:47,692 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2024-01-10 06:34:47,692 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:33727. Reason: nanny-close
2024-01-10 06:34:47,692 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:37595'. Reason: nanny-close
2024-01-10 06:34:47,692 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2024-01-10 06:34:47,692 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:46809. Reason: nanny-close
2024-01-10 06:34:47,692 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:33937'. Reason: nanny-close
2024-01-10 06:34:47,692 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:35085. Reason: nanny-close
2024-01-10 06:34:47,692 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2024-01-10 06:34:47,693 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:35035'. Reason: nanny-close
2024-01-10 06:34:47,693 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:37363. Reason: nanny-close
2024-01-10 06:34:47,693 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2024-01-10 06:34:47,693 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:46300; closing.
2024-01-10 06:34:47,693 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2024-01-10 06:34:47,693 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2024-01-10 06:34:47,693 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:37065', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1704868487.6936858')
2024-01-10 06:34:47,693 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:36551. Reason: nanny-close
2024-01-10 06:34:47,694 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:46338; closing.
2024-01-10 06:34:47,694 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:39557. Reason: nanny-close
2024-01-10 06:34:47,694 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2024-01-10 06:34:47,694 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2024-01-10 06:34:47,695 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2024-01-10 06:34:47,695 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2024-01-10 06:34:47,695 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:33733', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1704868487.6951349')
2024-01-10 06:34:47,695 - distributed.nanny - INFO - Worker closed
2024-01-10 06:34:47,695 - distributed.nanny - INFO - Worker closed
2024-01-10 06:34:47,695 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2024-01-10 06:34:47,696 - distributed.nanny - INFO - Worker closed
2024-01-10 06:34:47,696 - distributed.nanny - INFO - Worker closed
2024-01-10 06:34:47,696 - distributed.nanny - INFO - Worker closed
2024-01-10 06:34:47,696 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:46290; closing.
2024-01-10 06:34:47,696 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:46258; closing.
2024-01-10 06:34:47,697 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:46328; closing.
2024-01-10 06:34:47,697 - distributed.nanny - INFO - Worker closed
2024-01-10 06:34:47,697 - distributed.nanny - INFO - Worker closed
2024-01-10 06:34:47,697 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2024-01-10 06:34:47,697 - distributed.batched - INFO - Batched Comm Closed <TCP (closed) Scheduler connection to worker local=tcp://127.0.0.1:9369 remote=tcp://127.0.0.1:46338>
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/batched.py", line 115, in _background_send
    nbytes = yield coro
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/tornado/gen.py", line 767, in run
    value = future.result()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/tcp.py", line 263, in write
    raise CommClosedError()
distributed.comm.core.CommClosedError
2024-01-10 06:34:47,699 - distributed.nanny - INFO - Worker closed
2024-01-10 06:34:47,700 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:46809', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1704868487.6999948')
2024-01-10 06:34:47,700 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:33727', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1704868487.7003589')
2024-01-10 06:34:47,700 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:35085', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1704868487.7007143')
2024-01-10 06:34:47,701 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:46268; closing.
2024-01-10 06:34:47,701 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:46280; closing.
2024-01-10 06:34:47,701 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:37363', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1704868487.7017708')
2024-01-10 06:34:47,702 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:36551', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1704868487.7021458')
2024-01-10 06:34:47,702 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:46314; closing.
2024-01-10 06:34:47,702 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:39557', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1704868487.7028878')
2024-01-10 06:34:47,703 - distributed.scheduler - INFO - Lost all workers
2024-01-10 06:34:48,655 - distributed._signals - INFO - Received signal SIGINT (2)
2024-01-10 06:34:48,656 - distributed.scheduler - INFO - Scheduler closing due to signal-2...
2024-01-10 06:34:48,657 - distributed.scheduler - INFO - Scheduler closing all comms
2024-01-10 06:34:48,658 - distributed.scheduler - INFO - Stopped scheduler at 'tcp://10.33.227.163:9369'
2024-01-10 06:34:48,659 - distributed.scheduler - INFO - End scheduler
PASSED
dask_cuda/tests/test_dask_cuda_worker.py::test_rmm_managed 2024-01-10 06:34:51,018 - distributed.scheduler - INFO - -----------------------------------------------
2024-01-10 06:34:51,023 - distributed.http.proxy - INFO - To route to workers diagnostics web server please install jupyter-server-proxy: python -m pip install jupyter-server-proxy
/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 41667 instead
  warnings.warn(
2024-01-10 06:34:51,027 - distributed.scheduler - INFO - State start
2024-01-10 06:34:51,052 - distributed.scheduler - INFO - -----------------------------------------------
2024-01-10 06:34:51,053 - distributed.scheduler - INFO -   Scheduler at:  tcp://10.33.227.163:9369
2024-01-10 06:34:51,054 - distributed.scheduler - INFO -   dashboard at:  http://10.33.227.163:41667/status
2024-01-10 06:34:51,054 - distributed.scheduler - INFO - Registering Worker plugin shuffle
2024-01-10 06:34:51,154 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:42809'
2024-01-10 06:34:51,162 - distributed.scheduler - INFO - Receive client connection: Client-5a59e3cc-af82-11ee-9743-d8c49764f6bb
2024-01-10 06:34:51,171 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:34825'
2024-01-10 06:34:51,180 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:45158
2024-01-10 06:34:51,187 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:46805'
2024-01-10 06:34:51,190 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:37763'
2024-01-10 06:34:51,198 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:40157'
2024-01-10 06:34:51,208 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:36191'
2024-01-10 06:34:51,219 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:33793'
2024-01-10 06:34:51,228 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:34877'
2024-01-10 06:34:53,071 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2024-01-10 06:34:53,071 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2024-01-10 06:34:53,075 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2024-01-10 06:34:53,076 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:42367
2024-01-10 06:34:53,076 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:42367
2024-01-10 06:34:53,076 - distributed.worker - INFO -          dashboard at:            127.0.0.1:39619
2024-01-10 06:34:53,077 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2024-01-10 06:34:53,077 - distributed.worker - INFO - -------------------------------------------------
2024-01-10 06:34:53,077 - distributed.worker - INFO -               Threads:                          1
2024-01-10 06:34:53,077 - distributed.worker - INFO -                Memory:                 125.97 GiB
2024-01-10 06:34:53,077 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-l4b4ex04
2024-01-10 06:34:53,077 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-aec0d9b1-ed6e-4efc-a60b-5863a5f86254
2024-01-10 06:34:53,077 - distributed.worker - INFO - Starting Worker plugin PreImport-416c4a62-6b78-4df0-982a-cddc8c64cc97
2024-01-10 06:34:53,077 - distributed.worker - INFO - Starting Worker plugin RMMSetup-6884a377-1fe2-4421-a302-e484989e5cfb
2024-01-10 06:34:53,082 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2024-01-10 06:34:53,082 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2024-01-10 06:34:53,086 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2024-01-10 06:34:53,087 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:35059
2024-01-10 06:34:53,087 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:35059
2024-01-10 06:34:53,087 - distributed.worker - INFO -          dashboard at:            127.0.0.1:45597
2024-01-10 06:34:53,087 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2024-01-10 06:34:53,087 - distributed.worker - INFO - -------------------------------------------------
2024-01-10 06:34:53,087 - distributed.worker - INFO -               Threads:                          1
2024-01-10 06:34:53,087 - distributed.worker - INFO -                Memory:                 125.97 GiB
2024-01-10 06:34:53,087 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-c299d1in
2024-01-10 06:34:53,088 - distributed.worker - INFO - Starting Worker plugin RMMSetup-049c794b-bcd9-453a-8478-58f0723b3084
2024-01-10 06:34:53,089 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2024-01-10 06:34:53,089 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2024-01-10 06:34:53,093 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2024-01-10 06:34:53,094 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:35283
2024-01-10 06:34:53,094 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:35283
2024-01-10 06:34:53,094 - distributed.worker - INFO -          dashboard at:            127.0.0.1:44807
2024-01-10 06:34:53,094 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2024-01-10 06:34:53,094 - distributed.worker - INFO - -------------------------------------------------
2024-01-10 06:34:53,094 - distributed.worker - INFO -               Threads:                          1
2024-01-10 06:34:53,094 - distributed.worker - INFO -                Memory:                 125.97 GiB
2024-01-10 06:34:53,094 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-r38y9fk4
2024-01-10 06:34:53,095 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-e4146a4a-cfd7-4f75-8284-e515819145be
2024-01-10 06:34:53,095 - distributed.worker - INFO - Starting Worker plugin PreImport-6b82d598-efb5-4695-975f-3fa741d1a062
2024-01-10 06:34:53,095 - distributed.worker - INFO - Starting Worker plugin RMMSetup-ba318d81-a999-40e0-b75f-1460caf97109
2024-01-10 06:34:53,098 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2024-01-10 06:34:53,098 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2024-01-10 06:34:53,102 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2024-01-10 06:34:53,103 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:37769
2024-01-10 06:34:53,103 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:37769
2024-01-10 06:34:53,103 - distributed.worker - INFO -          dashboard at:            127.0.0.1:38727
2024-01-10 06:34:53,103 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2024-01-10 06:34:53,103 - distributed.worker - INFO - -------------------------------------------------
2024-01-10 06:34:53,103 - distributed.worker - INFO -               Threads:                          1
2024-01-10 06:34:53,103 - distributed.worker - INFO -                Memory:                 125.97 GiB
2024-01-10 06:34:53,103 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-w5fk4vle
2024-01-10 06:34:53,103 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-db40271c-348c-4160-97b6-5d126c6e9a56
2024-01-10 06:34:53,104 - distributed.worker - INFO - Starting Worker plugin PreImport-a0a9b919-b021-40da-9f88-e15c94edc3f3
2024-01-10 06:34:53,104 - distributed.worker - INFO - Starting Worker plugin RMMSetup-c345f7c6-941b-4a2e-a3c4-8cad27cecaba
2024-01-10 06:34:53,109 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2024-01-10 06:34:53,109 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2024-01-10 06:34:53,113 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2024-01-10 06:34:53,114 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:34061
2024-01-10 06:34:53,114 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:34061
2024-01-10 06:34:53,114 - distributed.worker - INFO -          dashboard at:            127.0.0.1:45239
2024-01-10 06:34:53,115 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2024-01-10 06:34:53,115 - distributed.worker - INFO - -------------------------------------------------
2024-01-10 06:34:53,115 - distributed.worker - INFO -               Threads:                          1
2024-01-10 06:34:53,115 - distributed.worker - INFO -                Memory:                 125.97 GiB
2024-01-10 06:34:53,115 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-fkxoxghi
2024-01-10 06:34:53,115 - distributed.worker - INFO - Starting Worker plugin RMMSetup-b0defc81-3e8c-45a7-ab85-dcc97b960bd1
2024-01-10 06:34:53,116 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2024-01-10 06:34:53,116 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2024-01-10 06:34:53,118 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2024-01-10 06:34:53,118 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2024-01-10 06:34:53,122 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2024-01-10 06:34:53,123 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:42999
2024-01-10 06:34:53,123 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:42999
2024-01-10 06:34:53,123 - distributed.worker - INFO -          dashboard at:            127.0.0.1:43291
2024-01-10 06:34:53,124 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2024-01-10 06:34:53,124 - distributed.worker - INFO - -------------------------------------------------
2024-01-10 06:34:53,124 - distributed.worker - INFO -               Threads:                          1
2024-01-10 06:34:53,124 - distributed.worker - INFO -                Memory:                 125.97 GiB
2024-01-10 06:34:53,124 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-z1o5xnwf
2024-01-10 06:34:53,124 - distributed.worker - INFO - Starting Worker plugin RMMSetup-23deb0ed-4b35-4623-aa40-c3e8c4f7bbb8
2024-01-10 06:34:53,125 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2024-01-10 06:34:53,126 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:38615
2024-01-10 06:34:53,126 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:38615
2024-01-10 06:34:53,126 - distributed.worker - INFO -          dashboard at:            127.0.0.1:42971
2024-01-10 06:34:53,126 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2024-01-10 06:34:53,126 - distributed.worker - INFO - -------------------------------------------------
2024-01-10 06:34:53,126 - distributed.worker - INFO -               Threads:                          1
2024-01-10 06:34:53,126 - distributed.worker - INFO -                Memory:                 125.97 GiB
2024-01-10 06:34:53,126 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-52p0xcwi
2024-01-10 06:34:53,127 - distributed.worker - INFO - Starting Worker plugin RMMSetup-ed54ca19-92c0-4f82-a619-c8e19acf62d1
2024-01-10 06:34:53,376 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2024-01-10 06:34:53,376 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2024-01-10 06:34:53,381 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2024-01-10 06:34:53,382 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:38207
2024-01-10 06:34:53,382 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:38207
2024-01-10 06:34:53,382 - distributed.worker - INFO -          dashboard at:            127.0.0.1:44289
2024-01-10 06:34:53,382 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2024-01-10 06:34:53,382 - distributed.worker - INFO - -------------------------------------------------
2024-01-10 06:34:53,382 - distributed.worker - INFO -               Threads:                          1
2024-01-10 06:34:53,382 - distributed.worker - INFO -                Memory:                 125.97 GiB
2024-01-10 06:34:53,382 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-zy0f5900
2024-01-10 06:34:53,383 - distributed.worker - INFO - Starting Worker plugin RMMSetup-14d532fb-dd56-49db-9ab6-6b0faeb2af36
2024-01-10 06:34:57,116 - distributed.worker - INFO - -------------------------------------------------
2024-01-10 06:34:57,120 - distributed.worker - INFO - -------------------------------------------------
2024-01-10 06:34:57,134 - distributed.worker - INFO - Starting Worker plugin PreImport-d03a2e91-7f37-4312-a936-629b4082fb5f
2024-01-10 06:34:57,135 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-9cf88f84-cf64-49d1-86f0-6363e55e693f
2024-01-10 06:34:57,135 - distributed.worker - INFO - -------------------------------------------------
2024-01-10 06:34:57,137 - distributed.worker - INFO - Starting Worker plugin PreImport-074b6103-a0af-4547-966e-4be12d400e74
2024-01-10 06:34:57,138 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-39d74340-2735-4623-80da-53fdf446f4bb
2024-01-10 06:34:57,139 - distributed.worker - INFO - -------------------------------------------------
2024-01-10 06:34:57,144 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:35283', status: init, memory: 0, processing: 0>
2024-01-10 06:34:57,147 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:35283
2024-01-10 06:34:57,147 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:45178
2024-01-10 06:34:57,148 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-01-10 06:34:57,148 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2024-01-10 06:34:57,148 - distributed.worker - INFO - -------------------------------------------------
2024-01-10 06:34:57,150 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2024-01-10 06:34:57,155 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:37769', status: init, memory: 0, processing: 0>
2024-01-10 06:34:57,155 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:37769
2024-01-10 06:34:57,155 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:45186
2024-01-10 06:34:57,157 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-01-10 06:34:57,158 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:38615', status: init, memory: 0, processing: 0>
2024-01-10 06:34:57,159 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2024-01-10 06:34:57,159 - distributed.worker - INFO - -------------------------------------------------
2024-01-10 06:34:57,159 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:38615
2024-01-10 06:34:57,159 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:45200
2024-01-10 06:34:57,160 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-01-10 06:34:57,161 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2024-01-10 06:34:57,161 - distributed.worker - INFO - -------------------------------------------------
2024-01-10 06:34:57,161 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2024-01-10 06:34:57,162 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2024-01-10 06:34:57,176 - distributed.worker - INFO - -------------------------------------------------
2024-01-10 06:34:57,177 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:38207', status: init, memory: 0, processing: 0>
2024-01-10 06:34:57,177 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:38207
2024-01-10 06:34:57,178 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:45214
2024-01-10 06:34:57,179 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-01-10 06:34:57,181 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2024-01-10 06:34:57,181 - distributed.worker - INFO - -------------------------------------------------
2024-01-10 06:34:57,183 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2024-01-10 06:34:57,197 - distributed.worker - INFO - Starting Worker plugin PreImport-a4ad82ac-027f-4149-a9da-ef9e17fdf2c1
2024-01-10 06:34:57,197 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-5c770ba3-885a-432b-904a-54ffc3f0b473
2024-01-10 06:34:57,198 - distributed.worker - INFO - -------------------------------------------------
2024-01-10 06:34:57,201 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:42367', status: init, memory: 0, processing: 0>
2024-01-10 06:34:57,202 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:42367
2024-01-10 06:34:57,202 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:45220
2024-01-10 06:34:57,203 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-01-10 06:34:57,204 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2024-01-10 06:34:57,204 - distributed.worker - INFO - -------------------------------------------------
2024-01-10 06:34:57,205 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2024-01-10 06:34:57,230 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:34061', status: init, memory: 0, processing: 0>
2024-01-10 06:34:57,230 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:34061
2024-01-10 06:34:57,230 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:45236
2024-01-10 06:34:57,233 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-01-10 06:34:57,234 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2024-01-10 06:34:57,234 - distributed.worker - INFO - -------------------------------------------------
2024-01-10 06:34:57,236 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2024-01-10 06:34:57,267 - distributed.worker - INFO - Starting Worker plugin PreImport-10cbafd5-a0a1-480a-90b9-ee37e56dc09d
2024-01-10 06:34:57,268 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-010bba0d-1744-4203-8d34-24eed0471db8
2024-01-10 06:34:57,269 - distributed.worker - INFO - -------------------------------------------------
2024-01-10 06:34:57,292 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-8373779f-1780-48aa-829c-97c07c8f9294
2024-01-10 06:34:57,293 - distributed.worker - INFO - Starting Worker plugin PreImport-6033290d-d543-43c7-aaa7-afec4342a8de
2024-01-10 06:34:57,293 - distributed.worker - INFO - -------------------------------------------------
2024-01-10 06:34:57,304 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:42999', status: init, memory: 0, processing: 0>
2024-01-10 06:34:57,305 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:42999
2024-01-10 06:34:57,305 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:45250
2024-01-10 06:34:57,306 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-01-10 06:34:57,308 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2024-01-10 06:34:57,308 - distributed.worker - INFO - -------------------------------------------------
2024-01-10 06:34:57,310 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2024-01-10 06:34:57,316 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:35059', status: init, memory: 0, processing: 0>
2024-01-10 06:34:57,316 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:35059
2024-01-10 06:34:57,316 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:45266
2024-01-10 06:34:57,317 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-01-10 06:34:57,318 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2024-01-10 06:34:57,318 - distributed.worker - INFO - -------------------------------------------------
2024-01-10 06:34:57,319 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2024-01-10 06:34:57,396 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2024-01-10 06:34:57,396 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2024-01-10 06:34:57,396 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2024-01-10 06:34:57,396 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2024-01-10 06:34:57,396 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2024-01-10 06:34:57,397 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2024-01-10 06:34:57,397 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2024-01-10 06:34:57,397 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2024-01-10 06:34:57,402 - distributed.scheduler - INFO - Remove client Client-5a59e3cc-af82-11ee-9743-d8c49764f6bb
2024-01-10 06:34:57,402 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:45158; closing.
2024-01-10 06:34:57,402 - distributed.scheduler - INFO - Remove client Client-5a59e3cc-af82-11ee-9743-d8c49764f6bb
2024-01-10 06:34:57,403 - distributed.scheduler - INFO - Close client connection: Client-5a59e3cc-af82-11ee-9743-d8c49764f6bb
2024-01-10 06:34:57,404 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:42809'. Reason: nanny-close
2024-01-10 06:34:57,404 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2024-01-10 06:34:57,404 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:34825'. Reason: nanny-close
2024-01-10 06:34:57,405 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2024-01-10 06:34:57,405 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:46805'. Reason: nanny-close
2024-01-10 06:34:57,405 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:35059. Reason: nanny-close
2024-01-10 06:34:57,405 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2024-01-10 06:34:57,405 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:37763'. Reason: nanny-close
2024-01-10 06:34:57,406 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:42367. Reason: nanny-close
2024-01-10 06:34:57,406 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2024-01-10 06:34:57,406 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:40157'. Reason: nanny-close
2024-01-10 06:34:57,406 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:37769. Reason: nanny-close
2024-01-10 06:34:57,406 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2024-01-10 06:34:57,406 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:36191'. Reason: nanny-close
2024-01-10 06:34:57,407 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2024-01-10 06:34:57,407 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:42999. Reason: nanny-close
2024-01-10 06:34:57,407 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:33793'. Reason: nanny-close
2024-01-10 06:34:57,407 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:38615. Reason: nanny-close
2024-01-10 06:34:57,407 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2024-01-10 06:34:57,407 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:45266; closing.
2024-01-10 06:34:57,407 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2024-01-10 06:34:57,407 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:34877'. Reason: nanny-close
2024-01-10 06:34:57,407 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:35283. Reason: nanny-close
2024-01-10 06:34:57,407 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:35059', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1704868497.4076567')
2024-01-10 06:34:57,407 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2024-01-10 06:34:57,408 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:34061. Reason: nanny-close
2024-01-10 06:34:57,408 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2024-01-10 06:34:57,408 - distributed.nanny - INFO - Worker closed
2024-01-10 06:34:57,408 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:38207. Reason: nanny-close
2024-01-10 06:34:57,408 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2024-01-10 06:34:57,409 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2024-01-10 06:34:57,409 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2024-01-10 06:34:57,410 - distributed.nanny - INFO - Worker closed
2024-01-10 06:34:57,410 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:45186; closing.
2024-01-10 06:34:57,410 - distributed.nanny - INFO - Worker closed
2024-01-10 06:34:57,410 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:45200; closing.
2024-01-10 06:34:57,410 - distributed.nanny - INFO - Worker closed
2024-01-10 06:34:57,410 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:45220; closing.
2024-01-10 06:34:57,410 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2024-01-10 06:34:57,411 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2024-01-10 06:34:57,411 - distributed.nanny - INFO - Worker closed
2024-01-10 06:34:57,411 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2024-01-10 06:34:57,411 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:37769', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1704868497.4113276')
2024-01-10 06:34:57,411 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:38615', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1704868497.4117036')
2024-01-10 06:34:57,412 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:42367', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1704868497.4120705')
2024-01-10 06:34:57,412 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:45178; closing.
2024-01-10 06:34:57,412 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:45250; closing.
2024-01-10 06:34:57,412 - distributed.nanny - INFO - Worker closed
2024-01-10 06:34:57,413 - distributed.nanny - INFO - Worker closed
2024-01-10 06:34:57,413 - distributed.nanny - INFO - Worker closed
2024-01-10 06:34:57,413 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:35283', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1704868497.4134476')
2024-01-10 06:34:57,413 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:42999', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1704868497.413755')
2024-01-10 06:34:57,414 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:45236; closing.
2024-01-10 06:34:57,414 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:45214; closing.
2024-01-10 06:34:57,414 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:34061', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1704868497.4147074')
2024-01-10 06:34:57,415 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:38207', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1704868497.415106')
2024-01-10 06:34:57,415 - distributed.scheduler - INFO - Lost all workers
2024-01-10 06:34:58,670 - distributed._signals - INFO - Received signal SIGINT (2)
2024-01-10 06:34:58,670 - distributed.scheduler - INFO - Scheduler closing due to signal-2...
2024-01-10 06:34:58,671 - distributed.scheduler - INFO - Scheduler closing all comms
2024-01-10 06:34:58,672 - distributed.scheduler - INFO - Stopped scheduler at 'tcp://10.33.227.163:9369'
2024-01-10 06:34:58,673 - distributed.scheduler - INFO - End scheduler
PASSED
dask_cuda/tests/test_dask_cuda_worker.py::test_rmm_async 2024-01-10 06:35:01,130 - distributed.scheduler - INFO - -----------------------------------------------
2024-01-10 06:35:01,135 - distributed.http.proxy - INFO - To route to workers diagnostics web server please install jupyter-server-proxy: python -m pip install jupyter-server-proxy
2024-01-10 06:35:01,138 - distributed.scheduler - INFO - State start
2024-01-10 06:35:01,160 - distributed.scheduler - INFO - -----------------------------------------------
2024-01-10 06:35:01,161 - distributed.scheduler - INFO -   Scheduler at:  tcp://10.33.227.163:9369
2024-01-10 06:35:01,162 - distributed.scheduler - INFO -   dashboard at:  http://10.33.227.163:8787/status
2024-01-10 06:35:01,163 - distributed.scheduler - INFO - Registering Worker plugin shuffle
2024-01-10 06:35:01,280 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:40483'
2024-01-10 06:35:01,299 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:41527'
2024-01-10 06:35:01,315 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:35053'
2024-01-10 06:35:01,326 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:35345'
2024-01-10 06:35:01,329 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:39555'
2024-01-10 06:35:01,338 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:46487'
2024-01-10 06:35:01,347 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:40373'
2024-01-10 06:35:01,357 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:41769'
2024-01-10 06:35:02,451 - distributed.scheduler - INFO - Receive client connection: Client-6056556a-af82-11ee-9743-d8c49764f6bb
2024-01-10 06:35:02,473 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:37774
2024-01-10 06:35:03,220 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2024-01-10 06:35:03,220 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2024-01-10 06:35:03,220 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2024-01-10 06:35:03,220 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2024-01-10 06:35:03,222 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2024-01-10 06:35:03,222 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2024-01-10 06:35:03,225 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2024-01-10 06:35:03,225 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2024-01-10 06:35:03,225 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2024-01-10 06:35:03,225 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:42135
2024-01-10 06:35:03,225 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:42135
2024-01-10 06:35:03,225 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:46227
2024-01-10 06:35:03,225 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2024-01-10 06:35:03,225 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:46227
2024-01-10 06:35:03,225 - distributed.worker - INFO -          dashboard at:            127.0.0.1:36157
2024-01-10 06:35:03,226 - distributed.worker - INFO -          dashboard at:            127.0.0.1:40743
2024-01-10 06:35:03,226 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2024-01-10 06:35:03,226 - distributed.worker - INFO - -------------------------------------------------
2024-01-10 06:35:03,226 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2024-01-10 06:35:03,226 - distributed.worker - INFO - -------------------------------------------------
2024-01-10 06:35:03,226 - distributed.worker - INFO -               Threads:                          1
2024-01-10 06:35:03,226 - distributed.worker - INFO -               Threads:                          1
2024-01-10 06:35:03,226 - distributed.worker - INFO -                Memory:                 125.97 GiB
2024-01-10 06:35:03,226 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-05_krr03
2024-01-10 06:35:03,226 - distributed.worker - INFO -                Memory:                 125.97 GiB
2024-01-10 06:35:03,226 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-tu6aje7o
2024-01-10 06:35:03,226 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-58c0bf71-0251-4307-afc3-871d3a0fd56d
2024-01-10 06:35:03,226 - distributed.worker - INFO - Starting Worker plugin RMMSetup-a43492cc-1112-400b-b947-751cd368f7b4
2024-01-10 06:35:03,226 - distributed.worker - INFO - Starting Worker plugin PreImport-a84cc0d4-94c5-494e-b8b9-04228177add0
2024-01-10 06:35:03,226 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2024-01-10 06:35:03,226 - distributed.worker - INFO - Starting Worker plugin RMMSetup-b9566866-897d-46b5-b713-0300b091cef4
2024-01-10 06:35:03,227 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:42625
2024-01-10 06:35:03,227 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:42625
2024-01-10 06:35:03,227 - distributed.worker - INFO -          dashboard at:            127.0.0.1:36589
2024-01-10 06:35:03,227 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2024-01-10 06:35:03,227 - distributed.worker - INFO - -------------------------------------------------
2024-01-10 06:35:03,227 - distributed.worker - INFO -               Threads:                          1
2024-01-10 06:35:03,227 - distributed.worker - INFO -                Memory:                 125.97 GiB
2024-01-10 06:35:03,227 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-fhkf5ebv
2024-01-10 06:35:03,228 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-a3cf1385-2661-4616-9414-a4ff7c419c97
2024-01-10 06:35:03,228 - distributed.worker - INFO - Starting Worker plugin PreImport-f312b65f-1d10-4cbd-97f0-5078163b5c34
2024-01-10 06:35:03,228 - distributed.worker - INFO - Starting Worker plugin RMMSetup-f4a9a48f-b201-4b21-b438-013d57340df7
2024-01-10 06:35:03,229 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2024-01-10 06:35:03,230 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:39519
2024-01-10 06:35:03,230 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:39519
2024-01-10 06:35:03,230 - distributed.worker - INFO -          dashboard at:            127.0.0.1:33513
2024-01-10 06:35:03,230 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2024-01-10 06:35:03,231 - distributed.worker - INFO - -------------------------------------------------
2024-01-10 06:35:03,231 - distributed.worker - INFO -               Threads:                          1
2024-01-10 06:35:03,231 - distributed.worker - INFO -                Memory:                 125.97 GiB
2024-01-10 06:35:03,231 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-jecbuo_x
2024-01-10 06:35:03,231 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-70e9ebdf-38af-413a-8df3-df25733b5311
2024-01-10 06:35:03,232 - distributed.worker - INFO - Starting Worker plugin PreImport-56b9223d-5bf6-4e23-ab49-6c78590ebddc
2024-01-10 06:35:03,233 - distributed.worker - INFO - Starting Worker plugin RMMSetup-3363390b-ba04-4aad-ac90-37e411cf0403
2024-01-10 06:35:03,289 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2024-01-10 06:35:03,290 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2024-01-10 06:35:03,291 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2024-01-10 06:35:03,291 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2024-01-10 06:35:03,291 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2024-01-10 06:35:03,291 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2024-01-10 06:35:03,291 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2024-01-10 06:35:03,291 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2024-01-10 06:35:03,294 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2024-01-10 06:35:03,295 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:42463
2024-01-10 06:35:03,295 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2024-01-10 06:35:03,295 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:42463
2024-01-10 06:35:03,295 - distributed.worker - INFO -          dashboard at:            127.0.0.1:34255
2024-01-10 06:35:03,295 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2024-01-10 06:35:03,295 - distributed.worker - INFO - -------------------------------------------------
2024-01-10 06:35:03,295 - distributed.worker - INFO -               Threads:                          1
2024-01-10 06:35:03,295 - distributed.worker - INFO -                Memory:                 125.97 GiB
2024-01-10 06:35:03,295 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-b_ktyqvo
2024-01-10 06:35:03,296 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2024-01-10 06:35:03,296 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2024-01-10 06:35:03,296 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-90681c49-be6c-4565-bdcd-26ef60d354a9
2024-01-10 06:35:03,296 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:40435
2024-01-10 06:35:03,296 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:40435
2024-01-10 06:35:03,296 - distributed.worker - INFO -          dashboard at:            127.0.0.1:42127
2024-01-10 06:35:03,296 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2024-01-10 06:35:03,296 - distributed.worker - INFO - -------------------------------------------------
2024-01-10 06:35:03,296 - distributed.worker - INFO -               Threads:                          1
2024-01-10 06:35:03,296 - distributed.worker - INFO -                Memory:                 125.97 GiB
2024-01-10 06:35:03,296 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-1csvhupe
2024-01-10 06:35:03,296 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:35641
2024-01-10 06:35:03,296 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:44455
2024-01-10 06:35:03,296 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:35641
2024-01-10 06:35:03,296 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-7a01b44c-84ac-4855-a553-ba08e65f680c
2024-01-10 06:35:03,297 - distributed.worker - INFO -          dashboard at:            127.0.0.1:40919
2024-01-10 06:35:03,297 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:44455
2024-01-10 06:35:03,297 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2024-01-10 06:35:03,297 - distributed.worker - INFO - Starting Worker plugin RMMSetup-a36fb13e-e946-4ce4-828c-1034b9979adc
2024-01-10 06:35:03,297 - distributed.worker - INFO - -------------------------------------------------
2024-01-10 06:35:03,297 - distributed.worker - INFO -          dashboard at:            127.0.0.1:33545
2024-01-10 06:35:03,297 - distributed.worker - INFO -               Threads:                          1
2024-01-10 06:35:03,297 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2024-01-10 06:35:03,297 - distributed.worker - INFO -                Memory:                 125.97 GiB
2024-01-10 06:35:03,297 - distributed.worker - INFO - -------------------------------------------------
2024-01-10 06:35:03,297 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-f5wmjt4_
2024-01-10 06:35:03,297 - distributed.worker - INFO -               Threads:                          1
2024-01-10 06:35:03,297 - distributed.worker - INFO -                Memory:                 125.97 GiB
2024-01-10 06:35:03,297 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-ns1yj7n7
2024-01-10 06:35:03,297 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-4d5181e3-6747-4147-90db-466f457439e5
2024-01-10 06:35:03,297 - distributed.worker - INFO - Starting Worker plugin RMMSetup-e64c9056-f243-4e31-bd43-f236fee4d723
2024-01-10 06:35:03,297 - distributed.worker - INFO - Starting Worker plugin RMMSetup-7da8287d-c4c4-41c6-b7d4-653c90814195
2024-01-10 06:35:03,299 - distributed.worker - INFO - Starting Worker plugin PreImport-0b3ae49c-afe8-4477-b74e-dade31e2a596
2024-01-10 06:35:03,300 - distributed.worker - INFO - Starting Worker plugin RMMSetup-b9f5c4aa-9abc-4c31-82dd-7e1ab83790f5
2024-01-10 06:35:05,501 - distributed.worker - INFO - -------------------------------------------------
2024-01-10 06:35:05,522 - distributed.worker - INFO - Starting Worker plugin PreImport-49a9b45b-f86a-42b0-bb42-d77d09b0aca3
2024-01-10 06:35:05,523 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-4b2ba92b-ed3e-452c-86de-a4de2b7c77e2
2024-01-10 06:35:05,523 - distributed.worker - INFO - -------------------------------------------------
2024-01-10 06:35:05,528 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:42135', status: init, memory: 0, processing: 0>
2024-01-10 06:35:05,529 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:42135
2024-01-10 06:35:05,529 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:37798
2024-01-10 06:35:05,530 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-01-10 06:35:05,531 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2024-01-10 06:35:05,531 - distributed.worker - INFO - -------------------------------------------------
2024-01-10 06:35:05,533 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2024-01-10 06:35:05,549 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:46227', status: init, memory: 0, processing: 0>
2024-01-10 06:35:05,550 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:46227
2024-01-10 06:35:05,550 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:37806
2024-01-10 06:35:05,551 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-01-10 06:35:05,551 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2024-01-10 06:35:05,551 - distributed.worker - INFO - -------------------------------------------------
2024-01-10 06:35:05,553 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2024-01-10 06:35:05,583 - distributed.worker - INFO - -------------------------------------------------
2024-01-10 06:35:05,611 - distributed.worker - INFO - -------------------------------------------------
2024-01-10 06:35:05,620 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:42625', status: init, memory: 0, processing: 0>
2024-01-10 06:35:05,621 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:42625
2024-01-10 06:35:05,621 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:37814
2024-01-10 06:35:05,622 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-01-10 06:35:05,623 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2024-01-10 06:35:05,623 - distributed.worker - INFO - -------------------------------------------------
2024-01-10 06:35:05,625 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2024-01-10 06:35:05,646 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:39519', status: init, memory: 0, processing: 0>
2024-01-10 06:35:05,647 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:39519
2024-01-10 06:35:05,647 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:37828
2024-01-10 06:35:05,648 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-01-10 06:35:05,649 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2024-01-10 06:35:05,649 - distributed.worker - INFO - -------------------------------------------------
2024-01-10 06:35:05,651 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2024-01-10 06:35:05,687 - distributed.worker - INFO - Starting Worker plugin PreImport-6cdbc7ae-4dc0-4176-8763-2e4922008f3b
2024-01-10 06:35:05,687 - distributed.worker - INFO - -------------------------------------------------
2024-01-10 06:35:05,712 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:35641', status: init, memory: 0, processing: 0>
2024-01-10 06:35:05,713 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:35641
2024-01-10 06:35:05,713 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:37832
2024-01-10 06:35:05,714 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-01-10 06:35:05,714 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2024-01-10 06:35:05,714 - distributed.worker - INFO - -------------------------------------------------
2024-01-10 06:35:05,716 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2024-01-10 06:35:05,720 - distributed.worker - INFO - Starting Worker plugin PreImport-0e2a8e75-a4be-4824-a7cb-14c573cf07ba
2024-01-10 06:35:05,720 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-f69f7e08-833b-4629-a542-9bb2b7adc964
2024-01-10 06:35:05,721 - distributed.worker - INFO - Starting Worker plugin PreImport-c014fcfb-c111-4043-9e7c-65754dc13730
2024-01-10 06:35:05,722 - distributed.worker - INFO - -------------------------------------------------
2024-01-10 06:35:05,722 - distributed.worker - INFO - -------------------------------------------------
2024-01-10 06:35:05,729 - distributed.worker - INFO - -------------------------------------------------
2024-01-10 06:35:05,745 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:40435', status: init, memory: 0, processing: 0>
2024-01-10 06:35:05,746 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:40435
2024-01-10 06:35:05,746 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:37838
2024-01-10 06:35:05,747 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-01-10 06:35:05,748 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2024-01-10 06:35:05,748 - distributed.worker - INFO - -------------------------------------------------
2024-01-10 06:35:05,749 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2024-01-10 06:35:05,760 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:44455', status: init, memory: 0, processing: 0>
2024-01-10 06:35:05,761 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:44455
2024-01-10 06:35:05,761 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:37840
2024-01-10 06:35:05,762 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-01-10 06:35:05,763 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2024-01-10 06:35:05,763 - distributed.worker - INFO - -------------------------------------------------
2024-01-10 06:35:05,766 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2024-01-10 06:35:05,768 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:42463', status: init, memory: 0, processing: 0>
2024-01-10 06:35:05,768 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:42463
2024-01-10 06:35:05,769 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:37854
2024-01-10 06:35:05,770 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-01-10 06:35:05,771 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2024-01-10 06:35:05,771 - distributed.worker - INFO - -------------------------------------------------
2024-01-10 06:35:05,773 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2024-01-10 06:35:05,850 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2024-01-10 06:35:05,850 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2024-01-10 06:35:05,850 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2024-01-10 06:35:05,850 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2024-01-10 06:35:05,850 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2024-01-10 06:35:05,851 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2024-01-10 06:35:05,851 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2024-01-10 06:35:05,851 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2024-01-10 06:35:05,862 - distributed.worker - INFO - Run out-of-band function 'get_worker_config'
2024-01-10 06:35:05,862 - distributed.worker - INFO - Run out-of-band function 'get_worker_config'
2024-01-10 06:35:05,862 - distributed.worker - INFO - Run out-of-band function 'get_worker_config'
2024-01-10 06:35:05,862 - distributed.worker - INFO - Run out-of-band function 'get_worker_config'
2024-01-10 06:35:05,863 - distributed.worker - INFO - Run out-of-band function 'get_worker_config'
2024-01-10 06:35:05,863 - distributed.worker - INFO - Run out-of-band function 'get_worker_config'
2024-01-10 06:35:05,863 - distributed.worker - INFO - Run out-of-band function 'get_worker_config'
2024-01-10 06:35:05,863 - distributed.worker - INFO - Run out-of-band function 'get_worker_config'
2024-01-10 06:35:05,872 - distributed.worker - INFO - Run out-of-band function 'lambda'
2024-01-10 06:35:05,873 - distributed.worker - INFO - Run out-of-band function 'lambda'
2024-01-10 06:35:05,876 - distributed.scheduler - INFO - Remove client Client-6056556a-af82-11ee-9743-d8c49764f6bb
2024-01-10 06:35:05,876 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:37774; closing.
2024-01-10 06:35:05,876 - distributed.scheduler - INFO - Remove client Client-6056556a-af82-11ee-9743-d8c49764f6bb
2024-01-10 06:35:05,877 - distributed.scheduler - INFO - Close client connection: Client-6056556a-af82-11ee-9743-d8c49764f6bb
2024-01-10 06:35:05,877 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:40483'. Reason: nanny-close
2024-01-10 06:35:05,878 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2024-01-10 06:35:05,878 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:41527'. Reason: nanny-close
2024-01-10 06:35:05,879 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2024-01-10 06:35:05,879 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:35053'. Reason: nanny-close
2024-01-10 06:35:05,879 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:42625. Reason: nanny-close
2024-01-10 06:35:05,879 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2024-01-10 06:35:05,879 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:35345'. Reason: nanny-close
2024-01-10 06:35:05,880 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:39519. Reason: nanny-close
2024-01-10 06:35:05,880 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2024-01-10 06:35:05,880 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:39555'. Reason: nanny-close
2024-01-10 06:35:05,880 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:42135. Reason: nanny-close
2024-01-10 06:35:05,880 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2024-01-10 06:35:05,880 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:46487'. Reason: nanny-close
2024-01-10 06:35:05,880 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:46227. Reason: nanny-close
2024-01-10 06:35:05,881 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2024-01-10 06:35:05,881 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:40373'. Reason: nanny-close
2024-01-10 06:35:05,881 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:44455. Reason: nanny-close
2024-01-10 06:35:05,881 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2024-01-10 06:35:05,881 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:41769'. Reason: nanny-close
2024-01-10 06:35:05,881 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:42463. Reason: nanny-close
2024-01-10 06:35:05,881 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2024-01-10 06:35:05,881 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2024-01-10 06:35:05,882 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:37814; closing.
2024-01-10 06:35:05,882 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:40435. Reason: nanny-close
2024-01-10 06:35:05,882 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2024-01-10 06:35:05,882 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:42625', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1704868505.8822489')
2024-01-10 06:35:05,882 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2024-01-10 06:35:05,882 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2024-01-10 06:35:05,882 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:35641. Reason: nanny-close
2024-01-10 06:35:05,883 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:37798; closing.
2024-01-10 06:35:05,883 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2024-01-10 06:35:05,883 - distributed.nanny - INFO - Worker closed
2024-01-10 06:35:05,883 - distributed.nanny - INFO - Worker closed
2024-01-10 06:35:05,883 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2024-01-10 06:35:05,883 - distributed.nanny - INFO - Worker closed
2024-01-10 06:35:05,884 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2024-01-10 06:35:05,884 - distributed.nanny - INFO - Worker closed
2024-01-10 06:35:05,884 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:42135', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1704868505.8841927')
2024-01-10 06:35:05,884 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:37828; closing.
2024-01-10 06:35:05,884 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2024-01-10 06:35:05,884 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:37806; closing.
2024-01-10 06:35:05,885 - distributed.nanny - INFO - Worker closed
2024-01-10 06:35:05,885 - distributed.nanny - INFO - Worker closed
2024-01-10 06:35:05,885 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:39519', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1704868505.8856952')
2024-01-10 06:35:05,885 - distributed.nanny - INFO - Worker closed
2024-01-10 06:35:05,886 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:37840; closing.
2024-01-10 06:35:05,886 - distributed.nanny - INFO - Worker closed
2024-01-10 06:35:05,886 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:46227', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1704868505.8862333')
2024-01-10 06:35:05,886 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:37854; closing.
2024-01-10 06:35:05,887 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:44455', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1704868505.8871303')
2024-01-10 06:35:05,887 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:42463', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1704868505.8874488')
2024-01-10 06:35:05,887 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:37838; closing.
2024-01-10 06:35:05,887 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:37832; closing.
2024-01-10 06:35:05,888 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:40435', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1704868505.8883114')
2024-01-10 06:35:05,888 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:35641', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1704868505.8886702')
2024-01-10 06:35:05,888 - distributed.scheduler - INFO - Lost all workers
2024-01-10 06:35:07,094 - distributed._signals - INFO - Received signal SIGINT (2)
2024-01-10 06:35:07,095 - distributed.scheduler - INFO - Scheduler closing due to signal-2...
2024-01-10 06:35:07,095 - distributed.scheduler - INFO - Scheduler closing all comms
2024-01-10 06:35:07,097 - distributed.scheduler - INFO - Stopped scheduler at 'tcp://10.33.227.163:9369'
2024-01-10 06:35:07,097 - distributed.scheduler - INFO - End scheduler
PASSED
dask_cuda/tests/test_dask_cuda_worker.py::test_rmm_async_with_maximum_pool_size 2024-01-10 06:35:09,434 - distributed.scheduler - INFO - -----------------------------------------------
2024-01-10 06:35:09,439 - distributed.http.proxy - INFO - To route to workers diagnostics web server please install jupyter-server-proxy: python -m pip install jupyter-server-proxy
/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 33581 instead
  warnings.warn(
2024-01-10 06:35:09,443 - distributed.scheduler - INFO - State start
2024-01-10 06:35:09,465 - distributed.scheduler - INFO - -----------------------------------------------
2024-01-10 06:35:09,466 - distributed.scheduler - INFO -   Scheduler at:  tcp://10.33.227.163:9369
2024-01-10 06:35:09,466 - distributed.scheduler - INFO -   dashboard at:  http://10.33.227.163:33581/status
2024-01-10 06:35:09,467 - distributed.scheduler - INFO - Registering Worker plugin shuffle
2024-01-10 06:35:09,636 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:35271'
2024-01-10 06:35:09,657 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:37365'
2024-01-10 06:35:09,667 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:45683'
2024-01-10 06:35:09,682 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:34515'
2024-01-10 06:35:09,685 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:40305'
2024-01-10 06:35:09,694 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:44971'
2024-01-10 06:35:09,705 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:32857'
2024-01-10 06:35:09,715 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:33327'
2024-01-10 06:35:10,837 - distributed.scheduler - INFO - Receive client connection: Client-65526de3-af82-11ee-9743-d8c49764f6bb
2024-01-10 06:35:10,851 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:55708
2024-01-10 06:35:11,516 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2024-01-10 06:35:11,516 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2024-01-10 06:35:11,520 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2024-01-10 06:35:11,521 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:44645
2024-01-10 06:35:11,521 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:44645
2024-01-10 06:35:11,521 - distributed.worker - INFO -          dashboard at:            127.0.0.1:45427
2024-01-10 06:35:11,522 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2024-01-10 06:35:11,522 - distributed.worker - INFO - -------------------------------------------------
2024-01-10 06:35:11,522 - distributed.worker - INFO -               Threads:                          1
2024-01-10 06:35:11,522 - distributed.worker - INFO -                Memory:                 125.97 GiB
2024-01-10 06:35:11,522 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-py__upzh
2024-01-10 06:35:11,522 - distributed.worker - INFO - Starting Worker plugin RMMSetup-86635d20-2289-4658-bdec-1da53e351286
2024-01-10 06:35:11,762 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2024-01-10 06:35:11,763 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2024-01-10 06:35:11,767 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2024-01-10 06:35:11,767 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2024-01-10 06:35:11,768 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2024-01-10 06:35:11,768 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:33305
2024-01-10 06:35:11,768 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:33305
2024-01-10 06:35:11,768 - distributed.worker - INFO -          dashboard at:            127.0.0.1:45215
2024-01-10 06:35:11,768 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2024-01-10 06:35:11,768 - distributed.worker - INFO - -------------------------------------------------
2024-01-10 06:35:11,768 - distributed.worker - INFO -               Threads:                          1
2024-01-10 06:35:11,768 - distributed.worker - INFO -                Memory:                 125.97 GiB
2024-01-10 06:35:11,768 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-88mqkhc8
2024-01-10 06:35:11,769 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-b48ff71d-ff2e-4496-adc7-72a8d2753a8b
2024-01-10 06:35:11,770 - distributed.worker - INFO - Starting Worker plugin PreImport-f99dd9f6-8ba5-413a-82ff-f0db60cc98b9
2024-01-10 06:35:11,770 - distributed.worker - INFO - Starting Worker plugin RMMSetup-257031f2-40cd-402f-9f6f-e95634fee1bb
2024-01-10 06:35:11,772 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2024-01-10 06:35:11,773 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:46093
2024-01-10 06:35:11,773 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:46093
2024-01-10 06:35:11,773 - distributed.worker - INFO -          dashboard at:            127.0.0.1:40887
2024-01-10 06:35:11,773 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2024-01-10 06:35:11,773 - distributed.worker - INFO - -------------------------------------------------
2024-01-10 06:35:11,773 - distributed.worker - INFO -               Threads:                          1
2024-01-10 06:35:11,773 - distributed.worker - INFO -                Memory:                 125.97 GiB
2024-01-10 06:35:11,773 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-d43tga8c
2024-01-10 06:35:11,773 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-4c751492-dfb6-49c9-bc9f-cff76d246e6c
2024-01-10 06:35:11,774 - distributed.worker - INFO - Starting Worker plugin PreImport-dc45811e-4bd6-426c-a797-e76208ddee4f
2024-01-10 06:35:11,774 - distributed.worker - INFO - Starting Worker plugin RMMSetup-3691479a-2146-4734-9d49-188a93236f66
2024-01-10 06:35:11,776 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2024-01-10 06:35:11,776 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2024-01-10 06:35:11,779 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2024-01-10 06:35:11,779 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2024-01-10 06:35:11,781 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2024-01-10 06:35:11,781 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2024-01-10 06:35:11,781 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2024-01-10 06:35:11,782 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:46633
2024-01-10 06:35:11,782 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:46633
2024-01-10 06:35:11,782 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2024-01-10 06:35:11,782 - distributed.worker - INFO -          dashboard at:            127.0.0.1:44313
2024-01-10 06:35:11,782 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2024-01-10 06:35:11,782 - distributed.worker - INFO - -------------------------------------------------
2024-01-10 06:35:11,782 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2024-01-10 06:35:11,782 - distributed.worker - INFO -               Threads:                          1
2024-01-10 06:35:11,782 - distributed.worker - INFO -                Memory:                 125.97 GiB
2024-01-10 06:35:11,782 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-m3t8djnx
2024-01-10 06:35:11,782 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-b721c8a1-ed23-4bc5-bdf0-2f47c8206bde
2024-01-10 06:35:11,782 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2024-01-10 06:35:11,782 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2024-01-10 06:35:11,782 - distributed.worker - INFO - Starting Worker plugin PreImport-9649b9a6-65a2-4bc9-8f10-f4dd8c6227ff
2024-01-10 06:35:11,783 - distributed.worker - INFO - Starting Worker plugin RMMSetup-34786fd2-0359-4f2a-a1bd-3802eabaad07
2024-01-10 06:35:11,786 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2024-01-10 06:35:11,786 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2024-01-10 06:35:11,787 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:43175
2024-01-10 06:35:11,787 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:43175
2024-01-10 06:35:11,787 - distributed.worker - INFO -          dashboard at:            127.0.0.1:39215
2024-01-10 06:35:11,787 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2024-01-10 06:35:11,787 - distributed.worker - INFO - -------------------------------------------------
2024-01-10 06:35:11,787 - distributed.worker - INFO -               Threads:                          1
2024-01-10 06:35:11,787 - distributed.worker - INFO -                Memory:                 125.97 GiB
2024-01-10 06:35:11,787 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-_v3gv3st
2024-01-10 06:35:11,787 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:37349
2024-01-10 06:35:11,787 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2024-01-10 06:35:11,787 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:37349
2024-01-10 06:35:11,787 - distributed.worker - INFO -          dashboard at:            127.0.0.1:37579
2024-01-10 06:35:11,787 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-e0dfe86f-6b67-48cc-a97b-3ab87e02dcde
2024-01-10 06:35:11,788 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2024-01-10 06:35:11,788 - distributed.worker - INFO - -------------------------------------------------
2024-01-10 06:35:11,788 - distributed.worker - INFO -               Threads:                          1
2024-01-10 06:35:11,788 - distributed.worker - INFO - Starting Worker plugin PreImport-a1734f84-36f9-49c9-b604-4f5d796a8657
2024-01-10 06:35:11,788 - distributed.worker - INFO -                Memory:                 125.97 GiB
2024-01-10 06:35:11,788 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-gnu3374o
2024-01-10 06:35:11,788 - distributed.worker - INFO - Starting Worker plugin RMMSetup-aed4be2e-aa01-42cd-b36b-55ac655d77c3
2024-01-10 06:35:11,788 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-80a52ca2-1a75-4455-92d1-4f777074e3cb
2024-01-10 06:35:11,788 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2024-01-10 06:35:11,788 - distributed.worker - INFO - Starting Worker plugin PreImport-d6c5e802-4422-41db-b41f-13d144148b22
2024-01-10 06:35:11,788 - distributed.worker - INFO - Starting Worker plugin RMMSetup-6d876730-bb80-4ca9-a525-89567f1fdb0e
2024-01-10 06:35:11,788 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:32811
2024-01-10 06:35:11,788 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:32811
2024-01-10 06:35:11,788 - distributed.worker - INFO -          dashboard at:            127.0.0.1:39469
2024-01-10 06:35:11,789 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2024-01-10 06:35:11,789 - distributed.worker - INFO - -------------------------------------------------
2024-01-10 06:35:11,789 - distributed.worker - INFO -               Threads:                          1
2024-01-10 06:35:11,789 - distributed.worker - INFO -                Memory:                 125.97 GiB
2024-01-10 06:35:11,789 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-f4t1krtz
2024-01-10 06:35:11,789 - distributed.worker - INFO - Starting Worker plugin RMMSetup-f57f8219-e97c-447d-a297-9a964f1bb015
2024-01-10 06:35:11,789 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:39993
2024-01-10 06:35:11,790 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:39993
2024-01-10 06:35:11,790 - distributed.worker - INFO -          dashboard at:            127.0.0.1:37495
2024-01-10 06:35:11,790 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2024-01-10 06:35:11,790 - distributed.worker - INFO - -------------------------------------------------
2024-01-10 06:35:11,790 - distributed.worker - INFO -               Threads:                          1
2024-01-10 06:35:11,790 - distributed.worker - INFO -                Memory:                 125.97 GiB
2024-01-10 06:35:11,790 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-ig1kscjl
2024-01-10 06:35:11,790 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-b888509f-d6ca-42ef-89bf-c9cea35bb13f
2024-01-10 06:35:11,790 - distributed.worker - INFO - Starting Worker plugin PreImport-02364ff4-92e2-40a8-92e9-c5a83cf8e6bc
2024-01-10 06:35:11,790 - distributed.worker - INFO - Starting Worker plugin RMMSetup-1c314b5f-8b4d-4cba-ba1f-1056236ed880
2024-01-10 06:35:12,037 - distributed.worker - INFO - Starting Worker plugin PreImport-b84590ca-b066-4f2e-938c-d6d3eac099e9
2024-01-10 06:35:12,037 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-ffef14f4-cd81-4fa0-be91-97f5511f575c
2024-01-10 06:35:12,038 - distributed.worker - INFO - -------------------------------------------------
2024-01-10 06:35:12,063 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:44645', status: init, memory: 0, processing: 0>
2024-01-10 06:35:12,064 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:44645
2024-01-10 06:35:12,064 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:55726
2024-01-10 06:35:12,065 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-01-10 06:35:12,066 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2024-01-10 06:35:12,066 - distributed.worker - INFO - -------------------------------------------------
2024-01-10 06:35:12,068 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2024-01-10 06:35:14,063 - distributed.worker - INFO - -------------------------------------------------
2024-01-10 06:35:14,097 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:33305', status: init, memory: 0, processing: 0>
2024-01-10 06:35:14,098 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:33305
2024-01-10 06:35:14,099 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:55738
2024-01-10 06:35:14,100 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-01-10 06:35:14,101 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2024-01-10 06:35:14,102 - distributed.worker - INFO - -------------------------------------------------
2024-01-10 06:35:14,103 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2024-01-10 06:35:14,156 - distributed.worker - INFO - -------------------------------------------------
2024-01-10 06:35:14,163 - distributed.worker - INFO - -------------------------------------------------
2024-01-10 06:35:14,179 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:43175', status: init, memory: 0, processing: 0>
2024-01-10 06:35:14,180 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:43175
2024-01-10 06:35:14,180 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:55752
2024-01-10 06:35:14,181 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-01-10 06:35:14,181 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2024-01-10 06:35:14,181 - distributed.worker - INFO - -------------------------------------------------
2024-01-10 06:35:14,183 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2024-01-10 06:35:14,184 - distributed.worker - INFO - -------------------------------------------------
2024-01-10 06:35:14,186 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:46093', status: init, memory: 0, processing: 0>
2024-01-10 06:35:14,186 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:46093
2024-01-10 06:35:14,187 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:55760
2024-01-10 06:35:14,187 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-01-10 06:35:14,188 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2024-01-10 06:35:14,188 - distributed.worker - INFO - -------------------------------------------------
2024-01-10 06:35:14,190 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2024-01-10 06:35:14,204 - distributed.worker - INFO - -------------------------------------------------
2024-01-10 06:35:14,209 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:46633', status: init, memory: 0, processing: 0>
2024-01-10 06:35:14,209 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:46633
2024-01-10 06:35:14,209 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:55770
2024-01-10 06:35:14,210 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-01-10 06:35:14,211 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2024-01-10 06:35:14,211 - distributed.worker - INFO - -------------------------------------------------
2024-01-10 06:35:14,213 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2024-01-10 06:35:14,219 - distributed.worker - INFO - -------------------------------------------------
2024-01-10 06:35:14,238 - distributed.worker - INFO - Starting Worker plugin PreImport-b9dce6ae-3833-4eb1-a36b-392638d12719
2024-01-10 06:35:14,239 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:39993', status: init, memory: 0, processing: 0>
2024-01-10 06:35:14,240 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:39993
2024-01-10 06:35:14,240 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:55784
2024-01-10 06:35:14,240 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-54900988-b401-46fd-bbcc-add374250100
2024-01-10 06:35:14,241 - distributed.worker - INFO - -------------------------------------------------
2024-01-10 06:35:14,241 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-01-10 06:35:14,242 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2024-01-10 06:35:14,242 - distributed.worker - INFO - -------------------------------------------------
2024-01-10 06:35:14,244 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2024-01-10 06:35:14,248 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:37349', status: init, memory: 0, processing: 0>
2024-01-10 06:35:14,249 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:37349
2024-01-10 06:35:14,249 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:55798
2024-01-10 06:35:14,250 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-01-10 06:35:14,251 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2024-01-10 06:35:14,251 - distributed.worker - INFO - -------------------------------------------------
2024-01-10 06:35:14,253 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2024-01-10 06:35:14,264 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:32811', status: init, memory: 0, processing: 0>
2024-01-10 06:35:14,264 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:32811
2024-01-10 06:35:14,264 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:55810
2024-01-10 06:35:14,265 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-01-10 06:35:14,266 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2024-01-10 06:35:14,266 - distributed.worker - INFO - -------------------------------------------------
2024-01-10 06:35:14,268 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2024-01-10 06:35:14,328 - distributed.worker - INFO - Run out-of-band function 'lambda'
2024-01-10 06:35:14,329 - distributed.worker - INFO - Run out-of-band function 'lambda'
2024-01-10 06:35:14,329 - distributed.worker - INFO - Run out-of-band function 'lambda'
2024-01-10 06:35:14,329 - distributed.worker - INFO - Run out-of-band function 'lambda'
2024-01-10 06:35:14,329 - distributed.worker - INFO - Run out-of-band function 'lambda'
2024-01-10 06:35:14,329 - distributed.worker - INFO - Run out-of-band function 'lambda'
2024-01-10 06:35:14,329 - distributed.worker - INFO - Run out-of-band function 'lambda'
2024-01-10 06:35:14,330 - distributed.worker - INFO - Run out-of-band function 'lambda'
2024-01-10 06:35:14,343 - distributed.worker - INFO - Run out-of-band function 'get_worker_config'
2024-01-10 06:35:14,343 - distributed.worker - INFO - Run out-of-band function 'get_worker_config'
2024-01-10 06:35:14,343 - distributed.worker - INFO - Run out-of-band function 'get_worker_config'
2024-01-10 06:35:14,343 - distributed.worker - INFO - Run out-of-band function 'get_worker_config'
2024-01-10 06:35:14,344 - distributed.worker - INFO - Run out-of-band function 'get_worker_config'
2024-01-10 06:35:14,344 - distributed.worker - INFO - Run out-of-band function 'get_worker_config'
2024-01-10 06:35:14,344 - distributed.worker - INFO - Run out-of-band function 'get_worker_config'
2024-01-10 06:35:14,344 - distributed.worker - INFO - Run out-of-band function 'get_worker_config'
2024-01-10 06:35:14,353 - distributed.worker - INFO - Run out-of-band function 'lambda'
2024-01-10 06:35:14,354 - distributed.worker - INFO - Run out-of-band function 'lambda'
2024-01-10 06:35:14,357 - distributed.scheduler - INFO - Remove client Client-65526de3-af82-11ee-9743-d8c49764f6bb
2024-01-10 06:35:14,357 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:55708; closing.
2024-01-10 06:35:14,357 - distributed.scheduler - INFO - Remove client Client-65526de3-af82-11ee-9743-d8c49764f6bb
2024-01-10 06:35:14,358 - distributed.scheduler - INFO - Close client connection: Client-65526de3-af82-11ee-9743-d8c49764f6bb
2024-01-10 06:35:14,359 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:35271'. Reason: nanny-close
2024-01-10 06:35:14,359 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2024-01-10 06:35:14,359 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:37365'. Reason: nanny-close
2024-01-10 06:35:14,360 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2024-01-10 06:35:14,360 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:45683'. Reason: nanny-close
2024-01-10 06:35:14,360 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:33305. Reason: nanny-close
2024-01-10 06:35:14,360 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2024-01-10 06:35:14,361 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:34515'. Reason: nanny-close
2024-01-10 06:35:14,361 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:44645. Reason: nanny-close
2024-01-10 06:35:14,361 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2024-01-10 06:35:14,361 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:40305'. Reason: nanny-close
2024-01-10 06:35:14,361 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:32811. Reason: nanny-close
2024-01-10 06:35:14,361 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2024-01-10 06:35:14,361 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:44971'. Reason: nanny-close
2024-01-10 06:35:14,361 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:46093. Reason: nanny-close
2024-01-10 06:35:14,362 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2024-01-10 06:35:14,362 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:32857'. Reason: nanny-close
2024-01-10 06:35:14,362 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2024-01-10 06:35:14,362 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:37349. Reason: nanny-close
2024-01-10 06:35:14,362 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:33327'. Reason: nanny-close
2024-01-10 06:35:14,362 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2024-01-10 06:35:14,362 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:39993. Reason: nanny-close
2024-01-10 06:35:14,363 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2024-01-10 06:35:14,363 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2024-01-10 06:35:14,363 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:43175. Reason: nanny-close
2024-01-10 06:35:14,363 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:55810; closing.
2024-01-10 06:35:14,363 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2024-01-10 06:35:14,363 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:46633. Reason: nanny-close
2024-01-10 06:35:14,363 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2024-01-10 06:35:14,363 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:32811', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1704868514.3637838')
2024-01-10 06:35:14,364 - distributed.nanny - INFO - Worker closed
2024-01-10 06:35:14,364 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:55760; closing.
2024-01-10 06:35:14,364 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2024-01-10 06:35:14,364 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:55726; closing.
2024-01-10 06:35:14,364 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:55738; closing.
2024-01-10 06:35:14,364 - distributed.nanny - INFO - Worker closed
2024-01-10 06:35:14,364 - distributed.nanny - INFO - Worker closed
2024-01-10 06:35:14,364 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2024-01-10 06:35:14,365 - distributed.nanny - INFO - Worker closed
2024-01-10 06:35:14,365 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2024-01-10 06:35:14,365 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2024-01-10 06:35:14,365 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:46093', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1704868514.3654454')
2024-01-10 06:35:14,365 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:44645', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1704868514.3658843')
2024-01-10 06:35:14,366 - distributed.nanny - INFO - Worker closed
2024-01-10 06:35:14,366 - distributed.nanny - INFO - Worker closed
2024-01-10 06:35:14,366 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:33305', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1704868514.3663146')
2024-01-10 06:35:14,366 - distributed.nanny - INFO - Worker closed
2024-01-10 06:35:14,366 - distributed.nanny - INFO - Worker closed
2024-01-10 06:35:14,367 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:55798; closing.
2024-01-10 06:35:14,368 - distributed.batched - INFO - Batched Comm Closed <TCP (closed) Scheduler connection to worker local=tcp://127.0.0.1:9369 remote=tcp://127.0.0.1:55738>
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/batched.py", line 115, in _background_send
    nbytes = yield coro
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/tornado/gen.py", line 767, in run
    value = future.result()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/tcp.py", line 263, in write
    raise CommClosedError()
distributed.comm.core.CommClosedError
2024-01-10 06:35:14,370 - distributed.batched - INFO - Batched Comm Closed <TCP (closed) Scheduler connection to worker local=tcp://127.0.0.1:9369 remote=tcp://127.0.0.1:55726>
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/batched.py", line 115, in _background_send
    nbytes = yield coro
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/tornado/gen.py", line 767, in run
    value = future.result()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/tcp.py", line 263, in write
    raise CommClosedError()
distributed.comm.core.CommClosedError
2024-01-10 06:35:14,370 - distributed.batched - INFO - Batched Comm Closed <TCP (closed) Scheduler connection to worker local=tcp://127.0.0.1:9369 remote=tcp://127.0.0.1:55760>
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/batched.py", line 115, in _background_send
    nbytes = yield coro
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/tornado/gen.py", line 767, in run
    value = future.result()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/tcp.py", line 263, in write
    raise CommClosedError()
distributed.comm.core.CommClosedError
2024-01-10 06:35:14,371 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:37349', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1704868514.3711028')
2024-01-10 06:35:14,371 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:55784; closing.
2024-01-10 06:35:14,371 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:55752; closing.
2024-01-10 06:35:14,371 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:55770; closing.
2024-01-10 06:35:14,372 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:39993', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1704868514.372367')
2024-01-10 06:35:14,372 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:43175', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1704868514.3727767')
2024-01-10 06:35:14,373 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:46633', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1704868514.3731728')
2024-01-10 06:35:14,373 - distributed.scheduler - INFO - Lost all workers
2024-01-10 06:35:16,477 - distributed._signals - INFO - Received signal SIGINT (2)
2024-01-10 06:35:16,478 - distributed.scheduler - INFO - Scheduler closing due to signal-2...
2024-01-10 06:35:16,478 - distributed.scheduler - INFO - Scheduler closing all comms
2024-01-10 06:35:16,479 - distributed.scheduler - INFO - Stopped scheduler at 'tcp://10.33.227.163:9369'
2024-01-10 06:35:16,480 - distributed.scheduler - INFO - End scheduler
PASSED
dask_cuda/tests/test_dask_cuda_worker.py::test_rmm_logging 2024-01-10 06:35:18,759 - distributed.scheduler - INFO - -----------------------------------------------
2024-01-10 06:35:18,764 - distributed.http.proxy - INFO - To route to workers diagnostics web server please install jupyter-server-proxy: python -m pip install jupyter-server-proxy
/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 46693 instead
  warnings.warn(
2024-01-10 06:35:18,768 - distributed.scheduler - INFO - State start
2024-01-10 06:35:18,795 - distributed.scheduler - INFO - -----------------------------------------------
2024-01-10 06:35:18,797 - distributed.scheduler - INFO -   Scheduler at:  tcp://10.33.227.163:9369
2024-01-10 06:35:18,798 - distributed.scheduler - INFO -   dashboard at:  http://10.33.227.163:46693/status
2024-01-10 06:35:18,798 - distributed.scheduler - INFO - Registering Worker plugin shuffle
2024-01-10 06:35:18,992 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:41885'
2024-01-10 06:35:19,009 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:38309'
2024-01-10 06:35:19,025 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:43223'
2024-01-10 06:35:19,028 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:35751'
2024-01-10 06:35:19,037 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:42335'
2024-01-10 06:35:19,046 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:40767'
2024-01-10 06:35:19,057 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:41147'
2024-01-10 06:35:19,067 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:46295'
2024-01-10 06:35:20,936 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2024-01-10 06:35:20,937 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2024-01-10 06:35:20,937 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2024-01-10 06:35:20,938 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2024-01-10 06:35:20,944 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2024-01-10 06:35:20,945 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2024-01-10 06:35:20,945 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:37297
2024-01-10 06:35:20,946 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:37297
2024-01-10 06:35:20,946 - distributed.worker - INFO -          dashboard at:            127.0.0.1:39243
2024-01-10 06:35:20,946 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2024-01-10 06:35:20,946 - distributed.worker - INFO - -------------------------------------------------
2024-01-10 06:35:20,946 - distributed.worker - INFO -               Threads:                          1
2024-01-10 06:35:20,946 - distributed.worker - INFO -                Memory:                 125.97 GiB
2024-01-10 06:35:20,946 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-aq7yly6_
2024-01-10 06:35:20,947 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-7696613d-6343-43a2-94e6-b1690ca85cf3
2024-01-10 06:35:20,947 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:44373
2024-01-10 06:35:20,947 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:44373
2024-01-10 06:35:20,947 - distributed.worker - INFO -          dashboard at:            127.0.0.1:43813
2024-01-10 06:35:20,947 - distributed.worker - INFO - Starting Worker plugin PreImport-0da0293c-04d5-4a1c-9ec2-6c9f3b6aae5b
2024-01-10 06:35:20,947 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2024-01-10 06:35:20,947 - distributed.worker - INFO - -------------------------------------------------
2024-01-10 06:35:20,947 - distributed.worker - INFO - Starting Worker plugin RMMSetup-8044bcec-b327-44b2-bdac-de51584c5f06
2024-01-10 06:35:20,947 - distributed.worker - INFO -               Threads:                          1
2024-01-10 06:35:20,948 - distributed.worker - INFO -                Memory:                 125.97 GiB
2024-01-10 06:35:20,948 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-48trr66n
2024-01-10 06:35:20,948 - distributed.worker - INFO - Starting Worker plugin RMMSetup-f2eb2313-6823-46d3-9676-a4963203e3e8
2024-01-10 06:35:20,956 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2024-01-10 06:35:20,956 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2024-01-10 06:35:20,963 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2024-01-10 06:35:20,965 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:40809
2024-01-10 06:35:20,965 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:40809
2024-01-10 06:35:20,965 - distributed.worker - INFO -          dashboard at:            127.0.0.1:42429
2024-01-10 06:35:20,965 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2024-01-10 06:35:20,966 - distributed.worker - INFO - -------------------------------------------------
2024-01-10 06:35:20,966 - distributed.worker - INFO -               Threads:                          1
2024-01-10 06:35:20,966 - distributed.worker - INFO -                Memory:                 125.97 GiB
2024-01-10 06:35:20,966 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-vlze19vt
2024-01-10 06:35:20,966 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-7b1ce102-8593-441a-88b3-dcc04fe008dd
2024-01-10 06:35:20,967 - distributed.worker - INFO - Starting Worker plugin PreImport-0aa4ec6a-ca00-442b-99b5-6872ac8dbc5b
2024-01-10 06:35:20,967 - distributed.worker - INFO - Starting Worker plugin RMMSetup-6442ed28-007a-4771-bd2d-c596940ab58e
2024-01-10 06:35:20,985 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2024-01-10 06:35:20,985 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2024-01-10 06:35:20,990 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2024-01-10 06:35:20,990 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:34241
2024-01-10 06:35:20,991 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:34241
2024-01-10 06:35:20,991 - distributed.worker - INFO -          dashboard at:            127.0.0.1:43051
2024-01-10 06:35:20,991 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2024-01-10 06:35:20,991 - distributed.worker - INFO - -------------------------------------------------
2024-01-10 06:35:20,991 - distributed.worker - INFO -               Threads:                          1
2024-01-10 06:35:20,991 - distributed.worker - INFO -                Memory:                 125.97 GiB
2024-01-10 06:35:20,991 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-h0xf9z07
2024-01-10 06:35:20,991 - distributed.worker - INFO - Starting Worker plugin RMMSetup-7b2989b8-01ab-47af-980a-c3c855722223
2024-01-10 06:35:20,993 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2024-01-10 06:35:20,993 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2024-01-10 06:35:21,001 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2024-01-10 06:35:21,003 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:32855
2024-01-10 06:35:21,003 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:32855
2024-01-10 06:35:21,003 - distributed.worker - INFO -          dashboard at:            127.0.0.1:35781
2024-01-10 06:35:21,003 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2024-01-10 06:35:21,003 - distributed.worker - INFO - -------------------------------------------------
2024-01-10 06:35:21,003 - distributed.worker - INFO -               Threads:                          1
2024-01-10 06:35:21,003 - distributed.worker - INFO -                Memory:                 125.97 GiB
2024-01-10 06:35:21,003 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-27mypdmy
2024-01-10 06:35:21,004 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-b9b456da-e88d-456a-8362-f90b78d80fa8
2024-01-10 06:35:21,004 - distributed.worker - INFO - Starting Worker plugin PreImport-908275a9-9b87-4bcc-87f8-5a6145fc1d6a
2024-01-10 06:35:21,004 - distributed.worker - INFO - Starting Worker plugin RMMSetup-c7ff4f31-1a25-42a5-99cd-481729c7173c
2024-01-10 06:35:21,026 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2024-01-10 06:35:21,027 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2024-01-10 06:35:21,031 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2024-01-10 06:35:21,032 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:41027
2024-01-10 06:35:21,032 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:41027
2024-01-10 06:35:21,032 - distributed.worker - INFO -          dashboard at:            127.0.0.1:44765
2024-01-10 06:35:21,032 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2024-01-10 06:35:21,032 - distributed.worker - INFO - -------------------------------------------------
2024-01-10 06:35:21,032 - distributed.worker - INFO -               Threads:                          1
2024-01-10 06:35:21,032 - distributed.worker - INFO -                Memory:                 125.97 GiB
2024-01-10 06:35:21,032 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-wnqv7t9m
2024-01-10 06:35:21,033 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-f45361c5-b44e-41f2-baa0-631b56a4e03b
2024-01-10 06:35:21,033 - distributed.worker - INFO - Starting Worker plugin PreImport-a032d3d5-6a7d-4e5b-bd1f-3dd7ade6ec50
2024-01-10 06:35:21,033 - distributed.worker - INFO - Starting Worker plugin RMMSetup-aeedcbcf-a757-43af-8971-7bb5eabe4bf1
2024-01-10 06:35:21,036 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2024-01-10 06:35:21,036 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2024-01-10 06:35:21,043 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2024-01-10 06:35:21,045 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:44861
2024-01-10 06:35:21,045 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:44861
2024-01-10 06:35:21,045 - distributed.worker - INFO -          dashboard at:            127.0.0.1:32889
2024-01-10 06:35:21,045 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2024-01-10 06:35:21,045 - distributed.worker - INFO - -------------------------------------------------
2024-01-10 06:35:21,046 - distributed.worker - INFO -               Threads:                          1
2024-01-10 06:35:21,046 - distributed.worker - INFO -                Memory:                 125.97 GiB
2024-01-10 06:35:21,046 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-dryksnov
2024-01-10 06:35:21,046 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-6e90be39-c294-481e-8b79-471c8a8bb9cd
2024-01-10 06:35:21,046 - distributed.worker - INFO - Starting Worker plugin PreImport-3d6ce3c9-b372-4015-9f55-dc14057ae431
2024-01-10 06:35:21,047 - distributed.worker - INFO - Starting Worker plugin RMMSetup-64bed271-e834-4efc-8e0d-8ad9266b6f01
2024-01-10 06:35:21,058 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2024-01-10 06:35:21,058 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2024-01-10 06:35:21,064 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2024-01-10 06:35:21,065 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:42883
2024-01-10 06:35:21,065 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:42883
2024-01-10 06:35:21,065 - distributed.worker - INFO -          dashboard at:            127.0.0.1:45193
2024-01-10 06:35:21,065 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2024-01-10 06:35:21,065 - distributed.worker - INFO - -------------------------------------------------
2024-01-10 06:35:21,065 - distributed.worker - INFO -               Threads:                          1
2024-01-10 06:35:21,065 - distributed.worker - INFO -                Memory:                 125.97 GiB
2024-01-10 06:35:21,066 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-kd9417ob
2024-01-10 06:35:21,066 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-d0aceb86-f132-4cb5-865d-1d142dc7e162
2024-01-10 06:35:21,066 - distributed.worker - INFO - Starting Worker plugin PreImport-b1db2d0f-3f10-4a63-aa53-20c04052e60c
2024-01-10 06:35:21,066 - distributed.worker - INFO - Starting Worker plugin RMMSetup-35f50bb6-27f8-4511-a1f1-02d658f3f674
2024-01-10 06:35:22,412 - distributed.scheduler - INFO - Receive client connection: Client-6ae1f84e-af82-11ee-9743-d8c49764f6bb
2024-01-10 06:35:22,428 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:50220
2024-01-10 06:35:23,098 - distributed.worker - INFO - -------------------------------------------------
2024-01-10 06:35:23,113 - distributed.worker - INFO - -------------------------------------------------
2024-01-10 06:35:23,128 - distributed.worker - INFO - Starting Worker plugin PreImport-bb858ac2-e2ad-4ec0-86ef-eae01e707f84
2024-01-10 06:35:23,129 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-ea5105d7-d617-459d-9e1e-62c437f4b6d4
2024-01-10 06:35:23,130 - distributed.worker - INFO - -------------------------------------------------
2024-01-10 06:35:23,134 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:37297', status: init, memory: 0, processing: 0>
2024-01-10 06:35:23,135 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:37297
2024-01-10 06:35:23,135 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:50238
2024-01-10 06:35:23,137 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-01-10 06:35:23,138 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2024-01-10 06:35:23,138 - distributed.worker - INFO - -------------------------------------------------
2024-01-10 06:35:23,138 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:40809', status: init, memory: 0, processing: 0>
2024-01-10 06:35:23,139 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:40809
2024-01-10 06:35:23,139 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:50244
2024-01-10 06:35:23,140 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-01-10 06:35:23,140 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2024-01-10 06:35:23,141 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2024-01-10 06:35:23,141 - distributed.worker - INFO - -------------------------------------------------
2024-01-10 06:35:23,142 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2024-01-10 06:35:23,159 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:34241', status: init, memory: 0, processing: 0>
2024-01-10 06:35:23,160 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:34241
2024-01-10 06:35:23,160 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:50258
2024-01-10 06:35:23,161 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-01-10 06:35:23,162 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2024-01-10 06:35:23,162 - distributed.worker - INFO - -------------------------------------------------
2024-01-10 06:35:23,164 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2024-01-10 06:35:23,169 - distributed.worker - INFO - -------------------------------------------------
2024-01-10 06:35:23,169 - distributed.worker - INFO - Starting Worker plugin PreImport-80b8c926-0fad-4c10-9782-178b83cfbc4d
2024-01-10 06:35:23,171 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-5027934b-4f45-455b-8938-e73f58c53190
2024-01-10 06:35:23,172 - distributed.worker - INFO - -------------------------------------------------
2024-01-10 06:35:23,201 - distributed.worker - INFO - -------------------------------------------------
2024-01-10 06:35:23,204 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:32855', status: init, memory: 0, processing: 0>
2024-01-10 06:35:23,204 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:32855
2024-01-10 06:35:23,204 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:50272
2024-01-10 06:35:23,206 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-01-10 06:35:23,206 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:44373', status: init, memory: 0, processing: 0>
2024-01-10 06:35:23,207 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:44373
2024-01-10 06:35:23,207 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:50280
2024-01-10 06:35:23,207 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2024-01-10 06:35:23,207 - distributed.worker - INFO - -------------------------------------------------
2024-01-10 06:35:23,208 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-01-10 06:35:23,209 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2024-01-10 06:35:23,210 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2024-01-10 06:35:23,210 - distributed.worker - INFO - -------------------------------------------------
2024-01-10 06:35:23,212 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2024-01-10 06:35:23,237 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:44861', status: init, memory: 0, processing: 0>
2024-01-10 06:35:23,237 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:44861
2024-01-10 06:35:23,237 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:50290
2024-01-10 06:35:23,239 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-01-10 06:35:23,240 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2024-01-10 06:35:23,240 - distributed.worker - INFO - -------------------------------------------------
2024-01-10 06:35:23,242 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2024-01-10 06:35:23,244 - distributed.worker - INFO - -------------------------------------------------
2024-01-10 06:35:23,255 - distributed.worker - INFO - -------------------------------------------------
2024-01-10 06:35:23,279 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:41027', status: init, memory: 0, processing: 0>
2024-01-10 06:35:23,280 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:41027
2024-01-10 06:35:23,280 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:50300
2024-01-10 06:35:23,281 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-01-10 06:35:23,283 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2024-01-10 06:35:23,283 - distributed.worker - INFO - -------------------------------------------------
2024-01-10 06:35:23,284 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:42883', status: init, memory: 0, processing: 0>
2024-01-10 06:35:23,284 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:42883
2024-01-10 06:35:23,285 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:50306
2024-01-10 06:35:23,285 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2024-01-10 06:35:23,286 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-01-10 06:35:23,287 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2024-01-10 06:35:23,287 - distributed.worker - INFO - -------------------------------------------------
2024-01-10 06:35:23,289 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2024-01-10 06:35:23,426 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2024-01-10 06:35:23,426 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2024-01-10 06:35:23,426 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2024-01-10 06:35:23,426 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2024-01-10 06:35:23,427 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2024-01-10 06:35:23,427 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2024-01-10 06:35:23,427 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2024-01-10 06:35:23,427 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2024-01-10 06:35:23,432 - distributed.scheduler - INFO - Remove client Client-6ae1f84e-af82-11ee-9743-d8c49764f6bb
2024-01-10 06:35:23,432 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:50220; closing.
2024-01-10 06:35:23,432 - distributed.scheduler - INFO - Remove client Client-6ae1f84e-af82-11ee-9743-d8c49764f6bb
2024-01-10 06:35:23,433 - distributed.scheduler - INFO - Close client connection: Client-6ae1f84e-af82-11ee-9743-d8c49764f6bb
2024-01-10 06:35:23,434 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:41885'. Reason: nanny-close
2024-01-10 06:35:23,434 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2024-01-10 06:35:23,435 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:38309'. Reason: nanny-close
2024-01-10 06:35:23,435 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2024-01-10 06:35:23,435 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:43223'. Reason: nanny-close
2024-01-10 06:35:23,435 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:42883. Reason: nanny-close
2024-01-10 06:35:23,436 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2024-01-10 06:35:23,436 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:35751'. Reason: nanny-close
2024-01-10 06:35:23,436 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:44373. Reason: nanny-close
2024-01-10 06:35:23,436 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2024-01-10 06:35:23,436 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:42335'. Reason: nanny-close
2024-01-10 06:35:23,437 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:34241. Reason: nanny-close
2024-01-10 06:35:23,437 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2024-01-10 06:35:23,437 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:40767'. Reason: nanny-close
2024-01-10 06:35:23,437 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:40809. Reason: nanny-close
2024-01-10 06:35:23,437 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2024-01-10 06:35:23,437 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:41147'. Reason: nanny-close
2024-01-10 06:35:23,437 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:50306; closing.
2024-01-10 06:35:23,437 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2024-01-10 06:35:23,438 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2024-01-10 06:35:23,438 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:32855. Reason: nanny-close
2024-01-10 06:35:23,438 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:42883', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1704868523.4381683')
2024-01-10 06:35:23,438 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:46295'. Reason: nanny-close
2024-01-10 06:35:23,438 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:37297. Reason: nanny-close
2024-01-10 06:35:23,438 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2024-01-10 06:35:23,439 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:41027. Reason: nanny-close
2024-01-10 06:35:23,439 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2024-01-10 06:35:23,439 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:50280; closing.
2024-01-10 06:35:23,439 - distributed.nanny - INFO - Worker closed
2024-01-10 06:35:23,439 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:44861. Reason: nanny-close
2024-01-10 06:35:23,439 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2024-01-10 06:35:23,439 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2024-01-10 06:35:23,440 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:44373', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1704868523.440256')
2024-01-10 06:35:23,440 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:50258; closing.
2024-01-10 06:35:23,440 - distributed.nanny - INFO - Worker closed
2024-01-10 06:35:23,440 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2024-01-10 06:35:23,441 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2024-01-10 06:35:23,441 - distributed.nanny - INFO - Worker closed
2024-01-10 06:35:23,441 - distributed.nanny - INFO - Worker closed
2024-01-10 06:35:23,441 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2024-01-10 06:35:23,442 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2024-01-10 06:35:23,441 - distributed.batched - INFO - Batched Comm Closed <TCP (closed) Scheduler connection to worker local=tcp://127.0.0.1:9369 remote=tcp://127.0.0.1:50280>
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/tcp.py", line 298, in write
    raise StreamClosedError()
tornado.iostream.StreamClosedError: Stream is closed

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/batched.py", line 115, in _background_send
    nbytes = yield coro
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/tornado/gen.py", line 767, in run
    value = future.result()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/tcp.py", line 309, in write
    convert_stream_closed_error(self, e)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/tcp.py", line 142, in convert_stream_closed_error
    raise CommClosedError(f"in {obj}: {exc}") from exc
distributed.comm.core.CommClosedError: in <TCP (closed) Scheduler connection to worker local=tcp://127.0.0.1:9369 remote=tcp://127.0.0.1:50280>: Stream is closed
2024-01-10 06:35:23,442 - distributed.nanny - INFO - Worker closed
2024-01-10 06:35:23,443 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:34241', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1704868523.4430008')
2024-01-10 06:35:23,443 - distributed.nanny - INFO - Worker closed
2024-01-10 06:35:23,443 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:50244; closing.
2024-01-10 06:35:23,443 - distributed.nanny - INFO - Worker closed
2024-01-10 06:35:23,443 - distributed.nanny - INFO - Worker closed
2024-01-10 06:35:23,444 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:40809', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1704868523.4440877')
2024-01-10 06:35:23,444 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:50272; closing.
2024-01-10 06:35:23,444 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:50238; closing.
2024-01-10 06:35:23,445 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:32855', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1704868523.4452965')
2024-01-10 06:35:23,445 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:37297', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1704868523.4455905')
2024-01-10 06:35:23,445 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:50300; closing.
2024-01-10 06:35:23,446 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:50290; closing.
2024-01-10 06:35:23,446 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:41027', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1704868523.4465072')
2024-01-10 06:35:23,447 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:44861', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1704868523.446949')
2024-01-10 06:35:23,447 - distributed.scheduler - INFO - Lost all workers
2024-01-10 06:35:24,450 - distributed._signals - INFO - Received signal SIGINT (2)
2024-01-10 06:35:24,450 - distributed.scheduler - INFO - Scheduler closing due to signal-2...
2024-01-10 06:35:24,451 - distributed.scheduler - INFO - Scheduler closing all comms
2024-01-10 06:35:24,452 - distributed.scheduler - INFO - Stopped scheduler at 'tcp://10.33.227.163:9369'
2024-01-10 06:35:24,452 - distributed.scheduler - INFO - End scheduler
PASSED
dask_cuda/tests/test_dask_cuda_worker.py::test_dashboard_address 2024-01-10 06:35:26,714 - distributed.scheduler - INFO - -----------------------------------------------
2024-01-10 06:35:26,718 - distributed.http.proxy - INFO - To route to workers diagnostics web server please install jupyter-server-proxy: python -m pip install jupyter-server-proxy
2024-01-10 06:35:26,722 - distributed.scheduler - INFO - State start
2024-01-10 06:35:26,746 - distributed.scheduler - INFO - -----------------------------------------------
2024-01-10 06:35:26,747 - distributed.scheduler - INFO -   Scheduler at:  tcp://10.33.227.163:9369
2024-01-10 06:35:26,748 - distributed.scheduler - INFO -   dashboard at:  http://10.33.227.163:8787/status
2024-01-10 06:35:26,749 - distributed.scheduler - INFO - Registering Worker plugin shuffle
2024-01-10 06:35:26,969 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:44317'
2024-01-10 06:35:27,638 - distributed.scheduler - INFO - Receive client connection: Client-6fa238bf-af82-11ee-9743-d8c49764f6bb
2024-01-10 06:35:27,653 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:50416
2024-01-10 06:35:28,996 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2024-01-10 06:35:28,996 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2024-01-10 06:35:29,592 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2024-01-10 06:35:29,593 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:35807
2024-01-10 06:35:29,593 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:35807
2024-01-10 06:35:29,593 - distributed.worker - INFO -          dashboard at:             127.0.0.1:9370
2024-01-10 06:35:29,593 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2024-01-10 06:35:29,593 - distributed.worker - INFO - -------------------------------------------------
2024-01-10 06:35:29,593 - distributed.worker - INFO -               Threads:                          1
2024-01-10 06:35:29,594 - distributed.worker - INFO -                Memory:                   0.98 TiB
2024-01-10 06:35:29,594 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-ok86flns
2024-01-10 06:35:29,594 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-c8613eda-d864-4a0c-8181-d01e3ca0e4fa
2024-01-10 06:35:29,594 - distributed.worker - INFO - Starting Worker plugin RMMSetup-ab67f49d-2932-4275-9c82-a9a795a8c454
2024-01-10 06:35:29,594 - distributed.worker - INFO - Starting Worker plugin PreImport-dc4d1a6f-04a3-4123-8f7a-9295651523b9
2024-01-10 06:35:29,594 - distributed.worker - INFO - -------------------------------------------------
2024-01-10 06:35:29,648 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:35807', status: init, memory: 0, processing: 0>
2024-01-10 06:35:29,650 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:35807
2024-01-10 06:35:29,650 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:50422
2024-01-10 06:35:29,651 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-01-10 06:35:29,652 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2024-01-10 06:35:29,652 - distributed.worker - INFO - -------------------------------------------------
2024-01-10 06:35:29,653 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2024-01-10 06:35:29,716 - distributed.worker - INFO - Run out-of-band function 'lambda'
2024-01-10 06:35:29,719 - distributed.scheduler - INFO - Remove client Client-6fa238bf-af82-11ee-9743-d8c49764f6bb
2024-01-10 06:35:29,719 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:50416; closing.
2024-01-10 06:35:29,720 - distributed.scheduler - INFO - Remove client Client-6fa238bf-af82-11ee-9743-d8c49764f6bb
2024-01-10 06:35:29,720 - distributed.scheduler - INFO - Close client connection: Client-6fa238bf-af82-11ee-9743-d8c49764f6bb
2024-01-10 06:35:29,721 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:44317'. Reason: nanny-close
2024-01-10 06:35:29,721 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2024-01-10 06:35:29,722 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:35807. Reason: nanny-close
2024-01-10 06:35:29,724 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2024-01-10 06:35:29,724 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:50422; closing.
2024-01-10 06:35:29,724 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:35807', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1704868529.7247934')
2024-01-10 06:35:29,725 - distributed.scheduler - INFO - Lost all workers
2024-01-10 06:35:29,725 - distributed.nanny - INFO - Worker closed
2024-01-10 06:35:30,386 - distributed._signals - INFO - Received signal SIGINT (2)
2024-01-10 06:35:30,387 - distributed.scheduler - INFO - Scheduler closing due to signal-2...
2024-01-10 06:35:30,387 - distributed.scheduler - INFO - Scheduler closing all comms
2024-01-10 06:35:30,388 - distributed.scheduler - INFO - Stopped scheduler at 'tcp://10.33.227.163:9369'
2024-01-10 06:35:30,389 - distributed.scheduler - INFO - End scheduler
PASSED
dask_cuda/tests/test_dask_cuda_worker.py::test_unknown_argument PASSED
dask_cuda/tests/test_dask_cuda_worker.py::test_pre_import 2024-01-10 06:35:34,899 - distributed.scheduler - INFO - -----------------------------------------------
2024-01-10 06:35:34,903 - distributed.http.proxy - INFO - To route to workers diagnostics web server please install jupyter-server-proxy: python -m pip install jupyter-server-proxy
/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 38919 instead
  warnings.warn(
2024-01-10 06:35:34,908 - distributed.scheduler - INFO - State start
2024-01-10 06:35:34,932 - distributed.scheduler - INFO - -----------------------------------------------
2024-01-10 06:35:34,933 - distributed.scheduler - INFO -   Scheduler at:  tcp://10.33.227.163:9369
2024-01-10 06:35:34,933 - distributed.scheduler - INFO -   dashboard at:  http://10.33.227.163:38919/status
2024-01-10 06:35:34,933 - distributed.scheduler - INFO - Registering Worker plugin shuffle
2024-01-10 06:35:35,016 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:36385'
2024-01-10 06:35:35,067 - distributed.scheduler - INFO - Receive client connection: Client-747a0cb1-af82-11ee-9743-d8c49764f6bb
2024-01-10 06:35:35,083 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:35508
2024-01-10 06:35:36,792 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2024-01-10 06:35:36,792 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2024-01-10 06:35:37,360 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2024-01-10 06:35:37,361 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:37639
2024-01-10 06:35:37,361 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:37639
2024-01-10 06:35:37,361 - distributed.worker - INFO -          dashboard at:            127.0.0.1:36717
2024-01-10 06:35:37,361 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2024-01-10 06:35:37,361 - distributed.worker - INFO - -------------------------------------------------
2024-01-10 06:35:37,361 - distributed.worker - INFO -               Threads:                          1
2024-01-10 06:35:37,361 - distributed.worker - INFO -                Memory:                   0.98 TiB
2024-01-10 06:35:37,361 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-lmj2r8sc
2024-01-10 06:35:37,362 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-f646b6e9-601f-40f7-9eed-41116f35d306
2024-01-10 06:35:37,362 - distributed.worker - INFO - Starting Worker plugin RMMSetup-9e17ba17-5d84-48ad-a9f2-8ee8cf5d50d6
2024-01-10 06:35:37,362 - distributed.worker - INFO - Starting Worker plugin PreImport-aac5d2f1-4d19-4df3-a7af-f8f5c8a20003
2024-01-10 06:35:37,363 - distributed.worker - INFO - -------------------------------------------------
2024-01-10 06:35:37,417 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:37639', status: init, memory: 0, processing: 0>
2024-01-10 06:35:37,419 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:37639
2024-01-10 06:35:37,419 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:35526
2024-01-10 06:35:37,420 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-01-10 06:35:37,420 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2024-01-10 06:35:37,420 - distributed.worker - INFO - -------------------------------------------------
2024-01-10 06:35:37,421 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2024-01-10 06:35:37,492 - distributed.worker - INFO - Run out-of-band function 'lambda'
2024-01-10 06:35:37,495 - distributed.scheduler - INFO - Remove client Client-747a0cb1-af82-11ee-9743-d8c49764f6bb
2024-01-10 06:35:37,495 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:35508; closing.
2024-01-10 06:35:37,495 - distributed.scheduler - INFO - Remove client Client-747a0cb1-af82-11ee-9743-d8c49764f6bb
2024-01-10 06:35:37,496 - distributed.scheduler - INFO - Close client connection: Client-747a0cb1-af82-11ee-9743-d8c49764f6bb
2024-01-10 06:35:37,496 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:36385'. Reason: nanny-close
2024-01-10 06:35:37,497 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2024-01-10 06:35:37,497 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:37639. Reason: nanny-close
2024-01-10 06:35:37,499 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2024-01-10 06:35:37,499 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:35526; closing.
2024-01-10 06:35:37,499 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:37639', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1704868537.499851')
2024-01-10 06:35:37,500 - distributed.scheduler - INFO - Lost all workers
2024-01-10 06:35:37,500 - distributed.nanny - INFO - Worker closed
2024-01-10 06:35:38,061 - distributed._signals - INFO - Received signal SIGINT (2)
2024-01-10 06:35:38,062 - distributed.scheduler - INFO - Scheduler closing due to signal-2...
2024-01-10 06:35:38,063 - distributed.scheduler - INFO - Scheduler closing all comms
2024-01-10 06:35:38,064 - distributed.scheduler - INFO - Stopped scheduler at 'tcp://10.33.227.163:9369'
2024-01-10 06:35:38,064 - distributed.scheduler - INFO - End scheduler
PASSED
dask_cuda/tests/test_dask_cuda_worker.py::test_pre_import_not_found 2024-01-10 06:35:40,307 - distributed.scheduler - INFO - -----------------------------------------------
2024-01-10 06:35:40,312 - distributed.http.proxy - INFO - To route to workers diagnostics web server please install jupyter-server-proxy: python -m pip install jupyter-server-proxy
/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 39571 instead
  warnings.warn(
2024-01-10 06:35:40,315 - distributed.scheduler - INFO - State start
2024-01-10 06:35:40,361 - distributed.scheduler - INFO - -----------------------------------------------
2024-01-10 06:35:40,362 - distributed.scheduler - INFO -   Scheduler at:  tcp://10.33.227.163:9369
2024-01-10 06:35:40,363 - distributed.scheduler - INFO -   dashboard at:  http://10.33.227.163:39571/status
2024-01-10 06:35:40,363 - distributed.scheduler - INFO - Registering Worker plugin shuffle
2024-01-10 06:35:42,989 - distributed.core - INFO - Lost connection to 'tcp://127.0.0.1:43822'
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/tcp.py", line 225, in read
    frames_nosplit_nbytes_bin = await stream.read_bytes(fmt_size)
tornado.iostream.StreamClosedError: Stream is closed

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 969, in _handle_comm
    result = await result
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/scheduler.py", line 4428, in add_nanny
    await comm.read()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/tcp.py", line 237, in read
    convert_stream_closed_error(self, e)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/tcp.py", line 142, in convert_stream_closed_error
    raise CommClosedError(f"in {obj}: {exc}") from exc
distributed.comm.core.CommClosedError: in <TCP (closed)  local=tcp://127.0.0.1:9369 remote=tcp://127.0.0.1:43822>: Stream is closed
2024-01-10 06:35:43,254 - distributed._signals - INFO - Received signal SIGINT (2)
2024-01-10 06:35:43,255 - distributed.scheduler - INFO - Scheduler closing due to signal-2...
2024-01-10 06:35:43,255 - distributed.scheduler - INFO - Scheduler closing all comms
2024-01-10 06:35:43,256 - distributed.scheduler - INFO - Stopped scheduler at 'tcp://10.33.227.163:9369'
2024-01-10 06:35:43,256 - distributed.scheduler - INFO - End scheduler
PASSED
dask_cuda/tests/test_dask_cuda_worker.py::test_cuda_mig_visible_devices_and_memory_limit_and_nthreads SKIPPED
dask_cuda/tests/test_dask_cuda_worker.py::test_cuda_visible_devices_uuid 2024-01-10 06:35:45,585 - distributed.scheduler - INFO - -----------------------------------------------
2024-01-10 06:35:45,590 - distributed.http.proxy - INFO - To route to workers diagnostics web server please install jupyter-server-proxy: python -m pip install jupyter-server-proxy
/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 39051 instead
  warnings.warn(
2024-01-10 06:35:45,594 - distributed.scheduler - INFO - State start
2024-01-10 06:35:45,676 - distributed.scheduler - INFO - -----------------------------------------------
2024-01-10 06:35:45,677 - distributed.scheduler - INFO -   Scheduler at:  tcp://10.33.227.163:9359
2024-01-10 06:35:45,677 - distributed.scheduler - INFO -   dashboard at:  http://10.33.227.163:39051/status
2024-01-10 06:35:45,678 - distributed.scheduler - INFO - Registering Worker plugin shuffle
2024-01-10 06:35:46,021 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:40149'
2024-01-10 06:35:46,692 - distributed.scheduler - INFO - Receive client connection: Client-7ad7a2c0-af82-11ee-9743-d8c49764f6bb
2024-01-10 06:35:46,710 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:47512
2024-01-10 06:35:47,851 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2024-01-10 06:35:47,851 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2024-01-10 06:35:47,855 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2024-01-10 06:35:47,856 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:42231
2024-01-10 06:35:47,856 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:42231
2024-01-10 06:35:47,856 - distributed.worker - INFO -          dashboard at:            127.0.0.1:38289
2024-01-10 06:35:47,856 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9359
2024-01-10 06:35:47,856 - distributed.worker - INFO - -------------------------------------------------
2024-01-10 06:35:47,856 - distributed.worker - INFO -               Threads:                          1
2024-01-10 06:35:47,856 - distributed.worker - INFO -                Memory:                   0.98 TiB
2024-01-10 06:35:47,856 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/mockworker-tt74y73y
2024-01-10 06:35:47,856 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-a45c75bc-4908-4de0-b3d9-602c94a6e1dd
2024-01-10 06:35:47,857 - distributed.worker - INFO - Starting Worker plugin PreImport-686df1e6-c6d4-4eac-ba78-4f3c17ef9533
2024-01-10 06:35:47,857 - distributed.worker - INFO - Starting Worker plugin RMMSetup-0f320410-b3e9-49f4-a1e7-a2da5aaed150
2024-01-10 06:35:47,857 - distributed.worker - INFO - -------------------------------------------------
2024-01-10 06:35:47,911 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:42231', status: init, memory: 0, processing: 0>
2024-01-10 06:35:47,912 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:42231
2024-01-10 06:35:47,912 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:47522
2024-01-10 06:35:47,913 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-01-10 06:35:47,914 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9359
2024-01-10 06:35:47,914 - distributed.worker - INFO - -------------------------------------------------
2024-01-10 06:35:47,916 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9359
2024-01-10 06:35:47,939 - distributed.worker - INFO - Run out-of-band function 'lambda'
2024-01-10 06:35:47,942 - distributed.scheduler - INFO - Remove client Client-7ad7a2c0-af82-11ee-9743-d8c49764f6bb
2024-01-10 06:35:47,942 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:47512; closing.
2024-01-10 06:35:47,942 - distributed.scheduler - INFO - Remove client Client-7ad7a2c0-af82-11ee-9743-d8c49764f6bb
2024-01-10 06:35:47,943 - distributed.scheduler - INFO - Close client connection: Client-7ad7a2c0-af82-11ee-9743-d8c49764f6bb
2024-01-10 06:35:47,944 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:40149'. Reason: nanny-close
2024-01-10 06:35:47,958 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2024-01-10 06:35:47,959 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:42231. Reason: nanny-close
2024-01-10 06:35:47,961 - distributed.core - INFO - Connection to tcp://127.0.0.1:9359 has been closed.
2024-01-10 06:35:47,961 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:47522; closing.
2024-01-10 06:35:47,961 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:42231', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1704868547.9615135')
2024-01-10 06:35:47,962 - distributed.scheduler - INFO - Lost all workers
2024-01-10 06:35:47,962 - distributed.nanny - INFO - Worker closed
2024-01-10 06:35:48,559 - distributed._signals - INFO - Received signal SIGINT (2)
2024-01-10 06:35:48,559 - distributed.scheduler - INFO - Scheduler closing due to signal-2...
2024-01-10 06:35:48,560 - distributed.scheduler - INFO - Scheduler closing all comms
2024-01-10 06:35:48,561 - distributed.scheduler - INFO - Stopped scheduler at 'tcp://10.33.227.163:9359'
2024-01-10 06:35:48,562 - distributed.scheduler - INFO - End scheduler
PASSED
dask_cuda/tests/test_dask_cuda_worker.py::test_rmm_track_allocations 2024-01-10 06:35:50,892 - distributed.scheduler - INFO - -----------------------------------------------
2024-01-10 06:35:50,897 - distributed.http.proxy - INFO - To route to workers diagnostics web server please install jupyter-server-proxy: python -m pip install jupyter-server-proxy
/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 35289 instead
  warnings.warn(
2024-01-10 06:35:50,901 - distributed.scheduler - INFO - State start
2024-01-10 06:35:50,925 - distributed.scheduler - INFO - -----------------------------------------------
2024-01-10 06:35:50,926 - distributed.scheduler - INFO -   Scheduler at:  tcp://10.33.227.163:9369
2024-01-10 06:35:50,927 - distributed.scheduler - INFO -   dashboard at:  http://10.33.227.163:35289/status
2024-01-10 06:35:50,928 - distributed.scheduler - INFO - Registering Worker plugin shuffle
2024-01-10 06:35:51,152 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:33077'
2024-01-10 06:35:51,169 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:35369'
2024-01-10 06:35:51,177 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:39843'
2024-01-10 06:35:51,194 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:35315'
2024-01-10 06:35:51,197 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:35395'
2024-01-10 06:35:51,206 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:33291'
2024-01-10 06:35:51,215 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:37363'
2024-01-10 06:35:51,224 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:37961'
2024-01-10 06:35:52,667 - distributed.scheduler - INFO - Receive client connection: Client-7e071a43-af82-11ee-9743-d8c49764f6bb
2024-01-10 06:35:52,681 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:37808
2024-01-10 06:35:53,049 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2024-01-10 06:35:53,049 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2024-01-10 06:35:53,053 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2024-01-10 06:35:53,054 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:34781
2024-01-10 06:35:53,054 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:34781
2024-01-10 06:35:53,054 - distributed.worker - INFO -          dashboard at:            127.0.0.1:38749
2024-01-10 06:35:53,054 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2024-01-10 06:35:53,054 - distributed.worker - INFO - -------------------------------------------------
2024-01-10 06:35:53,054 - distributed.worker - INFO -               Threads:                          1
2024-01-10 06:35:53,054 - distributed.worker - INFO -                Memory:                 125.97 GiB
2024-01-10 06:35:53,054 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-tyz99u7l
2024-01-10 06:35:53,054 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-b534e79f-a948-4e72-829a-088a9404dc78
2024-01-10 06:35:53,055 - distributed.worker - INFO - Starting Worker plugin PreImport-e3c484fa-fcee-435e-bb1c-c27dc43837d8
2024-01-10 06:35:53,055 - distributed.worker - INFO - Starting Worker plugin RMMSetup-5fca574e-5b54-49fb-863b-eb65a4d6e765
2024-01-10 06:35:53,069 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2024-01-10 06:35:53,069 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2024-01-10 06:35:53,073 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2024-01-10 06:35:53,074 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:40227
2024-01-10 06:35:53,074 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:40227
2024-01-10 06:35:53,074 - distributed.worker - INFO -          dashboard at:            127.0.0.1:33949
2024-01-10 06:35:53,074 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2024-01-10 06:35:53,074 - distributed.worker - INFO - -------------------------------------------------
2024-01-10 06:35:53,074 - distributed.worker - INFO -               Threads:                          1
2024-01-10 06:35:53,074 - distributed.worker - INFO -                Memory:                 125.97 GiB
2024-01-10 06:35:53,074 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-mukcusyz
2024-01-10 06:35:53,075 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-56165e85-29d6-40ff-a4a1-34c5d1c2d1ce
2024-01-10 06:35:53,075 - distributed.worker - INFO - Starting Worker plugin PreImport-fdfd2c06-03a2-4a3f-a2d6-5cca31d68d40
2024-01-10 06:35:53,075 - distributed.worker - INFO - Starting Worker plugin RMMSetup-eac58748-1d23-4639-9cc7-6ea7bd268e6d
2024-01-10 06:35:53,122 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2024-01-10 06:35:53,122 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2024-01-10 06:35:53,122 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2024-01-10 06:35:53,122 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2024-01-10 06:35:53,126 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2024-01-10 06:35:53,126 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2024-01-10 06:35:53,127 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:40841
2024-01-10 06:35:53,127 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:40841
2024-01-10 06:35:53,127 - distributed.worker - INFO -          dashboard at:            127.0.0.1:43955
2024-01-10 06:35:53,127 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2024-01-10 06:35:53,127 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:40327
2024-01-10 06:35:53,127 - distributed.worker - INFO - -------------------------------------------------
2024-01-10 06:35:53,127 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:40327
2024-01-10 06:35:53,127 - distributed.worker - INFO -               Threads:                          1
2024-01-10 06:35:53,127 - distributed.worker - INFO -          dashboard at:            127.0.0.1:46491
2024-01-10 06:35:53,127 - distributed.worker - INFO -                Memory:                 125.97 GiB
2024-01-10 06:35:53,128 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2024-01-10 06:35:53,128 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-cgaad2r7
2024-01-10 06:35:53,128 - distributed.worker - INFO - -------------------------------------------------
2024-01-10 06:35:53,128 - distributed.worker - INFO -               Threads:                          1
2024-01-10 06:35:53,128 - distributed.worker - INFO -                Memory:                 125.97 GiB
2024-01-10 06:35:53,128 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-ggqiw41m
2024-01-10 06:35:53,128 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-b0841d63-52f7-4e6a-904a-f62d29cb9876
2024-01-10 06:35:53,128 - distributed.worker - INFO - Starting Worker plugin RMMSetup-deddedee-22b3-4169-afd5-dacd7bc81330
2024-01-10 06:35:53,128 - distributed.worker - INFO - Starting Worker plugin PreImport-64352d40-7b95-43ba-8a0e-e5a6946f1099
2024-01-10 06:35:53,128 - distributed.worker - INFO - Starting Worker plugin RMMSetup-30d3a2a9-890b-4e69-a81c-7a5273d1374a
2024-01-10 06:35:53,129 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2024-01-10 06:35:53,129 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2024-01-10 06:35:53,131 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2024-01-10 06:35:53,131 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2024-01-10 06:35:53,133 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2024-01-10 06:35:53,134 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:42137
2024-01-10 06:35:53,134 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:42137
2024-01-10 06:35:53,134 - distributed.worker - INFO -          dashboard at:            127.0.0.1:38263
2024-01-10 06:35:53,134 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2024-01-10 06:35:53,134 - distributed.worker - INFO - -------------------------------------------------
2024-01-10 06:35:53,135 - distributed.worker - INFO -               Threads:                          1
2024-01-10 06:35:53,135 - distributed.worker - INFO -                Memory:                 125.97 GiB
2024-01-10 06:35:53,135 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-6d5ejyub
2024-01-10 06:35:53,135 - distributed.worker - INFO - Starting Worker plugin RMMSetup-3ed155ed-46c6-4e86-a318-f2047b1084b4
2024-01-10 06:35:53,135 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2024-01-10 06:35:53,136 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:37225
2024-01-10 06:35:53,136 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:37225
2024-01-10 06:35:53,136 - distributed.worker - INFO -          dashboard at:            127.0.0.1:34091
2024-01-10 06:35:53,137 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2024-01-10 06:35:53,137 - distributed.worker - INFO - -------------------------------------------------
2024-01-10 06:35:53,137 - distributed.worker - INFO -               Threads:                          1
2024-01-10 06:35:53,137 - distributed.worker - INFO -                Memory:                 125.97 GiB
2024-01-10 06:35:53,137 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-_cy30ec6
2024-01-10 06:35:53,137 - distributed.worker - INFO - Starting Worker plugin RMMSetup-4cc61b6a-d425-43b5-94a2-b8a774da44ed
2024-01-10 06:35:53,375 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2024-01-10 06:35:53,375 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2024-01-10 06:35:53,379 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2024-01-10 06:35:53,379 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2024-01-10 06:35:53,380 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2024-01-10 06:35:53,381 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:43737
2024-01-10 06:35:53,381 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:43737
2024-01-10 06:35:53,381 - distributed.worker - INFO -          dashboard at:            127.0.0.1:41833
2024-01-10 06:35:53,381 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2024-01-10 06:35:53,381 - distributed.worker - INFO - -------------------------------------------------
2024-01-10 06:35:53,381 - distributed.worker - INFO -               Threads:                          1
2024-01-10 06:35:53,381 - distributed.worker - INFO -                Memory:                 125.97 GiB
2024-01-10 06:35:53,381 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-ou8i1v9q
2024-01-10 06:35:53,381 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-e0581ca2-9cf6-4650-91d5-a4c659ebcaf0
2024-01-10 06:35:53,381 - distributed.worker - INFO - Starting Worker plugin PreImport-4a925a42-dbcc-459e-8ade-02f79bd44063
2024-01-10 06:35:53,382 - distributed.worker - INFO - Starting Worker plugin RMMSetup-a19acdfd-3902-4930-b951-be25a1b2fa0a
2024-01-10 06:35:53,384 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2024-01-10 06:35:53,385 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:33313
2024-01-10 06:35:53,385 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:33313
2024-01-10 06:35:53,385 - distributed.worker - INFO -          dashboard at:            127.0.0.1:35959
2024-01-10 06:35:53,385 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2024-01-10 06:35:53,385 - distributed.worker - INFO - -------------------------------------------------
2024-01-10 06:35:53,385 - distributed.worker - INFO -               Threads:                          1
2024-01-10 06:35:53,385 - distributed.worker - INFO -                Memory:                 125.97 GiB
2024-01-10 06:35:53,385 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-9c4tig0t
2024-01-10 06:35:53,385 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-fed9f84b-3c5f-43c5-9d08-645f216399d3
2024-01-10 06:35:53,387 - distributed.worker - INFO - Starting Worker plugin RMMSetup-62b40c45-d2ac-4850-823c-fa287ff6711f
2024-01-10 06:35:54,685 - distributed.worker - INFO - -------------------------------------------------
2024-01-10 06:35:54,705 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:34781', status: init, memory: 0, processing: 0>
2024-01-10 06:35:54,707 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:34781
2024-01-10 06:35:54,707 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:37838
2024-01-10 06:35:54,708 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-01-10 06:35:54,709 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2024-01-10 06:35:54,709 - distributed.worker - INFO - -------------------------------------------------
2024-01-10 06:35:54,710 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2024-01-10 06:35:57,018 - distributed.worker - INFO - -------------------------------------------------
2024-01-10 06:35:57,040 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:40227', status: init, memory: 0, processing: 0>
2024-01-10 06:35:57,041 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:40227
2024-01-10 06:35:57,041 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:37866
2024-01-10 06:35:57,042 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-01-10 06:35:57,043 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2024-01-10 06:35:57,043 - distributed.worker - INFO - -------------------------------------------------
2024-01-10 06:35:57,044 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2024-01-10 06:35:57,267 - distributed.worker - INFO - Starting Worker plugin PreImport-2a668178-f34a-43bb-aa89-5a086fa49213
2024-01-10 06:35:57,269 - distributed.worker - INFO - -------------------------------------------------
2024-01-10 06:35:57,274 - distributed.worker - INFO - -------------------------------------------------
2024-01-10 06:35:57,298 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:33313', status: init, memory: 0, processing: 0>
2024-01-10 06:35:57,299 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:33313
2024-01-10 06:35:57,299 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:37870
2024-01-10 06:35:57,300 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-01-10 06:35:57,301 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2024-01-10 06:35:57,301 - distributed.worker - INFO - -------------------------------------------------
2024-01-10 06:35:57,303 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2024-01-10 06:35:57,308 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:40841', status: init, memory: 0, processing: 0>
2024-01-10 06:35:57,309 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:40841
2024-01-10 06:35:57,309 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:37884
2024-01-10 06:35:57,310 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-01-10 06:35:57,311 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2024-01-10 06:35:57,312 - distributed.worker - INFO - -------------------------------------------------
2024-01-10 06:35:57,314 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2024-01-10 06:35:57,324 - distributed.worker - INFO - Starting Worker plugin PreImport-cca4231c-2ce0-4138-bcd3-06ab22862fd7
2024-01-10 06:35:57,325 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-9b2504ca-29b0-4e11-830b-fedd2e2dad87
2024-01-10 06:35:57,325 - distributed.worker - INFO - -------------------------------------------------
2024-01-10 06:35:57,358 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:37225', status: init, memory: 0, processing: 0>
2024-01-10 06:35:57,359 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:37225
2024-01-10 06:35:57,359 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:37888
2024-01-10 06:35:57,361 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-01-10 06:35:57,362 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2024-01-10 06:35:57,362 - distributed.worker - INFO - -------------------------------------------------
2024-01-10 06:35:57,365 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2024-01-10 06:35:57,379 - distributed.worker - INFO - Starting Worker plugin PreImport-6e9b682d-d02d-4cb1-9f47-2e65acd6efd7
2024-01-10 06:35:57,380 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-2db77d7c-9c19-40b2-8405-fb226374219d
2024-01-10 06:35:57,381 - distributed.worker - INFO - -------------------------------------------------
2024-01-10 06:35:57,401 - distributed.worker - INFO - Starting Worker plugin PreImport-249375cd-296a-439f-8488-ebfe96b0d68d
2024-01-10 06:35:57,402 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-eafef3a2-46d0-47b6-8eba-7077ebf2e195
2024-01-10 06:35:57,402 - distributed.worker - INFO - -------------------------------------------------
2024-01-10 06:35:57,412 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:40327', status: init, memory: 0, processing: 0>
2024-01-10 06:35:57,413 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:40327
2024-01-10 06:35:57,413 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:37894
2024-01-10 06:35:57,415 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-01-10 06:35:57,416 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2024-01-10 06:35:57,416 - distributed.worker - INFO - -------------------------------------------------
2024-01-10 06:35:57,418 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2024-01-10 06:35:57,423 - distributed.worker - INFO - -------------------------------------------------
2024-01-10 06:35:57,425 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:42137', status: init, memory: 0, processing: 0>
2024-01-10 06:35:57,426 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:42137
2024-01-10 06:35:57,426 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:37896
2024-01-10 06:35:57,427 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-01-10 06:35:57,428 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2024-01-10 06:35:57,428 - distributed.worker - INFO - -------------------------------------------------
2024-01-10 06:35:57,429 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2024-01-10 06:35:57,446 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:43737', status: init, memory: 0, processing: 0>
2024-01-10 06:35:57,447 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:43737
2024-01-10 06:35:57,448 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:37902
2024-01-10 06:35:57,448 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-01-10 06:35:57,450 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2024-01-10 06:35:57,450 - distributed.worker - INFO - -------------------------------------------------
2024-01-10 06:35:57,451 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2024-01-10 06:35:57,512 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2024-01-10 06:35:57,513 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2024-01-10 06:35:57,513 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2024-01-10 06:35:57,513 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2024-01-10 06:35:57,513 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2024-01-10 06:35:57,513 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2024-01-10 06:35:57,513 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2024-01-10 06:35:57,514 - distributed.worker - INFO - Run out-of-band function 'get_current_device_resource_type'
2024-01-10 06:35:57,528 - distributed.worker - INFO - Run out-of-band function 'lambda'
2024-01-10 06:35:57,529 - distributed.worker - INFO - Run out-of-band function 'lambda'
2024-01-10 06:35:57,529 - distributed.worker - INFO - Run out-of-band function 'lambda'
2024-01-10 06:35:57,529 - distributed.worker - INFO - Run out-of-band function 'lambda'
2024-01-10 06:35:57,529 - distributed.worker - INFO - Run out-of-band function 'lambda'
2024-01-10 06:35:57,529 - distributed.worker - INFO - Run out-of-band function 'lambda'
2024-01-10 06:35:57,529 - distributed.worker - INFO - Run out-of-band function 'lambda'
2024-01-10 06:35:57,529 - distributed.worker - INFO - Run out-of-band function 'lambda'
2024-01-10 06:35:57,535 - distributed.scheduler - INFO - Remove client Client-7e071a43-af82-11ee-9743-d8c49764f6bb
2024-01-10 06:35:57,535 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:37808; closing.
2024-01-10 06:35:57,535 - distributed.scheduler - INFO - Remove client Client-7e071a43-af82-11ee-9743-d8c49764f6bb
2024-01-10 06:35:57,536 - distributed.scheduler - INFO - Close client connection: Client-7e071a43-af82-11ee-9743-d8c49764f6bb
2024-01-10 06:35:57,537 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:33077'. Reason: nanny-close
2024-01-10 06:35:57,537 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2024-01-10 06:35:57,537 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:35369'. Reason: nanny-close
2024-01-10 06:35:57,538 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2024-01-10 06:35:57,538 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:39843'. Reason: nanny-close
2024-01-10 06:35:57,538 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:34781. Reason: nanny-close
2024-01-10 06:35:57,539 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2024-01-10 06:35:57,539 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:35315'. Reason: nanny-close
2024-01-10 06:35:57,539 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:40227. Reason: nanny-close
2024-01-10 06:35:57,539 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2024-01-10 06:35:57,539 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:35395'. Reason: nanny-close
2024-01-10 06:35:57,539 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:40841. Reason: nanny-close
2024-01-10 06:35:57,539 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2024-01-10 06:35:57,540 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:33291'. Reason: nanny-close
2024-01-10 06:35:57,540 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:37225. Reason: nanny-close
2024-01-10 06:35:57,540 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2024-01-10 06:35:57,540 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:37363'. Reason: nanny-close
2024-01-10 06:35:57,540 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:42137. Reason: nanny-close
2024-01-10 06:35:57,540 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2024-01-10 06:35:57,540 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:37838; closing.
2024-01-10 06:35:57,540 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2024-01-10 06:35:57,540 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:37961'. Reason: nanny-close
2024-01-10 06:35:57,540 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2024-01-10 06:35:57,541 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:43737. Reason: nanny-close
2024-01-10 06:35:57,541 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2024-01-10 06:35:57,541 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:34781', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1704868557.541204')
2024-01-10 06:35:57,541 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:40327. Reason: nanny-close
2024-01-10 06:35:57,542 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2024-01-10 06:35:57,542 - distributed.nanny - INFO - Worker closed
2024-01-10 06:35:57,542 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:33313. Reason: nanny-close
2024-01-10 06:35:57,542 - distributed.nanny - INFO - Worker closed
2024-01-10 06:35:57,542 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2024-01-10 06:35:57,542 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:37884; closing.
2024-01-10 06:35:57,542 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2024-01-10 06:35:57,542 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2024-01-10 06:35:57,542 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:37866; closing.
2024-01-10 06:35:57,543 - distributed.nanny - INFO - Worker closed
2024-01-10 06:35:57,544 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2024-01-10 06:35:57,544 - distributed.nanny - INFO - Worker closed
2024-01-10 06:35:57,544 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:40841', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1704868557.5440154')
2024-01-10 06:35:57,544 - distributed.nanny - INFO - Worker closed
2024-01-10 06:35:57,544 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:40227', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1704868557.544514')
2024-01-10 06:35:57,544 - distributed.nanny - INFO - Worker closed
2024-01-10 06:35:57,545 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2024-01-10 06:35:57,545 - distributed.nanny - INFO - Worker closed
2024-01-10 06:35:57,546 - distributed.nanny - INFO - Worker closed
2024-01-10 06:35:57,545 - distributed.batched - INFO - Batched Comm Closed <TCP (closed) Scheduler connection to worker local=tcp://127.0.0.1:9369 remote=tcp://127.0.0.1:37884>
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/tcp.py", line 298, in write
    raise StreamClosedError()
tornado.iostream.StreamClosedError: Stream is closed

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/batched.py", line 115, in _background_send
    nbytes = yield coro
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/tornado/gen.py", line 767, in run
    value = future.result()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/tcp.py", line 309, in write
    convert_stream_closed_error(self, e)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/tcp.py", line 142, in convert_stream_closed_error
    raise CommClosedError(f"in {obj}: {exc}") from exc
distributed.comm.core.CommClosedError: in <TCP (closed) Scheduler connection to worker local=tcp://127.0.0.1:9369 remote=tcp://127.0.0.1:37884>: Stream is closed
2024-01-10 06:35:57,548 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:37888; closing.
2024-01-10 06:35:57,548 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:37896; closing.
2024-01-10 06:35:57,548 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:37902; closing.
2024-01-10 06:35:57,549 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:37225', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1704868557.5491092')
2024-01-10 06:35:57,549 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:42137', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1704868557.5495641')
2024-01-10 06:35:57,550 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:43737', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1704868557.5500944')
2024-01-10 06:35:57,550 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:37894; closing.
2024-01-10 06:35:57,551 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:40327', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1704868557.5513415')
2024-01-10 06:35:57,551 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:37870; closing.
2024-01-10 06:35:57,552 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:33313', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1704868557.552391')
2024-01-10 06:35:57,552 - distributed.scheduler - INFO - Lost all workers
2024-01-10 06:35:57,552 - distributed.batched - INFO - Batched Comm Closed <TCP (closed) Scheduler connection to worker local=tcp://127.0.0.1:9369 remote=tcp://127.0.0.1:37870>
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/batched.py", line 115, in _background_send
    nbytes = yield coro
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/tornado/gen.py", line 767, in run
    value = future.result()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/comm/tcp.py", line 263, in write
    raise CommClosedError()
distributed.comm.core.CommClosedError
2024-01-10 06:35:58,803 - distributed._signals - INFO - Received signal SIGINT (2)
2024-01-10 06:35:58,804 - distributed.scheduler - INFO - Scheduler closing due to signal-2...
2024-01-10 06:35:58,804 - distributed.scheduler - INFO - Scheduler closing all comms
2024-01-10 06:35:58,806 - distributed.scheduler - INFO - Stopped scheduler at 'tcp://10.33.227.163:9369'
2024-01-10 06:35:58,806 - distributed.scheduler - INFO - End scheduler
PASSED
dask_cuda/tests/test_dask_cuda_worker.py::test_get_cluster_configuration 2024-01-10 06:36:01,266 - distributed.scheduler - INFO - -----------------------------------------------
2024-01-10 06:36:01,271 - distributed.http.proxy - INFO - To route to workers diagnostics web server please install jupyter-server-proxy: python -m pip install jupyter-server-proxy
/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 34987 instead
  warnings.warn(
2024-01-10 06:36:01,275 - distributed.scheduler - INFO - State start
2024-01-10 06:36:01,389 - distributed.scheduler - INFO - -----------------------------------------------
2024-01-10 06:36:01,390 - distributed.scheduler - INFO -   Scheduler at:  tcp://10.33.227.163:9369
2024-01-10 06:36:01,391 - distributed.scheduler - INFO -   dashboard at:  http://10.33.227.163:34987/status
2024-01-10 06:36:01,391 - distributed.scheduler - INFO - Registering Worker plugin shuffle
2024-01-10 06:36:01,532 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:44301'
2024-01-10 06:36:03,144 - distributed.scheduler - INFO - Receive client connection: Client-842cc7d1-af82-11ee-9743-d8c49764f6bb
2024-01-10 06:36:03,157 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:39930
2024-01-10 06:36:03,346 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2024-01-10 06:36:03,347 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2024-01-10 06:36:03,351 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2024-01-10 06:36:03,351 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:41961
2024-01-10 06:36:03,352 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:41961
2024-01-10 06:36:03,352 - distributed.worker - INFO -          dashboard at:            127.0.0.1:44297
2024-01-10 06:36:03,352 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2024-01-10 06:36:03,352 - distributed.worker - INFO - -------------------------------------------------
2024-01-10 06:36:03,352 - distributed.worker - INFO -               Threads:                          1
2024-01-10 06:36:03,352 - distributed.worker - INFO -                Memory:                   0.98 TiB
2024-01-10 06:36:03,352 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-uguakz93
2024-01-10 06:36:03,352 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-f1248bb6-6e7d-4c22-85c7-6619471a795f
2024-01-10 06:36:03,352 - distributed.worker - INFO - Starting Worker plugin RMMSetup-36c7db50-708b-4a4e-99ec-fdf8f2738041
2024-01-10 06:36:03,648 - distributed.worker - INFO - Starting Worker plugin PreImport-2bc3012d-ffc6-43e9-a566-b8e6970a2991
2024-01-10 06:36:03,648 - distributed.worker - INFO - -------------------------------------------------
2024-01-10 06:36:03,711 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:41961', status: init, memory: 0, processing: 0>
2024-01-10 06:36:03,713 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:41961
2024-01-10 06:36:03,713 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:39946
2024-01-10 06:36:03,714 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-01-10 06:36:03,714 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2024-01-10 06:36:03,715 - distributed.worker - INFO - -------------------------------------------------
2024-01-10 06:36:03,716 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2024-01-10 06:36:03,775 - distributed.worker - INFO - Run out-of-band function 'get_worker_config'
2024-01-10 06:36:03,779 - distributed.worker - INFO - Run out-of-band function 'lambda'
2024-01-10 06:36:03,781 - distributed.worker - INFO - Run out-of-band function 'lambda'
2024-01-10 06:36:03,783 - distributed.scheduler - INFO - Remove client Client-842cc7d1-af82-11ee-9743-d8c49764f6bb
2024-01-10 06:36:03,783 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:39930; closing.
2024-01-10 06:36:03,783 - distributed.scheduler - INFO - Remove client Client-842cc7d1-af82-11ee-9743-d8c49764f6bb
2024-01-10 06:36:03,784 - distributed.scheduler - INFO - Close client connection: Client-842cc7d1-af82-11ee-9743-d8c49764f6bb
2024-01-10 06:36:03,784 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:44301'. Reason: nanny-close
2024-01-10 06:36:03,785 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2024-01-10 06:36:03,786 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:41961. Reason: nanny-close
2024-01-10 06:36:03,787 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2024-01-10 06:36:03,787 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:39946; closing.
2024-01-10 06:36:03,787 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:41961', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1704868563.787834')
2024-01-10 06:36:03,788 - distributed.scheduler - INFO - Lost all workers
2024-01-10 06:36:03,789 - distributed.nanny - INFO - Worker closed
2024-01-10 06:36:04,399 - distributed._signals - INFO - Received signal SIGINT (2)
2024-01-10 06:36:04,400 - distributed.scheduler - INFO - Scheduler closing due to signal-2...
2024-01-10 06:36:04,400 - distributed.scheduler - INFO - Scheduler closing all comms
2024-01-10 06:36:04,401 - distributed.scheduler - INFO - Stopped scheduler at 'tcp://10.33.227.163:9369'
2024-01-10 06:36:04,402 - distributed.scheduler - INFO - End scheduler
PASSED
dask_cuda/tests/test_dask_cuda_worker.py::test_worker_fraction_limits 2024-01-10 06:36:06,556 - distributed.scheduler - INFO - -----------------------------------------------
2024-01-10 06:36:06,560 - distributed.http.proxy - INFO - To route to workers diagnostics web server please install jupyter-server-proxy: python -m pip install jupyter-server-proxy
/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 34425 instead
  warnings.warn(
2024-01-10 06:36:06,564 - distributed.scheduler - INFO - State start
2024-01-10 06:36:06,587 - distributed.scheduler - INFO - -----------------------------------------------
2024-01-10 06:36:06,588 - distributed.scheduler - INFO -   Scheduler at:  tcp://10.33.227.163:9369
2024-01-10 06:36:06,589 - distributed.scheduler - INFO -   dashboard at:  http://10.33.227.163:34425/status
2024-01-10 06:36:06,589 - distributed.scheduler - INFO - Registering Worker plugin shuffle
2024-01-10 06:36:06,733 - distributed.nanny - INFO -         Start Nanny at: 'tcp://127.0.0.1:46715'
2024-01-10 06:36:07,468 - distributed.scheduler - INFO - Receive client connection: Client-87694b9f-af82-11ee-9743-d8c49764f6bb
2024-01-10 06:36:07,483 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:40044
2024-01-10 06:36:08,899 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2024-01-10 06:36:08,899 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2024-01-10 06:36:08,905 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2024-01-10 06:36:08,906 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:45933
2024-01-10 06:36:08,906 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:45933
2024-01-10 06:36:08,906 - distributed.worker - INFO -          dashboard at:            127.0.0.1:43773
2024-01-10 06:36:08,906 - distributed.worker - INFO - Waiting to connect to:       tcp://127.0.0.1:9369
2024-01-10 06:36:08,907 - distributed.worker - INFO - -------------------------------------------------
2024-01-10 06:36:08,907 - distributed.worker - INFO -               Threads:                          1
2024-01-10 06:36:08,907 - distributed.worker - INFO -                Memory:                   0.98 TiB
2024-01-10 06:36:08,907 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-1mpk8jub
2024-01-10 06:36:08,907 - distributed.worker - INFO - Starting Worker plugin RMMSetup-3ad56919-1b90-42d5-9041-5d57796cfb5d
2024-01-10 06:36:10,940 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-3ff68a9f-3c65-4e7d-9a06-1e34565f92cb
2024-01-10 06:36:10,941 - distributed.worker - INFO - Starting Worker plugin PreImport-0eb3fe3f-c1b8-4ff1-a14a-19712e336665
2024-01-10 06:36:10,941 - distributed.worker - INFO - -------------------------------------------------
2024-01-10 06:36:11,025 - distributed.scheduler - INFO - Register worker <WorkerState 'tcp://127.0.0.1:45933', status: init, memory: 0, processing: 0>
2024-01-10 06:36:11,027 - distributed.scheduler - INFO - Starting worker compute stream, tcp://127.0.0.1:45933
2024-01-10 06:36:11,027 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:58238
2024-01-10 06:36:11,028 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-01-10 06:36:11,029 - distributed.worker - INFO -         Registered to:       tcp://127.0.0.1:9369
2024-01-10 06:36:11,029 - distributed.worker - INFO - -------------------------------------------------
2024-01-10 06:36:11,031 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:9369
2024-01-10 06:36:11,114 - distributed.worker - INFO - Run out-of-band function 'get_device_total_memory'
2024-01-10 06:36:11,120 - distributed.worker - INFO - Run out-of-band function 'get_worker_config'
2024-01-10 06:36:11,125 - distributed.worker - INFO - Run out-of-band function 'lambda'
2024-01-10 06:36:11,127 - distributed.worker - INFO - Run out-of-band function 'lambda'
2024-01-10 06:36:11,131 - distributed.scheduler - INFO - Remove client Client-87694b9f-af82-11ee-9743-d8c49764f6bb
2024-01-10 06:36:11,131 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:40044; closing.
2024-01-10 06:36:11,131 - distributed.scheduler - INFO - Remove client Client-87694b9f-af82-11ee-9743-d8c49764f6bb
2024-01-10 06:36:11,132 - distributed.scheduler - INFO - Close client connection: Client-87694b9f-af82-11ee-9743-d8c49764f6bb
2024-01-10 06:36:11,133 - distributed.nanny - INFO - Closing Nanny at 'tcp://127.0.0.1:46715'. Reason: nanny-close
2024-01-10 06:36:11,134 - distributed.nanny - INFO - Nanny asking worker to close. Reason: nanny-close
2024-01-10 06:36:11,135 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:45933. Reason: nanny-close
2024-01-10 06:36:11,137 - distributed.core - INFO - Connection to tcp://127.0.0.1:9369 has been closed.
2024-01-10 06:36:11,137 - distributed.core - INFO - Received 'close-stream' from tcp://127.0.0.1:58238; closing.
2024-01-10 06:36:11,137 - distributed.scheduler - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:45933', status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1704868571.1377122')
2024-01-10 06:36:11,138 - distributed.scheduler - INFO - Lost all workers
2024-01-10 06:36:11,139 - distributed.nanny - INFO - Worker closed
2024-01-10 06:36:11,949 - distributed._signals - INFO - Received signal SIGINT (2)
2024-01-10 06:36:11,950 - distributed.scheduler - INFO - Scheduler closing due to signal-2...
2024-01-10 06:36:11,951 - distributed.scheduler - INFO - Scheduler closing all comms
2024-01-10 06:36:11,952 - distributed.scheduler - INFO - Stopped scheduler at 'tcp://10.33.227.163:9369'
2024-01-10 06:36:11,953 - distributed.scheduler - INFO - End scheduler
PASSED
dask_cuda/tests/test_dask_cuda_worker.py::test_worker_timeout PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range0-1-1] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range0-1-10] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range0-1-100] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range0-10-1] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range0-10-10] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range0-10-100] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range0-100-1] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range0-100-10] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range0-100-100] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range1-1-1] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range1-1-10] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range1-1-100] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range1-10-1] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range1-10-10] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range1-10-100] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range1-100-1] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range1-100-10] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range1-100-100] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range2-1-1] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range2-1-10] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range2-1-100] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range2-10-1] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range2-10-10] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range2-10-100] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range2-100-1] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range2-100-10] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_short[array_size_range2-100-100] PASSED
dask_cuda/tests/test_device_host_file.py::test_device_host_file_step_by_step PASSED
dask_cuda/tests/test_device_host_file.py::test_serialize_cupy_collection[10-0-dict] PASSED
dask_cuda/tests/test_device_host_file.py::test_serialize_cupy_collection[10-0-list] PASSED
dask_cuda/tests/test_device_host_file.py::test_serialize_cupy_collection[10-0-tuple] PASSED
dask_cuda/tests/test_device_host_file.py::test_serialize_cupy_collection[10-1-dict] PASSED
dask_cuda/tests/test_device_host_file.py::test_serialize_cupy_collection[10-1-list] PASSED
dask_cuda/tests/test_device_host_file.py::test_serialize_cupy_collection[10-1-tuple] PASSED
dask_cuda/tests/test_device_host_file.py::test_serialize_cupy_collection[10-3-dict] PASSED
dask_cuda/tests/test_device_host_file.py::test_serialize_cupy_collection[10-3-list] PASSED
dask_cuda/tests/test_device_host_file.py::test_serialize_cupy_collection[10-3-tuple] PASSED
dask_cuda/tests/test_device_host_file.py::test_serialize_cupy_collection[10-6-dict] PASSED
dask_cuda/tests/test_device_host_file.py::test_serialize_cupy_collection[10-6-list] PASSED
dask_cuda/tests/test_device_host_file.py::test_serialize_cupy_collection[10-6-tuple] PASSED
dask_cuda/tests/test_device_host_file.py::test_serialize_cupy_collection[value1-0-dict] PASSED
dask_cuda/tests/test_device_host_file.py::test_serialize_cupy_collection[value1-0-list] PASSED
dask_cuda/tests/test_device_host_file.py::test_serialize_cupy_collection[value1-0-tuple] PASSED
dask_cuda/tests/test_device_host_file.py::test_serialize_cupy_collection[value1-1-dict] PASSED
dask_cuda/tests/test_device_host_file.py::test_serialize_cupy_collection[value1-1-list] PASSED
dask_cuda/tests/test_device_host_file.py::test_serialize_cupy_collection[value1-1-tuple] PASSED
dask_cuda/tests/test_device_host_file.py::test_serialize_cupy_collection[value1-3-dict] PASSED
dask_cuda/tests/test_device_host_file.py::test_serialize_cupy_collection[value1-3-list] PASSED
dask_cuda/tests/test_device_host_file.py::test_serialize_cupy_collection[value1-3-tuple] PASSED
dask_cuda/tests/test_device_host_file.py::test_serialize_cupy_collection[value1-6-dict] PASSED
dask_cuda/tests/test_device_host_file.py::test_serialize_cupy_collection[value1-6-list] PASSED
dask_cuda/tests/test_device_host_file.py::test_serialize_cupy_collection[value1-6-tuple] PASSED
dask_cuda/tests/test_dgx.py::test_default /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 45091 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_dgx.py::test_tcp_over_ucx[ucx] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 36373 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_dgx.py::test_tcp_over_ucx[ucxx] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 38717 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_dgx.py::test_tcp_only /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 34319 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_dgx.py::test_ucx_infiniband_nvlink[params0-ucx] PASSED
dask_cuda/tests/test_dgx.py::test_ucx_infiniband_nvlink[params0-ucxx] 2024-01-10 06:37:22,085 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed_ucxx/ucxx.py", line 396, in read
    await self.ep.recv(msg)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/ucxx/_lib_async/endpoint.py", line 383, in recv
    ret = await req.wait()
  File "libucxx.pyx", line 738, in wait
  File "libucxx.pyx", line 723, in wait_yield
  File "libucxx.pyx", line 718, in ucxx._lib.libucxx.UCXRequest.check_error
ucxx.UCXXCanceledError: Request canceled

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 1252, in heartbeat
    response = await retry_operation(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils_comm.py", line 455, in retry_operation
    return await retry(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils_comm.py", line 434, in retry
    return await coro()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1394, in send_recv_from_rpc
    return await send_recv(comm=comm, op=key, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1153, in send_recv
    response = await comm.read(deserializers=deserializers)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 832, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed_ucxx/ucxx.py", line 414, in read
    raise CommClosedError(
distributed.comm.core.CommClosedError: Connection closed by writer.
Inner exception: UCXXCanceledError('Request canceled')
PASSED
dask_cuda/tests/test_dgx.py::test_ucx_infiniband_nvlink[params1-ucx] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 44739 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_dgx.py::test_ucx_infiniband_nvlink[params1-ucxx] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 43149 instead
  warnings.warn(
2024-01-10 06:37:47,819 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed_ucxx/ucxx.py", line 396, in read
    await self.ep.recv(msg)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/ucxx/_lib_async/endpoint.py", line 383, in recv
    ret = await req.wait()
  File "libucxx.pyx", line 738, in wait
  File "libucxx.pyx", line 723, in wait_yield
  File "libucxx.pyx", line 718, in ucxx._lib.libucxx.UCXRequest.check_error
ucxx.UCXXCanceledError: Request canceled

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 1252, in heartbeat
    response = await retry_operation(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils_comm.py", line 455, in retry_operation
    return await retry(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils_comm.py", line 434, in retry
    return await coro()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1394, in send_recv_from_rpc
    return await send_recv(comm=comm, op=key, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1153, in send_recv
    response = await comm.read(deserializers=deserializers)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 832, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed_ucxx/ucxx.py", line 414, in read
    raise CommClosedError(
distributed.comm.core.CommClosedError: Connection closed by writer.
Inner exception: UCXXCanceledError('Request canceled')
PASSED
dask_cuda/tests/test_dgx.py::test_ucx_infiniband_nvlink[params2-ucx] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 39727 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_dgx.py::test_ucx_infiniband_nvlink[params2-ucxx] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 35511 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_dgx.py::test_ucx_infiniband_nvlink[params3-ucx] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 37677 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_dgx.py::test_ucx_infiniband_nvlink[params3-ucxx] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 33933 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_dgx.py::test_ucx_infiniband_nvlink[params4-ucx] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 35015 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_dgx.py::test_ucx_infiniband_nvlink[params4-ucxx] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 34335 instead
  warnings.warn(
[1704868738.683069] [dgx13:61566:0]            sock.c:481  UCX  ERROR bind(fd=175 addr=0.0.0.0:55104) failed: Address already in use
PASSED
dask_cuda/tests/test_explicit_comms.py::test_local_cluster[tcp] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 38387 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_explicit_comms.py::test_local_cluster[ucx] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 40521 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_explicit_comms.py::test_local_cluster[ucxx] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 39033 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_merge_empty_partitions /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 39485 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle[True-tcp-pandas-1] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 38893 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle[True-tcp-pandas-2] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 38367 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle[True-tcp-pandas-3] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 45857 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle[True-tcp-cudf-1] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 34913 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle[True-tcp-cudf-2] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 33519 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle[True-tcp-cudf-3] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 45181 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle[True-ucx-pandas-1] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 43649 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle[True-ucx-pandas-2] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 33421 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle[True-ucx-pandas-3] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 44579 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle[True-ucx-cudf-1] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 39857 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle[True-ucx-cudf-2] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 40895 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle[True-ucx-cudf-3] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 44835 instead
  warnings.warn(
[1704869016.518801] [dgx13:66578:0]            sock.c:481  UCX  ERROR bind(fd=122 addr=0.0.0.0:42612) failed: Address already in use
[1704869020.191034] [dgx13:66578:0]            sock.c:481  UCX  ERROR bind(fd=130 addr=0.0.0.0:37262) failed: Address already in use
PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle[True-ucxx-pandas-1] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 36201 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle[True-ucxx-pandas-2] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 35521 instead
  warnings.warn(
[1704869072.120497] [dgx13:67232:0]            sock.c:481  UCX  ERROR bind(fd=153 addr=0.0.0.0:33478) failed: Address already in use
PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle[True-ucxx-pandas-3] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 35995 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle[True-ucxx-cudf-1] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 35821 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle[True-ucxx-cudf-2] PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle[True-ucxx-cudf-3] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 39187 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle[False-tcp-pandas-1] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 34567 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle[False-tcp-pandas-2] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 37039 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle[False-tcp-pandas-3] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 43249 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle[False-tcp-cudf-1] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 35651 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle[False-tcp-cudf-2] PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle[False-tcp-cudf-3] PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle[False-ucx-pandas-1] [1704869341.588732] [dgx13:71419:0]            sock.c:481  UCX  ERROR bind(fd=122 addr=0.0.0.0:51948) failed: Address already in use
PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle[False-ucx-pandas-2] PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle[False-ucx-pandas-3] PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle[False-ucx-cudf-1] PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle[False-ucx-cudf-2] PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle[False-ucx-cudf-3] PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle[False-ucxx-pandas-1] PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle[False-ucxx-pandas-2] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 41935 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle[False-ucxx-pandas-3] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 42623 instead
  warnings.warn(
[1704869534.785324] [dgx13:74163:0]            sock.c:481  UCX  ERROR bind(fd=155 addr=0.0.0.0:55030) failed: Address already in use
PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle[False-ucxx-cudf-1] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 42507 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle[False-ucxx-cudf-2] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 32957 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle[False-ucxx-cudf-3] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 43111 instead
  warnings.warn(
[1704869643.868555] [dgx13:75398:0]            sock.c:481  UCX  ERROR bind(fd=121 addr=0.0.0.0:37398) failed: Address already in use
PASSED
dask_cuda/tests/test_explicit_comms.py::test_dask_use_explicit_comms[True] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 33821 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_explicit_comms.py::test_dask_use_explicit_comms[False] PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle_merge[tcp-pandas-1] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 33485 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle_merge[tcp-pandas-2] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 36241 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle_merge[tcp-pandas-4] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 34633 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle_merge[tcp-cudf-1] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 41013 instead
  warnings.warn(
2024-01-10 06:55:23,868 - distributed.worker - ERROR - Unexpected exception during heartbeat. Closing worker.
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 1252, in heartbeat
    response = await retry_operation(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils_comm.py", line 455, in retry_operation
    return await retry(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils_comm.py", line 434, in retry
    return await coro()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1391, in send_recv_from_rpc
    comm = await self.pool.connect(self.addr)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1590, in connect
    raise RuntimeError("ConnectionPool is closed")
RuntimeError: ConnectionPool is closed
2024-01-10 06:55:23,871 - tornado.application - ERROR - Exception in callback <bound method Worker.heartbeat of <Worker 'tcp://127.0.0.1:39107', name: 0, status: closed, stored: 0, running: 0/1, ready: 0, comm: 0, waiting: 0>>
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/tornado/ioloop.py", line 921, in _run
    await val
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 1252, in heartbeat
    response = await retry_operation(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils_comm.py", line 455, in retry_operation
    return await retry(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils_comm.py", line 434, in retry
    return await coro()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1391, in send_recv_from_rpc
    comm = await self.pool.connect(self.addr)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1590, in connect
    raise RuntimeError("ConnectionPool is closed")
RuntimeError: ConnectionPool is closed
PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle_merge[tcp-cudf-2] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 35163 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle_merge[tcp-cudf-4] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 36057 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle_merge[ucx-pandas-1] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 33285 instead
  warnings.warn(
[1704869759.403174] [dgx13:77153:0]            sock.c:481  UCX  ERROR bind(fd=122 addr=0.0.0.0:40468) failed: Address already in use
PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle_merge[ucx-pandas-2] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 38519 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle_merge[ucx-pandas-4] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 40327 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle_merge[ucx-cudf-1] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 43743 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle_merge[ucx-cudf-2] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 42753 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle_merge[ucx-cudf-4] PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle_merge[ucxx-pandas-1] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 37641 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle_merge[ucxx-pandas-2] 2024-01-10 06:57:40,575 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed_ucxx/ucxx.py", line 439, in read
    await self.ep.recv(each_frame)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed_ucxx/ucxx.py", line 505, in ep
    raise CommClosedError("UCX Endpoint is closed")
distributed.comm.core.CommClosedError: UCX Endpoint is closed

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 1252, in heartbeat
    response = await retry_operation(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils_comm.py", line 455, in retry_operation
    return await retry(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils_comm.py", line 434, in retry
    return await coro()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1394, in send_recv_from_rpc
    return await send_recv(comm=comm, op=key, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 1153, in send_recv
    response = await comm.read(deserializers=deserializers)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 832, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed_ucxx/ucxx.py", line 445, in read
    raise CommClosedError(
distributed.comm.core.CommClosedError: Connection closed by writer.
Inner exception: CommClosedError('UCX Endpoint is closed')
PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle_merge[ucxx-pandas-4] PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle_merge[ucxx-cudf-1] PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle_merge[ucxx-cudf-2] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 38289 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_explicit_comms.py::test_dataframe_shuffle_merge[ucxx-cudf-4] PASSED
dask_cuda/tests/test_explicit_comms.py::test_jit_unspill[tcp] PASSED
dask_cuda/tests/test_explicit_comms.py::test_jit_unspill[ucx] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 44361 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_explicit_comms.py::test_jit_unspill[ucxx] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 40343 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_explicit_comms.py::test_lock_workers PASSED
dask_cuda/tests/test_from_array.py::test_ucx_from_array[ucx] [1704869993.706364] [dgx13:55107:0]            sock.c:481  UCX  ERROR bind(fd=179 addr=0.0.0.0:51770) failed: Address already in use
PASSED
dask_cuda/tests/test_from_array.py::test_ucx_from_array[ucxx] PASSED
dask_cuda/tests/test_from_array.py::test_ucx_from_array[tcp] PASSED
dask_cuda/tests/test_gds.py::test_gds[True-cupy] SKIPPED (GDS not av...)
dask_cuda/tests/test_gds.py::test_gds[True-cudf] SKIPPED (GDS not av...)
dask_cuda/tests/test_gds.py::test_gds[True-numba.cuda] SKIPPED (GDS ...)
dask_cuda/tests/test_gds.py::test_gds[False-cupy] PASSED
dask_cuda/tests/test_gds.py::test_gds[False-cudf] PASSED
dask_cuda/tests/test_gds.py::test_gds[False-numba.cuda] PASSED
dask_cuda/tests/test_initialize.py::test_initialize_ucx_tcp[ucx] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 38945 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_initialize.py::test_initialize_ucx_tcp[ucxx] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 40587 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_initialize.py::test_initialize_ucx_nvlink[ucx] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 43881 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_initialize.py::test_initialize_ucx_nvlink[ucxx] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 33783 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_initialize.py::test_initialize_ucx_infiniband[ucx] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 40207 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_initialize.py::test_initialize_ucx_infiniband[ucxx] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 44503 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_initialize.py::test_initialize_ucx_all[ucx] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 39857 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_initialize.py::test_initialize_ucx_all[ucxx] /opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.
Perhaps you already have a cluster running?
Hosting the HTTP server on port 38255 instead
  warnings.warn(
PASSED
dask_cuda/tests/test_local_cuda_cluster.py::test_local_cuda_cluster PASSED
dask_cuda/tests/test_local_cuda_cluster.py::test_with_subset_of_cuda_visible_devices PASSED
dask_cuda/tests/test_local_cuda_cluster.py::test_ucx_protocol[ucx] PASSED
dask_cuda/tests/test_local_cuda_cluster.py::test_ucx_protocol[ucxx] [1704870091.591854] [dgx13:55107:1]            sock.c:481  UCX  ERROR bind(fd=252 addr=0.0.0.0:40962) failed: Address already in use
[1704870096.965932] [dgx13:81211:0]            sock.c:481  UCX  ERROR bind(fd=161 addr=0.0.0.0:60238) failed: Address already in use
[1704870096.993460] [dgx13:81215:0]            sock.c:481  UCX  ERROR bind(fd=161 addr=0.0.0.0:45482) failed: Address already in use
PASSED
dask_cuda/tests/test_local_cuda_cluster.py::test_explicit_ucx_with_protocol_none[ucx] [1704870098.742344] [dgx13:55107:1]            sock.c:481  UCX  ERROR bind(fd=249 addr=0.0.0.0:37328) failed: Address already in use
PASSED
dask_cuda/tests/test_local_cuda_cluster.py::test_explicit_ucx_with_protocol_none[ucxx] PASSED
dask_cuda/tests/test_local_cuda_cluster.py::test_ucx_protocol_type_error[ucx] PASSED
dask_cuda/tests/test_local_cuda_cluster.py::test_ucx_protocol_type_error[ucxx] PASSED
dask_cuda/tests/test_local_cuda_cluster.py::test_n_workers PASSED
dask_cuda/tests/test_local_cuda_cluster.py::test_threads_per_worker_and_memory_limit PASSED
dask_cuda/tests/test_local_cuda_cluster.py::test_no_memory_limits_cluster PASSED
dask_cuda/tests/test_local_cuda_cluster.py::test_no_memory_limits_cudaworker 2024-01-10 07:02:04,590 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2024-01-10 07:02:04,590 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2024-01-10 07:02:04,647 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2024-01-10 07:02:04,647 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2024-01-10 07:02:04,655 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2024-01-10 07:02:04,656 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2024-01-10 07:02:04,698 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2024-01-10 07:02:04,699 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2024-01-10 07:02:04,705 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2024-01-10 07:02:04,706 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2024-01-10 07:02:04,707 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2024-01-10 07:02:04,707 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2024-01-10 07:02:04,739 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2024-01-10 07:02:04,739 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2024-01-10 07:02:04,751 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2024-01-10 07:02:04,751 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2024-01-10 07:02:05,212 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2024-01-10 07:02:05,213 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:37643
2024-01-10 07:02:05,213 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:37643
2024-01-10 07:02:05,213 - distributed.worker - INFO -          dashboard at:            127.0.0.1:41031
2024-01-10 07:02:05,213 - distributed.worker - INFO - Waiting to connect to:      tcp://127.0.0.1:44449
2024-01-10 07:02:05,213 - distributed.worker - INFO - -------------------------------------------------
2024-01-10 07:02:05,213 - distributed.worker - INFO -               Threads:                          1
2024-01-10 07:02:05,213 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-sjz35vc2
2024-01-10 07:02:05,213 - distributed.worker - INFO - Starting Worker plugin RMMSetup-f3393577-5fe0-426b-b6d5-71a3de1fb7c2
2024-01-10 07:02:05,213 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-322e1022-0d43-4561-b852-420f3398ff6c
2024-01-10 07:02:05,214 - distributed.worker - INFO - Starting Worker plugin PreImport-3c9490aa-bd47-48f8-ab33-ea22f78afc23
2024-01-10 07:02:05,214 - distributed.worker - INFO - -------------------------------------------------
2024-01-10 07:02:05,279 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-01-10 07:02:05,279 - distributed.worker - INFO -         Registered to:      tcp://127.0.0.1:44449
2024-01-10 07:02:05,279 - distributed.worker - INFO - -------------------------------------------------
2024-01-10 07:02:05,280 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:44449
2024-01-10 07:02:05,300 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2024-01-10 07:02:05,301 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:43217
2024-01-10 07:02:05,302 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:43217
2024-01-10 07:02:05,302 - distributed.worker - INFO -          dashboard at:            127.0.0.1:45677
2024-01-10 07:02:05,302 - distributed.worker - INFO - Waiting to connect to:      tcp://127.0.0.1:44449
2024-01-10 07:02:05,302 - distributed.worker - INFO - -------------------------------------------------
2024-01-10 07:02:05,302 - distributed.worker - INFO -               Threads:                          1
2024-01-10 07:02:05,302 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-6arrrdks
2024-01-10 07:02:05,302 - distributed.worker - INFO - Starting Worker plugin PreImport-00241b33-3d2d-45b5-b5ad-fefd8e3dcbab
2024-01-10 07:02:05,302 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-28c4355e-e6cd-48b5-8b3c-8d5773297e54
2024-01-10 07:02:05,302 - distributed.worker - INFO - Starting Worker plugin RMMSetup-84007db0-4648-4aef-b324-eacb3d370a7d
2024-01-10 07:02:05,303 - distributed.worker - INFO - -------------------------------------------------
2024-01-10 07:02:05,306 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2024-01-10 07:02:05,307 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:34809
2024-01-10 07:02:05,307 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:34809
2024-01-10 07:02:05,307 - distributed.worker - INFO -          dashboard at:            127.0.0.1:41885
2024-01-10 07:02:05,307 - distributed.worker - INFO - Waiting to connect to:      tcp://127.0.0.1:44449
2024-01-10 07:02:05,307 - distributed.worker - INFO - -------------------------------------------------
2024-01-10 07:02:05,307 - distributed.worker - INFO -               Threads:                          1
2024-01-10 07:02:05,307 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-qbaf7qj1
2024-01-10 07:02:05,307 - distributed.worker - INFO - Starting Worker plugin RMMSetup-fae835d1-7239-4f8a-a6f3-ead307e7a323
2024-01-10 07:02:05,308 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-75bc6690-97f2-4169-a89f-6e31da27e46e
2024-01-10 07:02:05,308 - distributed.worker - INFO - Starting Worker plugin PreImport-f0164da6-478c-465a-a433-32ed6b91597e
2024-01-10 07:02:05,308 - distributed.worker - INFO - -------------------------------------------------
2024-01-10 07:02:05,333 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2024-01-10 07:02:05,334 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:33055
2024-01-10 07:02:05,334 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:33055
2024-01-10 07:02:05,334 - distributed.worker - INFO -          dashboard at:            127.0.0.1:41583
2024-01-10 07:02:05,334 - distributed.worker - INFO - Waiting to connect to:      tcp://127.0.0.1:44449
2024-01-10 07:02:05,334 - distributed.worker - INFO - -------------------------------------------------
2024-01-10 07:02:05,334 - distributed.worker - INFO -               Threads:                          1
2024-01-10 07:02:05,334 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-u_l5kmzv
2024-01-10 07:02:05,335 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-a3225da1-b9ca-45c2-9dc1-d13675f9e46e
2024-01-10 07:02:05,335 - distributed.worker - INFO - Starting Worker plugin RMMSetup-adc0df99-eaae-4ae0-8c13-42aa7d717c81
2024-01-10 07:02:05,335 - distributed.worker - INFO - Starting Worker plugin PreImport-3a476723-ccc6-4349-ab86-d4532672f8b7
2024-01-10 07:02:05,335 - distributed.worker - INFO - -------------------------------------------------
2024-01-10 07:02:05,357 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2024-01-10 07:02:05,358 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:35859
2024-01-10 07:02:05,358 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:35859
2024-01-10 07:02:05,358 - distributed.worker - INFO -          dashboard at:            127.0.0.1:39067
2024-01-10 07:02:05,358 - distributed.worker - INFO - Waiting to connect to:      tcp://127.0.0.1:44449
2024-01-10 07:02:05,358 - distributed.worker - INFO - -------------------------------------------------
2024-01-10 07:02:05,358 - distributed.worker - INFO -               Threads:                          1
2024-01-10 07:02:05,358 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-_4rbzz_p
2024-01-10 07:02:05,359 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-688e14f5-b404-4b0e-a1e0-410176905147
2024-01-10 07:02:05,359 - distributed.worker - INFO - Starting Worker plugin PreImport-0ce5a544-a78d-425a-964e-634bf2ef5e74
2024-01-10 07:02:05,359 - distributed.worker - INFO - Starting Worker plugin RMMSetup-98d2b507-5ef4-441e-8714-09bf9072a32c
2024-01-10 07:02:05,359 - distributed.worker - INFO - -------------------------------------------------
2024-01-10 07:02:05,370 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2024-01-10 07:02:05,371 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:39489
2024-01-10 07:02:05,371 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:39489
2024-01-10 07:02:05,371 - distributed.worker - INFO -          dashboard at:            127.0.0.1:45903
2024-01-10 07:02:05,371 - distributed.worker - INFO - Waiting to connect to:      tcp://127.0.0.1:44449
2024-01-10 07:02:05,371 - distributed.worker - INFO - -------------------------------------------------
2024-01-10 07:02:05,371 - distributed.worker - INFO -               Threads:                          1
2024-01-10 07:02:05,371 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-gd2ofma_
2024-01-10 07:02:05,372 - distributed.worker - INFO - Starting Worker plugin RMMSetup-01d22469-ef9a-4646-aeb3-e35fe0205e34
2024-01-10 07:02:05,372 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-44d468ca-97c5-4023-aa9a-30f8fb2d24e6
2024-01-10 07:02:05,372 - distributed.worker - INFO - Starting Worker plugin PreImport-0e6c6f22-c017-473c-9734-c87f2f00a6e1
2024-01-10 07:02:05,372 - distributed.worker - INFO - -------------------------------------------------
2024-01-10 07:02:05,396 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-01-10 07:02:05,397 - distributed.worker - INFO -         Registered to:      tcp://127.0.0.1:44449
2024-01-10 07:02:05,397 - distributed.worker - INFO - -------------------------------------------------
2024-01-10 07:02:05,398 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:44449
2024-01-10 07:02:05,434 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2024-01-10 07:02:05,435 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-01-10 07:02:05,435 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:36153
2024-01-10 07:02:05,435 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:36153
2024-01-10 07:02:05,435 - distributed.worker - INFO -          dashboard at:            127.0.0.1:44501
2024-01-10 07:02:05,436 - distributed.worker - INFO - Waiting to connect to:      tcp://127.0.0.1:44449
2024-01-10 07:02:05,436 - distributed.worker - INFO -         Registered to:      tcp://127.0.0.1:44449
2024-01-10 07:02:05,436 - distributed.worker - INFO - -------------------------------------------------
2024-01-10 07:02:05,436 - distributed.worker - INFO - -------------------------------------------------
2024-01-10 07:02:05,436 - distributed.worker - INFO -               Threads:                          1
2024-01-10 07:02:05,436 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-oibbwf_w
2024-01-10 07:02:05,436 - distributed.worker - INFO - Starting Worker plugin RMMSetup-39e3b16e-1eaa-4a85-b8d5-7d0d417d2bd4
2024-01-10 07:02:05,436 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-a5bfc649-4a3d-44c0-b951-9b9511706d50
2024-01-10 07:02:05,436 - distributed.worker - INFO - Starting Worker plugin PreImport-6608d247-a6b9-437b-b1d6-d2dffd09d3b0
2024-01-10 07:02:05,437 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:44449
2024-01-10 07:02:05,437 - distributed.worker - INFO - -------------------------------------------------
2024-01-10 07:02:05,437 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2024-01-10 07:02:05,438 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:36073
2024-01-10 07:02:05,438 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:36073
2024-01-10 07:02:05,438 - distributed.worker - INFO -          dashboard at:            127.0.0.1:40041
2024-01-10 07:02:05,438 - distributed.worker - INFO - Waiting to connect to:      tcp://127.0.0.1:44449
2024-01-10 07:02:05,438 - distributed.worker - INFO - -------------------------------------------------
2024-01-10 07:02:05,438 - distributed.worker - INFO -               Threads:                          1
2024-01-10 07:02:05,438 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-1wivly7x
2024-01-10 07:02:05,439 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-5db3c756-ed61-4432-a96b-0cbef70bb3d4
2024-01-10 07:02:05,439 - distributed.worker - INFO - Starting Worker plugin PreImport-11b60919-9fb0-4d1a-bbe3-42723b97eb65
2024-01-10 07:02:05,440 - distributed.worker - INFO - Starting Worker plugin RMMSetup-c6699653-1834-4b74-9a22-7934fa320f3e
2024-01-10 07:02:05,440 - distributed.worker - INFO - -------------------------------------------------
2024-01-10 07:02:05,480 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-01-10 07:02:05,481 - distributed.worker - INFO -         Registered to:      tcp://127.0.0.1:44449
2024-01-10 07:02:05,481 - distributed.worker - INFO - -------------------------------------------------
2024-01-10 07:02:05,482 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:44449
2024-01-10 07:02:05,512 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-01-10 07:02:05,513 - distributed.worker - INFO -         Registered to:      tcp://127.0.0.1:44449
2024-01-10 07:02:05,513 - distributed.worker - INFO - -------------------------------------------------
2024-01-10 07:02:05,514 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:44449
2024-01-10 07:02:05,525 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-01-10 07:02:05,526 - distributed.worker - INFO -         Registered to:      tcp://127.0.0.1:44449
2024-01-10 07:02:05,526 - distributed.worker - INFO - -------------------------------------------------
2024-01-10 07:02:05,527 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:44449
2024-01-10 07:02:05,567 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-01-10 07:02:05,568 - distributed.worker - INFO -         Registered to:      tcp://127.0.0.1:44449
2024-01-10 07:02:05,568 - distributed.worker - INFO - -------------------------------------------------
2024-01-10 07:02:05,569 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-01-10 07:02:05,569 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:44449
2024-01-10 07:02:05,570 - distributed.worker - INFO -         Registered to:      tcp://127.0.0.1:44449
2024-01-10 07:02:05,570 - distributed.worker - INFO - -------------------------------------------------
2024-01-10 07:02:05,572 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:44449
2024-01-10 07:02:05,630 - distributed.worker - INFO - Run out-of-band function 'lambda'
2024-01-10 07:02:05,631 - distributed.worker - INFO - Run out-of-band function 'lambda'
2024-01-10 07:02:05,630 - distributed.worker - INFO - Run out-of-band function 'lambda'
2024-01-10 07:02:05,631 - distributed.worker - INFO - Run out-of-band function 'lambda'
2024-01-10 07:02:05,631 - distributed.worker - INFO - Run out-of-band function 'lambda'
2024-01-10 07:02:05,631 - distributed.worker - INFO - Run out-of-band function 'lambda'
2024-01-10 07:02:05,631 - distributed.worker - INFO - Run out-of-band function 'lambda'
2024-01-10 07:02:05,631 - distributed.worker - INFO - Run out-of-band function 'lambda'
2024-01-10 07:02:05,637 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:37643. Reason: nanny-close
2024-01-10 07:02:05,637 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:35859. Reason: nanny-close
2024-01-10 07:02:05,638 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:34809. Reason: nanny-close
2024-01-10 07:02:05,638 - distributed.core - INFO - Connection to tcp://127.0.0.1:44449 has been closed.
2024-01-10 07:02:05,639 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:39489. Reason: nanny-close
2024-01-10 07:02:05,639 - distributed.core - INFO - Connection to tcp://127.0.0.1:44449 has been closed.
2024-01-10 07:02:05,639 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:43217. Reason: nanny-close
2024-01-10 07:02:05,640 - distributed.nanny - INFO - Worker closed
2024-01-10 07:02:05,640 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:33055. Reason: nanny-close
2024-01-10 07:02:05,640 - distributed.core - INFO - Connection to tcp://127.0.0.1:44449 has been closed.
2024-01-10 07:02:05,640 - distributed.nanny - INFO - Worker closed
2024-01-10 07:02:05,640 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:36153. Reason: nanny-close
2024-01-10 07:02:05,641 - distributed.core - INFO - Connection to tcp://127.0.0.1:44449 has been closed.
2024-01-10 07:02:05,641 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:36073. Reason: nanny-close
2024-01-10 07:02:05,641 - distributed.core - INFO - Connection to tcp://127.0.0.1:44449 has been closed.
2024-01-10 07:02:05,641 - distributed.nanny - INFO - Worker closed
2024-01-10 07:02:05,642 - distributed.core - INFO - Connection to tcp://127.0.0.1:44449 has been closed.
2024-01-10 07:02:05,642 - distributed.nanny - INFO - Worker closed
2024-01-10 07:02:05,642 - distributed.nanny - INFO - Worker closed
2024-01-10 07:02:05,643 - distributed.nanny - INFO - Worker closed
2024-01-10 07:02:05,643 - distributed.core - INFO - Connection to tcp://127.0.0.1:44449 has been closed.
2024-01-10 07:02:05,643 - distributed.core - INFO - Connection to tcp://127.0.0.1:44449 has been closed.
2024-01-10 07:02:05,645 - distributed.nanny - INFO - Worker closed
2024-01-10 07:02:05,645 - distributed.nanny - INFO - Worker closed
PASSED
dask_cuda/tests/test_local_cuda_cluster.py::test_all_to_all PASSED
dask_cuda/tests/test_local_cuda_cluster.py::test_rmm_pool PASSED
dask_cuda/tests/test_local_cuda_cluster.py::test_rmm_maximum_poolsize_without_poolsize_error PASSED
dask_cuda/tests/test_local_cuda_cluster.py::test_rmm_managed PASSED
dask_cuda/tests/test_local_cuda_cluster.py::test_rmm_async PASSED
dask_cuda/tests/test_local_cuda_cluster.py::test_rmm_async_with_maximum_pool_size PASSED
dask_cuda/tests/test_local_cuda_cluster.py::test_rmm_logging PASSED
dask_cuda/tests/test_local_cuda_cluster.py::test_pre_import PASSED
dask_cuda/tests/test_local_cuda_cluster.py::test_pre_import_not_found 2024-01-10 07:02:42,102 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2024-01-10 07:02:42,103 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2024-01-10 07:02:42,107 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2024-01-10 07:02:42,108 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:36381
2024-01-10 07:02:42,108 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:36381
2024-01-10 07:02:42,108 - distributed.worker - INFO -           Worker name:                          0
2024-01-10 07:02:42,108 - distributed.worker - INFO -          dashboard at:            127.0.0.1:45531
2024-01-10 07:02:42,108 - distributed.worker - INFO - Waiting to connect to:      tcp://127.0.0.1:35097
2024-01-10 07:02:42,108 - distributed.worker - INFO - -------------------------------------------------
2024-01-10 07:02:42,108 - distributed.worker - INFO -               Threads:                          1
2024-01-10 07:02:42,108 - distributed.worker - INFO -                Memory:                   0.98 TiB
2024-01-10 07:02:42,108 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-mfmwj6fo
2024-01-10 07:02:42,108 - distributed.worker - INFO - Starting Worker plugin PreImport-b16bd1c3-927d-4a70-91d6-43db50539182
2024-01-10 07:02:42,112 - distributed.worker - ERROR - No module named 'my_module'
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 832, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 1873, in plugin_add
    result = plugin.setup(worker=self)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/dask_cuda/plugins.py", line 122, in setup
    importlib.import_module(l)
  File "/opt/conda/envs/gdf/lib/python3.9/importlib/__init__.py", line 127, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File "<frozen importlib._bootstrap>", line 1030, in _gcd_import
  File "<frozen importlib._bootstrap>", line 1007, in _find_and_load
  File "<frozen importlib._bootstrap>", line 984, in _find_and_load_unlocked
ModuleNotFoundError: No module named 'my_module'
2024-01-10 07:02:42,113 - distributed.worker - INFO - Starting Worker plugin RMMSetup-c567ac0d-4762-4fd3-a626-516e3fbf5dfa
2024-01-10 07:02:42,113 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-3ac66577-7860-45bd-b29b-0ab5542346d2
2024-01-10 07:02:42,113 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:36381. Reason: failure-to-start-<class 'ModuleNotFoundError'>
2024-01-10 07:02:42,113 - distributed.worker - INFO - Closed worker has not yet started: Status.init
2024-01-10 07:02:42,114 - distributed.nanny - ERROR - Failed to start worker
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 663, in start
    await wait_for(self.start_unsafe(), timeout=timeout)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 1940, in wait_for
    return await asyncio.wait_for(fut, timeout)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 442, in wait_for
    return await fut
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 1473, in start_unsafe
    raise plugins_exceptions[0]
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 832, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 1873, in plugin_add
    result = plugin.setup(worker=self)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/dask_cuda/plugins.py", line 122, in setup
    importlib.import_module(l)
  File "/opt/conda/envs/gdf/lib/python3.9/importlib/__init__.py", line 127, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File "<frozen importlib._bootstrap>", line 1030, in _gcd_import
  File "<frozen importlib._bootstrap>", line 1007, in _find_and_load
  File "<frozen importlib._bootstrap>", line 984, in _find_and_load_unlocked
ModuleNotFoundError: No module named 'my_module'

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 967, in run
    async with worker:
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 677, in __aenter__
    await self
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 671, in start
    raise RuntimeError(f"{type(self).__name__} failed to start.") from exc
RuntimeError: Worker failed to start.
XFAIL
dask_cuda/tests/test_local_cuda_cluster.py::test_cluster_worker 2024-01-10 07:02:46,913 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2024-01-10 07:02:46,913 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2024-01-10 07:02:46,915 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2024-01-10 07:02:46,916 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2024-01-10 07:02:46,917 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2024-01-10 07:02:46,917 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2024-01-10 07:02:46,948 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2024-01-10 07:02:46,949 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2024-01-10 07:02:46,990 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2024-01-10 07:02:46,990 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2024-01-10 07:02:47,041 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2024-01-10 07:02:47,041 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2024-01-10 07:02:47,063 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2024-01-10 07:02:47,063 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2024-01-10 07:02:47,121 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2024-01-10 07:02:47,122 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2024-01-10 07:02:47,528 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2024-01-10 07:02:47,528 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:41535
2024-01-10 07:02:47,529 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:41535
2024-01-10 07:02:47,529 - distributed.worker - INFO -          dashboard at:            127.0.0.1:35963
2024-01-10 07:02:47,529 - distributed.worker - INFO - Waiting to connect to:      tcp://127.0.0.1:34983
2024-01-10 07:02:47,529 - distributed.worker - INFO - -------------------------------------------------
2024-01-10 07:02:47,529 - distributed.worker - INFO -               Threads:                          1
2024-01-10 07:02:47,529 - distributed.worker - INFO -                Memory:                 125.97 GiB
2024-01-10 07:02:47,529 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-ly2pwgdl
2024-01-10 07:02:47,529 - distributed.worker - INFO - Starting Worker plugin PreImport-167d0ec5-60df-43e5-b064-f83ea23c5455
2024-01-10 07:02:47,529 - distributed.worker - INFO - Starting Worker plugin RMMSetup-978c34b7-fd9f-41ac-9000-e98da3f20678
2024-01-10 07:02:47,529 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-2936b328-fe82-4229-9809-875da1761b2b
2024-01-10 07:02:47,530 - distributed.worker - INFO - -------------------------------------------------
2024-01-10 07:02:47,534 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2024-01-10 07:02:47,535 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:44097
2024-01-10 07:02:47,535 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:44097
2024-01-10 07:02:47,535 - distributed.worker - INFO -          dashboard at:            127.0.0.1:44703
2024-01-10 07:02:47,535 - distributed.worker - INFO - Waiting to connect to:      tcp://127.0.0.1:34983
2024-01-10 07:02:47,535 - distributed.worker - INFO - -------------------------------------------------
2024-01-10 07:02:47,535 - distributed.worker - INFO -               Threads:                          1
2024-01-10 07:02:47,535 - distributed.worker - INFO -                Memory:                 125.97 GiB
2024-01-10 07:02:47,535 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-lam0p7y5
2024-01-10 07:02:47,536 - distributed.worker - INFO - Starting Worker plugin PreImport-258816e9-0e18-49c7-97a0-9a733ee272be
2024-01-10 07:02:47,536 - distributed.worker - INFO - Starting Worker plugin RMMSetup-a605d3e7-3d51-4ce2-92f6-c6909df3ad38
2024-01-10 07:02:47,536 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-0f54241c-9b70-4382-ae21-77e3bebe7e66
2024-01-10 07:02:47,536 - distributed.worker - INFO - -------------------------------------------------
2024-01-10 07:02:47,537 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2024-01-10 07:02:47,538 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:33185
2024-01-10 07:02:47,538 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:33185
2024-01-10 07:02:47,538 - distributed.worker - INFO -          dashboard at:            127.0.0.1:34513
2024-01-10 07:02:47,538 - distributed.worker - INFO - Waiting to connect to:      tcp://127.0.0.1:34983
2024-01-10 07:02:47,538 - distributed.worker - INFO - -------------------------------------------------
2024-01-10 07:02:47,539 - distributed.worker - INFO -               Threads:                          1
2024-01-10 07:02:47,539 - distributed.worker - INFO -                Memory:                 125.97 GiB
2024-01-10 07:02:47,539 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-baugs824
2024-01-10 07:02:47,539 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-b639b3e0-3b1c-434d-80db-b6b1a0a176e2
2024-01-10 07:02:47,539 - distributed.worker - INFO - Starting Worker plugin RMMSetup-5fca414f-15d2-4413-9246-0310fe5239af
2024-01-10 07:02:47,539 - distributed.worker - INFO - Starting Worker plugin PreImport-e838d95c-b2cb-4c9a-8dea-e21bb9c67a5d
2024-01-10 07:02:47,539 - distributed.worker - INFO - -------------------------------------------------
2024-01-10 07:02:47,556 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2024-01-10 07:02:47,557 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:41103
2024-01-10 07:02:47,557 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:41103
2024-01-10 07:02:47,557 - distributed.worker - INFO -          dashboard at:            127.0.0.1:37699
2024-01-10 07:02:47,557 - distributed.worker - INFO - Waiting to connect to:      tcp://127.0.0.1:34983
2024-01-10 07:02:47,557 - distributed.worker - INFO - -------------------------------------------------
2024-01-10 07:02:47,557 - distributed.worker - INFO -               Threads:                          1
2024-01-10 07:02:47,557 - distributed.worker - INFO -                Memory:                 125.97 GiB
2024-01-10 07:02:47,557 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-3cvx0m64
2024-01-10 07:02:47,558 - distributed.worker - INFO - Starting Worker plugin RMMSetup-8cb12bf5-3725-481d-840d-95ca68bd57ec
2024-01-10 07:02:47,558 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-6c6c9623-47c2-4b66-96c5-0efb6cbd9883
2024-01-10 07:02:47,558 - distributed.worker - INFO - Starting Worker plugin PreImport-3755af15-8104-478a-b78a-5bb71c71515e
2024-01-10 07:02:47,558 - distributed.worker - INFO - -------------------------------------------------
2024-01-10 07:02:47,603 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2024-01-10 07:02:47,604 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:43245
2024-01-10 07:02:47,604 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:43245
2024-01-10 07:02:47,604 - distributed.worker - INFO -          dashboard at:            127.0.0.1:41833
2024-01-10 07:02:47,604 - distributed.worker - INFO - Waiting to connect to:      tcp://127.0.0.1:34983
2024-01-10 07:02:47,604 - distributed.worker - INFO - -------------------------------------------------
2024-01-10 07:02:47,604 - distributed.worker - INFO -               Threads:                          1
2024-01-10 07:02:47,604 - distributed.worker - INFO -                Memory:                 125.97 GiB
2024-01-10 07:02:47,604 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-fmekvf66
2024-01-10 07:02:47,605 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-2f3eb97c-3b40-43c1-b644-22cf8e924cc6
2024-01-10 07:02:47,605 - distributed.worker - INFO - Starting Worker plugin RMMSetup-263464dd-128c-471c-8733-785c2d090039
2024-01-10 07:02:47,605 - distributed.worker - INFO - Starting Worker plugin PreImport-f8fb1e33-8164-4188-9471-a1862e64b614
2024-01-10 07:02:47,605 - distributed.worker - INFO - -------------------------------------------------
2024-01-10 07:02:47,659 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2024-01-10 07:02:47,659 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:46457
2024-01-10 07:02:47,660 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:46457
2024-01-10 07:02:47,660 - distributed.worker - INFO -          dashboard at:            127.0.0.1:41345
2024-01-10 07:02:47,660 - distributed.worker - INFO - Waiting to connect to:      tcp://127.0.0.1:34983
2024-01-10 07:02:47,660 - distributed.worker - INFO - -------------------------------------------------
2024-01-10 07:02:47,660 - distributed.worker - INFO -               Threads:                          1
2024-01-10 07:02:47,660 - distributed.worker - INFO -                Memory:                 125.97 GiB
2024-01-10 07:02:47,660 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-k3g51gys
2024-01-10 07:02:47,660 - distributed.worker - INFO - Starting Worker plugin PreImport-132e8bb4-f8bb-495a-bf62-49dcda5b6f42
2024-01-10 07:02:47,660 - distributed.worker - INFO - Starting Worker plugin RMMSetup-e3b70838-d75c-43fb-afd2-d1165e199c76
2024-01-10 07:02:47,660 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-236f8145-4848-4428-8ad0-5e3b029ac9f4
2024-01-10 07:02:47,661 - distributed.worker - INFO - -------------------------------------------------
2024-01-10 07:02:47,682 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2024-01-10 07:02:47,683 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:46843
2024-01-10 07:02:47,683 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:46843
2024-01-10 07:02:47,683 - distributed.worker - INFO -          dashboard at:            127.0.0.1:45431
2024-01-10 07:02:47,683 - distributed.worker - INFO - Waiting to connect to:      tcp://127.0.0.1:34983
2024-01-10 07:02:47,683 - distributed.worker - INFO - -------------------------------------------------
2024-01-10 07:02:47,683 - distributed.worker - INFO -               Threads:                          1
2024-01-10 07:02:47,683 - distributed.worker - INFO -                Memory:                 125.97 GiB
2024-01-10 07:02:47,683 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-kb0staga
2024-01-10 07:02:47,683 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-01-10 07:02:47,684 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-23ae0f31-45e0-4955-b297-f946891c132a
2024-01-10 07:02:47,684 - distributed.worker - INFO - Starting Worker plugin PreImport-86163995-abf8-4b9b-becc-9a326ed1d6c6
2024-01-10 07:02:47,684 - distributed.worker - INFO -         Registered to:      tcp://127.0.0.1:34983
2024-01-10 07:02:47,684 - distributed.worker - INFO - -------------------------------------------------
2024-01-10 07:02:47,684 - distributed.worker - INFO - Starting Worker plugin RMMSetup-30190cca-fb3a-471c-9157-477b89bb257d
2024-01-10 07:02:47,684 - distributed.worker - INFO - -------------------------------------------------
2024-01-10 07:02:47,685 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:34983
2024-01-10 07:02:47,710 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-01-10 07:02:47,711 - distributed.worker - INFO -         Registered to:      tcp://127.0.0.1:34983
2024-01-10 07:02:47,711 - distributed.worker - INFO - -------------------------------------------------
2024-01-10 07:02:47,712 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:34983
2024-01-10 07:02:47,713 - distributed.preloading - INFO - Run preload setup: dask_cuda.initialize
2024-01-10 07:02:47,714 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:42327
2024-01-10 07:02:47,714 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:42327
2024-01-10 07:02:47,714 - distributed.worker - INFO -          dashboard at:            127.0.0.1:37261
2024-01-10 07:02:47,714 - distributed.worker - INFO - Waiting to connect to:      tcp://127.0.0.1:34983
2024-01-10 07:02:47,714 - distributed.worker - INFO - -------------------------------------------------
2024-01-10 07:02:47,715 - distributed.worker - INFO -               Threads:                          1
2024-01-10 07:02:47,715 - distributed.worker - INFO -                Memory:                 125.97 GiB
2024-01-10 07:02:47,715 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-7ybqnu4e
2024-01-10 07:02:47,715 - distributed.worker - INFO - Starting Worker plugin RMMSetup-5b90a68b-981b-4dda-9279-83666f1d0d73
2024-01-10 07:02:47,715 - distributed.worker - INFO - Starting Worker plugin CPUAffinity-5eff22c7-dcab-470b-969e-941b52bb0ad9
2024-01-10 07:02:47,715 - distributed.worker - INFO - Starting Worker plugin PreImport-af20830d-991c-4344-a1fa-e1b0a75f1ee0
2024-01-10 07:02:47,716 - distributed.worker - INFO - -------------------------------------------------
2024-01-10 07:02:47,721 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-01-10 07:02:47,722 - distributed.worker - INFO -         Registered to:      tcp://127.0.0.1:34983
2024-01-10 07:02:47,722 - distributed.worker - INFO - -------------------------------------------------
2024-01-10 07:02:47,723 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:34983
2024-01-10 07:02:47,737 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-01-10 07:02:47,738 - distributed.worker - INFO -         Registered to:      tcp://127.0.0.1:34983
2024-01-10 07:02:47,738 - distributed.worker - INFO - -------------------------------------------------
2024-01-10 07:02:47,739 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:34983
2024-01-10 07:02:47,781 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-01-10 07:02:47,782 - distributed.worker - INFO -         Registered to:      tcp://127.0.0.1:34983
2024-01-10 07:02:47,782 - distributed.worker - INFO - -------------------------------------------------
2024-01-10 07:02:47,783 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:34983
2024-01-10 07:02:47,815 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-01-10 07:02:47,816 - distributed.worker - INFO -         Registered to:      tcp://127.0.0.1:34983
2024-01-10 07:02:47,816 - distributed.worker - INFO - -------------------------------------------------
2024-01-10 07:02:47,817 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:34983
2024-01-10 07:02:47,829 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-01-10 07:02:47,830 - distributed.worker - INFO -         Registered to:      tcp://127.0.0.1:34983
2024-01-10 07:02:47,830 - distributed.worker - INFO - -------------------------------------------------
2024-01-10 07:02:47,831 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:34983
2024-01-10 07:02:47,836 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-01-10 07:02:47,837 - distributed.worker - INFO -         Registered to:      tcp://127.0.0.1:34983
2024-01-10 07:02:47,837 - distributed.worker - INFO - -------------------------------------------------
2024-01-10 07:02:47,838 - distributed.core - INFO - Starting established connection to tcp://127.0.0.1:34983
2024-01-10 07:02:47,875 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:33185. Reason: nanny-close
2024-01-10 07:02:47,876 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:44097. Reason: nanny-close
2024-01-10 07:02:47,876 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:41535. Reason: nanny-close
2024-01-10 07:02:47,877 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:41103. Reason: nanny-close
2024-01-10 07:02:47,877 - distributed.core - INFO - Connection to tcp://127.0.0.1:34983 has been closed.
2024-01-10 07:02:47,877 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:43245. Reason: nanny-close
2024-01-10 07:02:47,877 - distributed.core - INFO - Connection to tcp://127.0.0.1:34983 has been closed.
2024-01-10 07:02:47,878 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:46457. Reason: nanny-close
2024-01-10 07:02:47,878 - distributed.nanny - INFO - Worker closed
2024-01-10 07:02:47,879 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:46843. Reason: nanny-close
2024-01-10 07:02:47,879 - distributed.worker - INFO - Stopping worker at tcp://127.0.0.1:42327. Reason: nanny-close
2024-01-10 07:02:47,879 - distributed.nanny - INFO - Worker closed
2024-01-10 07:02:47,879 - distributed.core - INFO - Connection to tcp://127.0.0.1:34983 has been closed.
2024-01-10 07:02:47,879 - distributed.core - INFO - Connection to tcp://127.0.0.1:34983 has been closed.
2024-01-10 07:02:47,879 - distributed.core - INFO - Connection to tcp://127.0.0.1:34983 has been closed.
2024-01-10 07:02:47,880 - distributed.core - INFO - Connection to tcp://127.0.0.1:34983 has been closed.
2024-01-10 07:02:47,880 - distributed.nanny - INFO - Worker closed
2024-01-10 07:02:47,880 - distributed.nanny - INFO - Worker closed
2024-01-10 07:02:47,881 - distributed.core - INFO - Connection to tcp://127.0.0.1:34983 has been closed.
2024-01-10 07:02:47,881 - distributed.core - INFO - Connection to tcp://127.0.0.1:34983 has been closed.
2024-01-10 07:02:47,881 - distributed.nanny - INFO - Worker closed
2024-01-10 07:02:47,881 - distributed.nanny - INFO - Worker closed
2024-01-10 07:02:47,882 - distributed.nanny - INFO - Worker closed
2024-01-10 07:02:47,882 - distributed.nanny - INFO - Worker closed
PASSED
dask_cuda/tests/test_local_cuda_cluster.py::test_available_mig_workers SKIPPED
dask_cuda/tests/test_local_cuda_cluster.py::test_gpu_uuid PASSED
dask_cuda/tests/test_local_cuda_cluster.py::test_rmm_track_allocations 2024-01-10 07:02:55,420 - distributed.worker - ERROR - std::bad_alloc: out_of_memory: RMM failure at:/opt/conda/conda-bld/work/include/rmm/mr/device/pool_memory_resource.hpp:273: Maximum pool size exceeded
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 832, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 1873, in plugin_add
    result = plugin.setup(worker=self)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/dask_cuda/plugins.py", line 95, in setup
    rmm.reinitialize(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/rmm/rmm.py", line 81, in reinitialize
    mr._initialize(
  File "memory_resource.pyx", line 945, in rmm._lib.memory_resource._initialize
  File "memory_resource.pyx", line 1005, in rmm._lib.memory_resource._initialize
  File "memory_resource.pyx", line 385, in rmm._lib.memory_resource.PoolMemoryResource.__cinit__
MemoryError: std::bad_alloc: out_of_memory: RMM failure at:/opt/conda/conda-bld/work/include/rmm/mr/device/pool_memory_resource.hpp:273: Maximum pool size exceeded
2024-01-10 07:02:55,424 - distributed.nanny - ERROR - Failed to start worker
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 663, in start
    await wait_for(self.start_unsafe(), timeout=timeout)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 1940, in wait_for
    return await asyncio.wait_for(fut, timeout)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 442, in wait_for
    return await fut
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 1473, in start_unsafe
    raise plugins_exceptions[0]
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 832, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 1873, in plugin_add
    result = plugin.setup(worker=self)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/dask_cuda/plugins.py", line 95, in setup
    rmm.reinitialize(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/rmm/rmm.py", line 81, in reinitialize
    mr._initialize(
  File "memory_resource.pyx", line 945, in rmm._lib.memory_resource._initialize
  File "memory_resource.pyx", line 1005, in rmm._lib.memory_resource._initialize
  File "memory_resource.pyx", line 385, in rmm._lib.memory_resource.PoolMemoryResource.__cinit__
MemoryError: std::bad_alloc: out_of_memory: RMM failure at:/opt/conda/conda-bld/work/include/rmm/mr/device/pool_memory_resource.hpp:273: Maximum pool size exceeded

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 967, in run
    async with worker:
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 677, in __aenter__
    await self
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 671, in start
    raise RuntimeError(f"{type(self).__name__} failed to start.") from exc
RuntimeError: Worker failed to start.
2024-01-10 07:02:55,429 - distributed.worker - ERROR - std::bad_alloc: out_of_memory: RMM failure at:/opt/conda/conda-bld/work/include/rmm/mr/device/pool_memory_resource.hpp:273: Maximum pool size exceeded
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 832, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 1873, in plugin_add
    result = plugin.setup(worker=self)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/dask_cuda/plugins.py", line 95, in setup
    rmm.reinitialize(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/rmm/rmm.py", line 81, in reinitialize
    mr._initialize(
  File "memory_resource.pyx", line 945, in rmm._lib.memory_resource._initialize
  File "memory_resource.pyx", line 1005, in rmm._lib.memory_resource._initialize
  File "memory_resource.pyx", line 385, in rmm._lib.memory_resource.PoolMemoryResource.__cinit__
MemoryError: std::bad_alloc: out_of_memory: RMM failure at:/opt/conda/conda-bld/work/include/rmm/mr/device/pool_memory_resource.hpp:273: Maximum pool size exceeded
2024-01-10 07:02:55,432 - distributed.nanny - ERROR - Failed to start worker
Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 663, in start
    await wait_for(self.start_unsafe(), timeout=timeout)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 1940, in wait_for
    return await asyncio.wait_for(fut, timeout)
  File "/opt/conda/envs/gdf/lib/python3.9/asyncio/tasks.py", line 442, in wait_for
    return await fut
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 1473, in start_unsafe
    raise plugins_exceptions[0]
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 832, in wrapper
    return await func(*args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 1873, in plugin_add
    result = plugin.setup(worker=self)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/dask_cuda/plugins.py", line 95, in setup
    rmm.reinitialize(
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/rmm/rmm.py", line 81, in reinitialize
    mr._initialize(
  File "memory_resource.pyx", line 945, in rmm._lib.memory_resource._initialize
  File "memory_resource.pyx", line 1005, in rmm._lib.memory_resource._initialize
  File "memory_resource.pyx", line 385, in rmm._lib.memory_resource.PoolMemoryResource.__cinit__
MemoryError: std::bad_alloc: out_of_memory: RMM failure at:/opt/conda/conda-bld/work/include/rmm/mr/device/pool_memory_resource.hpp:273: Maximum pool size exceeded

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/nanny.py", line 967, in run
    async with worker:
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 677, in __aenter__
    await self
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/core.py", line 671, in start
    raise RuntimeError(f"{type(self).__name__} failed to start.") from exc
RuntimeError: Worker failed to start.
PASSED
dask_cuda/tests/test_local_cuda_cluster.py::test_get_cluster_configuration PASSED
dask_cuda/tests/test_local_cuda_cluster.py::test_worker_fraction_limits PASSED
dask_cuda/tests/test_local_cuda_cluster.py::test_print_cluster_config[ucx] PASSED
dask_cuda/tests/test_local_cuda_cluster.py::test_print_cluster_config[ucxx] PASSED
dask_cuda/tests/test_local_cuda_cluster.py::test_death_timeout_raises XFAIL
dask_cuda/tests/test_proxify_host_file.py::test_one_dev_item_limit PASSED
dask_cuda/tests/test_proxify_host_file.py::test_one_item_host_limit PASSED
dask_cuda/tests/test_proxify_host_file.py::test_spill_on_demand PASSED
dask_cuda/tests/test_proxify_host_file.py::test_local_cuda_cluster[True] PASSED
dask_cuda/tests/test_proxify_host_file.py::test_local_cuda_cluster[False] PASSED
dask_cuda/tests/test_proxify_host_file.py::test_dataframes_share_dev_mem PASSED
dask_cuda/tests/test_proxify_host_file.py::test_cudf_get_device_memory_objects PASSED
dask_cuda/tests/test_proxify_host_file.py::test_externals PASSED
dask_cuda/tests/test_proxify_host_file.py::test_incompatible_types PASSED
dask_cuda/tests/test_proxify_host_file.py::test_compatibility_mode_dataframe_shuffle[True-1] PASSED
dask_cuda/tests/test_proxify_host_file.py::test_compatibility_mode_dataframe_shuffle[True-2] PASSED
dask_cuda/tests/test_proxify_host_file.py::test_compatibility_mode_dataframe_shuffle[True-3] PASSED
dask_cuda/tests/test_proxify_host_file.py::test_compatibility_mode_dataframe_shuffle[False-1] PASSED
dask_cuda/tests/test_proxify_host_file.py::test_compatibility_mode_dataframe_shuffle[False-2] PASSED
dask_cuda/tests/test_proxify_host_file.py::test_compatibility_mode_dataframe_shuffle[False-3] PASSED
dask_cuda/tests/test_proxify_host_file.py::test_worker_force_spill_to_disk PASSED
dask_cuda/tests/test_proxify_host_file.py::test_on_demand_debug_info 2024-01-10 07:04:18,799 - distributed.worker - WARNING - RMM allocation of 1.00 MiB failed, spill-on-demand couldn't find any device memory to spill.
RMM allocs: 1.00 MiB, <ProxyManager dev_limit=25.60 GiB host_limit=0.98 TiB disk=0 B(0) host=0 B(0) dev=0 B(0)>, traceback:
  File "/opt/conda/envs/gdf/lib/python3.9/threading.py", line 937, in _bootstrap
    self._bootstrap_inner()
  File "/opt/conda/envs/gdf/lib/python3.9/threading.py", line 980, in _bootstrap_inner
    self.run()
  File "/opt/conda/envs/gdf/lib/python3.9/threading.py", line 917, in run
    self._target(*self._args, **self._kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/threadpoolexecutor.py", line 57, in _worker
    task.run()
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/_concurrent_futures_thread.py", line 65, in run
    result = self.fn(*self.args, **self.kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/utils.py", line 1541, in <lambda>
    executor, lambda: context.run(func, *args, **kwargs)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2954, in apply_function
    msg = apply_function_simple(function, args, kwargs, time_delay)
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/distributed/worker.py", line 2990, in apply_function_simple
    result = function(*args, **kwargs)
  File "/usr/src/dask-cuda/dask_cuda/tests/test_proxify_host_file.py", line 467, in task
    rmm.DeviceBuffer(size=rmm_pool_size),  # Trigger OOM
  File "/opt/conda/envs/gdf/lib/python3.9/site-packages/dask_cuda/proxify_host_file.py", line 617, in oom
    traceback.print_stack(file=f)


2024-01-10 07:04:19,016 - distributed.worker - WARNING - Compute Failed
Key:       task-5c302f54392a5ca98adb3c55c8357b0e
Function:  task
args:      ()
kwargs:    {}
Exception: "MemoryError('std::bad_alloc: out_of_memory: RMM failure at:/opt/conda/conda-bld/work/include/rmm/mr/device/pool_memory_resource.hpp:273: Maximum pool size exceeded')"

PASSED
dask_cuda/tests/test_proxy.py::test_proxy_object[None] PASSED
dask_cuda/tests/test_proxy.py::test_proxy_object[serializers1] PASSED
dask_cuda/tests/test_proxy.py::test_proxy_object[serializers2] PASSED
dask_cuda/tests/test_proxy.py::test_proxy_object_serializer PASSED
dask_cuda/tests/test_proxy.py::test_double_proxy_object[None-None] PASSED
dask_cuda/tests/test_proxy.py::test_double_proxy_object[None-serializers_first1] PASSED
dask_cuda/tests/test_proxy.py::test_double_proxy_object[None-serializers_first2] PASSED
dask_cuda/tests/test_proxy.py::test_double_proxy_object[serializers_second1-None] PASSED
dask_cuda/tests/test_proxy.py::test_double_proxy_object[serializers_second1-serializers_first1] PASSED
dask_cuda/tests/test_proxy.py::test_double_proxy_object[serializers_second1-serializers_first2] PASSED
dask_cuda/tests/test_proxy.py::test_double_proxy_object[serializers_second2-None] PASSED
dask_cuda/tests/test_proxy.py::test_double_proxy_object[serializers_second2-serializers_first1] PASSED
dask_cuda/tests/test_proxy.py::test_double_proxy_object[serializers_second2-serializers_first2] PASSED
dask_cuda/tests/test_proxy.py::test_proxy_object_of_array[numpy-None] PASSED
dask_cuda/tests/test_proxy.py::test_proxy_object_of_array[numpy-serializers1] PASSED
dask_cuda/tests/test_proxy.py::test_proxy_object_of_array[numpy-serializers2] PASSED
dask_cuda/tests/test_proxy.py::test_proxy_object_of_array[cupy-None] PASSED
dask_cuda/tests/test_proxy.py::test_proxy_object_of_array[cupy-serializers1] PASSED
dask_cuda/tests/test_proxy.py::test_proxy_object_of_array[cupy-serializers2] PASSED
dask_cuda/tests/test_proxy.py::test_proxy_object_of_cudf[None] PASSED
dask_cuda/tests/test_proxy.py::test_proxy_object_of_cudf[serializers1] PASSED
dask_cuda/tests/test_proxy.py::test_proxy_object_of_cudf[serializers2] PASSED
dask_cuda/tests/test_proxy.py::test_serialize_of_proxied_cudf[dask_serializers0-None] PASSED
dask_cuda/tests/test_proxy.py::test_serialize_of_proxied_cudf[dask_serializers0-proxy_serializers1] PASSED
dask_cuda/tests/test_proxy.py::test_serialize_of_proxied_cudf[dask_serializers0-proxy_serializers2] PASSED
dask_cuda/tests/test_proxy.py::test_serialize_of_proxied_cudf[dask_serializers0-proxy_serializers3] PASSED
dask_cuda/tests/test_proxy.py::test_serialize_of_proxied_cudf[dask_serializers1-None] PASSED
dask_cuda/tests/test_proxy.py::test_serialize_of_proxied_cudf[dask_serializers1-proxy_serializers1] PASSED
dask_cuda/tests/test_proxy.py::test_serialize_of_proxied_cudf[dask_serializers1-proxy_serializers2] PASSED
dask_cuda/tests/test_proxy.py::test_serialize_of_proxied_cudf[dask_serializers1-proxy_serializers3] PASSED
dask_cuda/tests/test_proxy.py::test_fixed_attribute_length[numpy] PASSED
dask_cuda/tests/test_proxy.py::test_fixed_attribute_length[cupy] 