2023-04-18 22:45:08,667 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-04-18 22:45:08,667 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-04-18 22:45:08,667 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-04-18 22:45:08,667 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-04-18 22:45:08,667 - distributed.diskutils - ERROR - Failed to clean up lingering worker directories in path: %s 
Traceback (most recent call last):
  File "/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/diskutils.py", line 268, in new_work_dir
    self._purge_leftovers()
  File "/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/diskutils.py", line 199, in _purge_leftovers
    if self._check_lock_or_purge(path):
  File "/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/diskutils.py", line 234, in _check_lock_or_purge
    lock.acquire()
  File "/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/locket/__init__.py", line 198, in acquire
    self._lock.acquire(self._timeout, self._retry_period)
  File "/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/locket/__init__.py", line 118, in acquire
    lock.acquire(timeout, retry_period)
  File "/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/locket/__init__.py", line 158, in acquire
    fileobj = open(self._path, "wb")
PermissionError: [Errno 13] Permission denied: '/tmp/dask-worker-space/worker-usav5jtm.dirlock'
2023-04-18 22:45:08,668 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-04-18 22:45:08,669 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-04-18 22:45:08,668 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-04-18 22:45:08,669 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-04-18 22:45:08,669 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-04-18 22:45:08,669 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-04-18 22:45:08,669 - distributed.diskutils - ERROR - Failed to clean up lingering worker directories in path: %s 
Traceback (most recent call last):
  File "/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/diskutils.py", line 268, in new_work_dir
    self._purge_leftovers()
  File "/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/diskutils.py", line 199, in _purge_leftovers
    if self._check_lock_or_purge(path):
  File "/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/diskutils.py", line 234, in _check_lock_or_purge
    lock.acquire()
  File "/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/locket/__init__.py", line 198, in acquire
    self._lock.acquire(self._timeout, self._retry_period)
  File "/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/locket/__init__.py", line 118, in acquire
    lock.acquire(timeout, retry_period)
  File "/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/locket/__init__.py", line 158, in acquire
    fileobj = open(self._path, "wb")
PermissionError: [Errno 13] Permission denied: '/tmp/dask-worker-space/worker-usav5jtm.dirlock'
2023-04-18 22:45:08,670 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-04-18 22:45:08,670 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-04-18 22:45:08,673 - distributed.diskutils - ERROR - Failed to clean up lingering worker directories in path: %s 
Traceback (most recent call last):
  File "/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/diskutils.py", line 268, in new_work_dir
    self._purge_leftovers()
  File "/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/diskutils.py", line 199, in _purge_leftovers
    if self._check_lock_or_purge(path):
  File "/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/diskutils.py", line 234, in _check_lock_or_purge
    lock.acquire()
  File "/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/locket/__init__.py", line 198, in acquire
    self._lock.acquire(self._timeout, self._retry_period)
  File "/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/locket/__init__.py", line 118, in acquire
    lock.acquire(timeout, retry_period)
  File "/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/locket/__init__.py", line 158, in acquire
    fileobj = open(self._path, "wb")
PermissionError: [Errno 13] Permission denied: '/tmp/dask-worker-space/worker-usav5jtm.dirlock'
2023-04-18 22:45:08,675 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-04-18 22:45:08,675 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-04-18 22:45:08,674 - distributed.diskutils - ERROR - Failed to clean up lingering worker directories in path: %s 
Traceback (most recent call last):
  File "/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/diskutils.py", line 268, in new_work_dir
    self._purge_leftovers()
  File "/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/diskutils.py", line 199, in _purge_leftovers
    if self._check_lock_or_purge(path):
  File "/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/diskutils.py", line 234, in _check_lock_or_purge
    lock.acquire()
  File "/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/locket/__init__.py", line 198, in acquire
    self._lock.acquire(self._timeout, self._retry_period)
  File "/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/locket/__init__.py", line 118, in acquire
    lock.acquire(timeout, retry_period)
  File "/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/locket/__init__.py", line 158, in acquire
    fileobj = open(self._path, "wb")
PermissionError: [Errno 13] Permission denied: '/tmp/dask-worker-space/worker-usav5jtm.dirlock'
2023-04-18 22:45:08,676 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-04-18 22:45:08,676 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
[dgx13:72232:0:72232] Caught signal 11 (Segmentation fault: address not mapped to object at address 0x448)
==== backtrace (tid:  72232) ====
 0  /datasets/pentschev/miniconda3/envs/gdf/lib/libucs.so.0(ucs_handle_error+0x2d4) [0x7fb4e36266b4]
 1  /datasets/pentschev/miniconda3/envs/gdf/lib/libucs.so.0(+0x2d88f) [0x7fb4e362688f]
 2  /datasets/pentschev/miniconda3/envs/gdf/lib/libucs.so.0(+0x2dbb4) [0x7fb4e3626bb4]
 3  /lib/x86_64-linux-gnu/libpthread.so.0(+0x12980) [0x7fb5b0546980]
 4  /datasets/pentschev/miniconda3/envs/gdf/lib/libucp.so.0(ucp_mem_type_unpack+0x17) [0x7fb4e38a21b7]
 5  /datasets/pentschev/miniconda3/envs/gdf/lib/libucp.so.0(ucp_rndv_data_handler+0x508) [0x7fb4e38cb638]
 6  /datasets/pentschev/miniconda3/envs/gdf/lib/libuct.so.0(+0x1f0ff) [0x7fb4e33de0ff]
 7  /datasets/pentschev/miniconda3/envs/gdf/lib/libuct.so.0(+0x1f674) [0x7fb4e33de674]
 8  /datasets/pentschev/miniconda3/envs/gdf/lib/libuct.so.0(+0x21a78) [0x7fb4e33e0a78]
 9  /datasets/pentschev/miniconda3/envs/gdf/lib/libucs.so.0(ucs_event_set_wait+0xb9) [0x7fb4e36308a9]
10  /datasets/pentschev/miniconda3/envs/gdf/lib/libuct.so.0(uct_tcp_iface_progress+0x7b) [0x7fb4e33e0b1b]
11  /datasets/pentschev/miniconda3/envs/gdf/lib/libucp.so.0(ucp_worker_progress+0x6a) [0x7fb4e389ef5a]
12  /datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/ucp/_libs/ucx_api.cpython-38-x86_64-linux-gnu.so(+0x272d9) [0x7fb4e3b4b2d9]
13  /datasets/pentschev/miniconda3/envs/gdf/bin/python(+0x12e343) [0x55bf9fb48343]
14  /datasets/pentschev/miniconda3/envs/gdf/bin/python(PyObject_Call+0x24a) [0x55bf9fb531fa]
15  /datasets/pentschev/miniconda3/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x680b) [0x55bf9fb39b8b]
16  /datasets/pentschev/miniconda3/envs/gdf/bin/python(_PyEval_EvalCodeWithName+0x2f1) [0x55bf9fb322f1]
17  /datasets/pentschev/miniconda3/envs/gdf/bin/python(_PyFunction_Vectorcall+0x19c) [0x55bf9fb4393c]
18  /datasets/pentschev/miniconda3/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x6d5) [0x55bf9fb33a55]
19  /datasets/pentschev/miniconda3/envs/gdf/bin/python(_PyFunction_Vectorcall+0x106) [0x55bf9fb438a6]
20  /datasets/pentschev/miniconda3/envs/gdf/bin/python(+0x136c36) [0x55bf9fb50c36]
21  /datasets/pentschev/miniconda3/envs/gdf/bin/python(+0x23565a) [0x55bf9fc4f65a]
22  /datasets/pentschev/miniconda3/envs/gdf/bin/python(+0xe0b07) [0x55bf9fafab07]
23  /datasets/pentschev/miniconda3/envs/gdf/bin/python(+0x120f96) [0x55bf9fb3af96]
24  /datasets/pentschev/miniconda3/envs/gdf/bin/python(PyVectorcall_Call+0x7a) [0x55bf9fb511ea]
25  /datasets/pentschev/miniconda3/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x5df8) [0x55bf9fb39178]
26  /datasets/pentschev/miniconda3/envs/gdf/bin/python(_PyFunction_Vectorcall+0x106) [0x55bf9fb438a6]
27  /datasets/pentschev/miniconda3/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x6d5) [0x55bf9fb33a55]
28  /datasets/pentschev/miniconda3/envs/gdf/bin/python(_PyFunction_Vectorcall+0x106) [0x55bf9fb438a6]
29  /datasets/pentschev/miniconda3/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x6d5) [0x55bf9fb33a55]
30  /datasets/pentschev/miniconda3/envs/gdf/bin/python(_PyFunction_Vectorcall+0x106) [0x55bf9fb438a6]
31  /datasets/pentschev/miniconda3/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x6d5) [0x55bf9fb33a55]
32  /datasets/pentschev/miniconda3/envs/gdf/bin/python(_PyFunction_Vectorcall+0x106) [0x55bf9fb438a6]
33  /datasets/pentschev/miniconda3/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x6d5) [0x55bf9fb33a55]
34  /datasets/pentschev/miniconda3/envs/gdf/bin/python(_PyEval_EvalCodeWithName+0x2f1) [0x55bf9fb322f1]
35  /datasets/pentschev/miniconda3/envs/gdf/bin/python(_PyFunction_Vectorcall+0x19c) [0x55bf9fb4393c]
36  /datasets/pentschev/miniconda3/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x4b7b) [0x55bf9fb37efb]
37  /datasets/pentschev/miniconda3/envs/gdf/bin/python(_PyEval_EvalCodeWithName+0x2f1) [0x55bf9fb322f1]
38  /datasets/pentschev/miniconda3/envs/gdf/bin/python(_PyFunction_Vectorcall+0x19c) [0x55bf9fb4393c]
39  /datasets/pentschev/miniconda3/envs/gdf/bin/python(+0x136e8c) [0x55bf9fb50e8c]
40  /datasets/pentschev/miniconda3/envs/gdf/bin/python(_PyObject_FastCallDict+0x282) [0x55bf9fb3ba92]
41  /datasets/pentschev/miniconda3/envs/gdf/bin/python(+0x1ee049) [0x55bf9fc08049]
42  /datasets/pentschev/miniconda3/envs/gdf/bin/python(PyObject_Call+0x2d3) [0x55bf9fb53283]
43  /datasets/pentschev/miniconda3/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x205e) [0x55bf9fb353de]
44  /datasets/pentschev/miniconda3/envs/gdf/bin/python(_PyFunction_Vectorcall+0x106) [0x55bf9fb438a6]
45  /datasets/pentschev/miniconda3/envs/gdf/bin/python(+0x136e8c) [0x55bf9fb50e8c]
46  /datasets/pentschev/miniconda3/envs/gdf/bin/python(PyObject_Call+0x24a) [0x55bf9fb531fa]
47  /datasets/pentschev/miniconda3/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x205e) [0x55bf9fb353de]
48  /datasets/pentschev/miniconda3/envs/gdf/bin/python(_PyFunction_Vectorcall+0x106) [0x55bf9fb438a6]
49  /datasets/pentschev/miniconda3/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x6d5) [0x55bf9fb33a55]
50  /datasets/pentschev/miniconda3/envs/gdf/bin/python(_PyEval_EvalCodeWithName+0x2f1) [0x55bf9fb322f1]
51  /datasets/pentschev/miniconda3/envs/gdf/bin/python(_PyFunction_Vectorcall+0x19c) [0x55bf9fb4393c]
52  /datasets/pentschev/miniconda3/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x6d5) [0x55bf9fb33a55]
53  /datasets/pentschev/miniconda3/envs/gdf/bin/python(_PyFunction_Vectorcall+0x106) [0x55bf9fb438a6]
54  /datasets/pentschev/miniconda3/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x3a9) [0x55bf9fb33729]
55  /datasets/pentschev/miniconda3/envs/gdf/bin/python(_PyEval_EvalCodeWithName+0x2f1) [0x55bf9fb322f1]
56  /datasets/pentschev/miniconda3/envs/gdf/bin/python(_PyFunction_Vectorcall+0x19c) [0x55bf9fb4393c]
57  /datasets/pentschev/miniconda3/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x11bf) [0x55bf9fb3453f]
58  /datasets/pentschev/miniconda3/envs/gdf/bin/python(_PyEval_EvalCodeWithName+0x2f1) [0x55bf9fb322f1]
59  /datasets/pentschev/miniconda3/envs/gdf/bin/python(PyEval_EvalCodeEx+0x39) [0x55bf9fbe4e99]
60  /datasets/pentschev/miniconda3/envs/gdf/bin/python(PyEval_EvalCode+0x1b) [0x55bf9fbe4e5b]
61  /datasets/pentschev/miniconda3/envs/gdf/bin/python(+0x1eb7f9) [0x55bf9fc057f9]
=================================
2023-04-18 22:45:16,316 - distributed.worker - ERROR - Worker stream died during communication: ucx://127.0.0.1:51031
Traceback (most recent call last):
  File "/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/comm/ucx.py", line 349, in read
    await self.ep.recv(msg)
  File "/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/ucp/core.py", line 725, in recv
    ret = await comm.tag_recv(self._ep, buffer, nbytes, tag, name=log)
ucp._libs.exceptions.UCXCanceled: <[Recv #003] ep: 0x7fc55d179100, tag: 0x6a9eeee0b28dbebd, nbytes: 16, type: <class 'numpy.ndarray'>>: 

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/worker.py", line 2066, in gather_dep
    response = await get_data_from_worker(
  File "/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/worker.py", line 2892, in get_data_from_worker
    response = await send_recv(
  File "/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/core.py", line 1024, in send_recv
    response = await comm.read(deserializers=deserializers)
  File "/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/comm/ucx.py", line 367, in read
    raise CommClosedError(
distributed.comm.core.CommClosedError: Connection closed by writer.
Inner exception: UCXCanceled("<[Recv #003] ep: 0x7fc55d179100, tag: 0x6a9eeee0b28dbebd, nbytes: 16, type: <class 'numpy.ndarray'>>: ")
2023-04-18 22:45:16,316 - distributed.worker - ERROR - Worker stream died during communication: ucx://127.0.0.1:51031
Traceback (most recent call last):
  File "/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/comm/ucx.py", line 349, in read
    await self.ep.recv(msg)
  File "/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/ucp/core.py", line 725, in recv
    ret = await comm.tag_recv(self._ep, buffer, nbytes, tag, name=log)
ucp._libs.exceptions.UCXCanceled: <[Recv #003] ep: 0x7ff3540b8280, tag: 0xcf20db7c6d556c4e, nbytes: 16, type: <class 'numpy.ndarray'>>: 

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/worker.py", line 2066, in gather_dep
    response = await get_data_from_worker(
  File "/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/worker.py", line 2892, in get_data_from_worker
    response = await send_recv(
  File "/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/core.py", line 1024, in send_recv
    response = await comm.read(deserializers=deserializers)
  File "/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/comm/ucx.py", line 367, in read
    raise CommClosedError(
distributed.comm.core.CommClosedError: Connection closed by writer.
Inner exception: UCXCanceled("<[Recv #003] ep: 0x7ff3540b8280, tag: 0xcf20db7c6d556c4e, nbytes: 16, type: <class 'numpy.ndarray'>>: ")
2023-04-18 22:45:16,316 - distributed.worker - ERROR - Worker stream died during communication: ucx://127.0.0.1:51031
Traceback (most recent call last):
  File "/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/comm/ucx.py", line 349, in read
    await self.ep.recv(msg)
  File "/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/ucp/core.py", line 725, in recv
    ret = await comm.tag_recv(self._ep, buffer, nbytes, tag, name=log)
ucp._libs.exceptions.UCXCanceled: <[Recv #003] ep: 0x7f8740de91c0, tag: 0xe8f47f65f9d6e2e4, nbytes: 16, type: <class 'numpy.ndarray'>>: 

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/worker.py", line 2066, in gather_dep
    response = await get_data_from_worker(
  File "/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/worker.py", line 2892, in get_data_from_worker
    response = await send_recv(
  File "/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/core.py", line 1024, in send_recv
    response = await comm.read(deserializers=deserializers)
  File "/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/comm/ucx.py", line 367, in read
    raise CommClosedError(
distributed.comm.core.CommClosedError: Connection closed by writer.
Inner exception: UCXCanceled("<[Recv #003] ep: 0x7f8740de91c0, tag: 0xe8f47f65f9d6e2e4, nbytes: 16, type: <class 'numpy.ndarray'>>: ")
2023-04-18 22:45:16,318 - distributed.worker - ERROR - failed during get data with ucx://127.0.0.1:49777 -> ucx://127.0.0.1:51031
Traceback (most recent call last):
  File "/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/comm/ucx.py", line 333, in write
    await self.ep.send(each_frame)
  File "/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/ucp/core.py", line 650, in send
    return await comm.tag_send(self._ep, buffer, nbytes, tag, name=log)
ucp._libs.exceptions.UCXError: <[Send #007] ep: 0x7f8740de9340, tag: 0x9a2efdc5e1b21899, nbytes: 100000000, type: <class 'cudf.core.buffer.buffer.Buffer'>>: Endpoint timeout

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/worker.py", line 1792, in get_data
    compressed = await comm.write(msg, serializers=serializers)
  File "/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/comm/ucx.py", line 337, in write
    raise CommClosedError("While writing, the connection was closed")
distributed.comm.core.CommClosedError: While writing, the connection was closed
2023-04-18 22:45:16,316 - distributed.worker - ERROR - Worker stream died during communication: ucx://127.0.0.1:51031
Traceback (most recent call last):
  File "/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/comm/ucx.py", line 349, in read
    await self.ep.recv(msg)
  File "/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/ucp/core.py", line 725, in recv
    ret = await comm.tag_recv(self._ep, buffer, nbytes, tag, name=log)
ucp._libs.exceptions.UCXCanceled: <[Recv #003] ep: 0x7f5df0876180, tag: 0x5b91e843efe4ddbe, nbytes: 16, type: <class 'numpy.ndarray'>>: 

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/worker.py", line 2066, in gather_dep
    response = await get_data_from_worker(
  File "/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/worker.py", line 2892, in get_data_from_worker
    response = await send_recv(
  File "/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/core.py", line 1024, in send_recv
    response = await comm.read(deserializers=deserializers)
  File "/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/comm/ucx.py", line 367, in read
    raise CommClosedError(
distributed.comm.core.CommClosedError: Connection closed by writer.
Inner exception: UCXCanceled("<[Recv #003] ep: 0x7f5df0876180, tag: 0x5b91e843efe4ddbe, nbytes: 16, type: <class 'numpy.ndarray'>>: ")
2023-04-18 22:45:16,333 - distributed.worker - ERROR - failed during get data with ucx://127.0.0.1:54897 -> ucx://127.0.0.1:51031
Traceback (most recent call last):
  File "/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/comm/ucx.py", line 315, in write
    await self.ep.send(struct.pack("?Q", False, nframes))
  File "/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/ucp/core.py", line 629, in send
    self._ep.raise_on_error()
  File "ucp/_libs/ucx_endpoint.pyx", line 355, in ucp._libs.ucx_api.UCXEndpoint.raise_on_error
ucp._libs.exceptions.UCXError: Endpoint 0x7f211014b2c0 error: Endpoint timeout

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/worker.py", line 1792, in get_data
    compressed = await comm.write(msg, serializers=serializers)
  File "/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/comm/ucx.py", line 337, in write
    raise CommClosedError("While writing, the connection was closed")
distributed.comm.core.CommClosedError: While writing, the connection was closed
2023-04-18 22:45:16,373 - distributed.nanny - WARNING - Restarting worker
[dgx13:72217:0:72217] Caught signal 11 (Segmentation fault: address not mapped to object at address 0x448)
==== backtrace (tid:  72217) ====
 0  /datasets/pentschev/miniconda3/envs/gdf/lib/libucs.so.0(ucs_handle_error+0x2d4) [0x7fc5715866b4]
 1  /datasets/pentschev/miniconda3/envs/gdf/lib/libucs.so.0(+0x2d88f) [0x7fc57158688f]
 2  /datasets/pentschev/miniconda3/envs/gdf/lib/libucs.so.0(+0x2dbb4) [0x7fc571586bb4]
 3  /lib/x86_64-linux-gnu/libpthread.so.0(+0x12980) [0x7fc618427980]
 4  /datasets/pentschev/miniconda3/envs/gdf/lib/libucp.so.0(ucp_mem_type_unpack+0x17) [0x7fc5718021b7]
 5  /datasets/pentschev/miniconda3/envs/gdf/lib/libucp.so.0(ucp_rndv_data_handler+0x508) [0x7fc57182b638]
 6  /datasets/pentschev/miniconda3/envs/gdf/lib/libuct.so.0(+0x1f0ff) [0x7fc57133e0ff]
 7  /datasets/pentschev/miniconda3/envs/gdf/lib/libuct.so.0(+0x1f674) [0x7fc57133e674]
 8  /datasets/pentschev/miniconda3/envs/gdf/lib/libuct.so.0(+0x21a78) [0x7fc571340a78]
 9  /datasets/pentschev/miniconda3/envs/gdf/lib/libucs.so.0(ucs_event_set_wait+0xb9) [0x7fc5715908a9]
10  /datasets/pentschev/miniconda3/envs/gdf/lib/libuct.so.0(uct_tcp_iface_progress+0x7b) [0x7fc571340b1b]
11  /datasets/pentschev/miniconda3/envs/gdf/lib/libucp.so.0(ucp_worker_progress+0x6a) [0x7fc5717fef5a]
12  /datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/ucp/_libs/ucx_api.cpython-38-x86_64-linux-gnu.so(+0x272d9) [0x7fc571aab2d9]
13  /datasets/pentschev/miniconda3/envs/gdf/bin/python(+0x12e343) [0x563e8731f343]
14  /datasets/pentschev/miniconda3/envs/gdf/bin/python(PyObject_Call+0x24a) [0x563e8732a1fa]
15  /datasets/pentschev/miniconda3/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x680b) [0x563e87310b8b]
16  /datasets/pentschev/miniconda3/envs/gdf/bin/python(_PyEval_EvalCodeWithName+0x2f1) [0x563e873092f1]
17  /datasets/pentschev/miniconda3/envs/gdf/bin/python(_PyFunction_Vectorcall+0x19c) [0x563e8731a93c]
18  /datasets/pentschev/miniconda3/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x6d5) [0x563e8730aa55]
19  /datasets/pentschev/miniconda3/envs/gdf/bin/python(+0x13e1e8) [0x563e8732f1e8]
20  /datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/lib-dynload/_asyncio.cpython-38-x86_64-linux-gnu.so(+0x7003) [0x7fc596d2f003]
21  /datasets/pentschev/miniconda3/envs/gdf/bin/python(_PyObject_MakeTpCall+0x3db) [0x563e8731330b]
22  /datasets/pentschev/miniconda3/envs/gdf/bin/python(+0xe0b07) [0x563e872d1b07]
23  /datasets/pentschev/miniconda3/envs/gdf/bin/python(+0x120f96) [0x563e87311f96]
24  /datasets/pentschev/miniconda3/envs/gdf/bin/python(PyVectorcall_Call+0x7a) [0x563e873281ea]
25  /datasets/pentschev/miniconda3/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x5df8) [0x563e87310178]
26  /datasets/pentschev/miniconda3/envs/gdf/bin/python(_PyFunction_Vectorcall+0x106) [0x563e8731a8a6]
27  /datasets/pentschev/miniconda3/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x6d5) [0x563e8730aa55]
28  /datasets/pentschev/miniconda3/envs/gdf/bin/python(_PyFunction_Vectorcall+0x106) [0x563e8731a8a6]
29  /datasets/pentschev/miniconda3/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x6d5) [0x563e8730aa55]
30  /datasets/pentschev/miniconda3/envs/gdf/bin/python(_PyFunction_Vectorcall+0x106) [0x563e8731a8a6]
31  /datasets/pentschev/miniconda3/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x6d5) [0x563e8730aa55]
32  /datasets/pentschev/miniconda3/envs/gdf/bin/python(_PyFunction_Vectorcall+0x106) [0x563e8731a8a6]
33  /datasets/pentschev/miniconda3/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x6d5) [0x563e8730aa55]
34  /datasets/pentschev/miniconda3/envs/gdf/bin/python(_PyEval_EvalCodeWithName+0x2f1) [0x563e873092f1]
35  /datasets/pentschev/miniconda3/envs/gdf/bin/python(_PyFunction_Vectorcall+0x19c) [0x563e8731a93c]
36  /datasets/pentschev/miniconda3/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x4b7b) [0x563e8730eefb]
37  /datasets/pentschev/miniconda3/envs/gdf/bin/python(_PyEval_EvalCodeWithName+0x2f1) [0x563e873092f1]
38  /datasets/pentschev/miniconda3/envs/gdf/bin/python(_PyFunction_Vectorcall+0x19c) [0x563e8731a93c]
39  /datasets/pentschev/miniconda3/envs/gdf/bin/python(+0x136e8c) [0x563e87327e8c]
40  /datasets/pentschev/miniconda3/envs/gdf/bin/python(_PyObject_FastCallDict+0x282) [0x563e87312a92]
41  /datasets/pentschev/miniconda3/envs/gdf/bin/python(+0x1ee049) [0x563e873df049]
42  /datasets/pentschev/miniconda3/envs/gdf/bin/python(PyObject_Call+0x2d3) [0x563e8732a283]
43  /datasets/pentschev/miniconda3/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x205e) [0x563e8730c3de]
44  /datasets/pentschev/miniconda3/envs/gdf/bin/python(_PyFunction_Vectorcall+0x106) [0x563e8731a8a6]
45  /datasets/pentschev/miniconda3/envs/gdf/bin/python(+0x136e8c) [0x563e87327e8c]
46  /datasets/pentschev/miniconda3/envs/gdf/bin/python(PyObject_Call+0x24a) [0x563e8732a1fa]
47  /datasets/pentschev/miniconda3/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x205e) [0x563e8730c3de]
48  /datasets/pentschev/miniconda3/envs/gdf/bin/python(_PyFunction_Vectorcall+0x106) [0x563e8731a8a6]
49  /datasets/pentschev/miniconda3/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x6d5) [0x563e8730aa55]
50  /datasets/pentschev/miniconda3/envs/gdf/bin/python(_PyEval_EvalCodeWithName+0x2f1) [0x563e873092f1]
51  /datasets/pentschev/miniconda3/envs/gdf/bin/python(_PyFunction_Vectorcall+0x19c) [0x563e8731a93c]
52  /datasets/pentschev/miniconda3/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x6d5) [0x563e8730aa55]
53  /datasets/pentschev/miniconda3/envs/gdf/bin/python(_PyFunction_Vectorcall+0x106) [0x563e8731a8a6]
54  /datasets/pentschev/miniconda3/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x3a9) [0x563e8730a729]
55  /datasets/pentschev/miniconda3/envs/gdf/bin/python(_PyEval_EvalCodeWithName+0x2f1) [0x563e873092f1]
56  /datasets/pentschev/miniconda3/envs/gdf/bin/python(_PyFunction_Vectorcall+0x19c) [0x563e8731a93c]
57  /datasets/pentschev/miniconda3/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x11bf) [0x563e8730b53f]
58  /datasets/pentschev/miniconda3/envs/gdf/bin/python(_PyEval_EvalCodeWithName+0x2f1) [0x563e873092f1]
59  /datasets/pentschev/miniconda3/envs/gdf/bin/python(PyEval_EvalCodeEx+0x39) [0x563e873bbe99]
60  /datasets/pentschev/miniconda3/envs/gdf/bin/python(PyEval_EvalCode+0x1b) [0x563e873bbe5b]
61  /datasets/pentschev/miniconda3/envs/gdf/bin/python(+0x1eb7f9) [0x563e873dc7f9]
=================================
2023-04-18 22:45:16,450 - distributed.worker - ERROR - Worker stream died during communication: ucx://127.0.0.1:51031
Traceback (most recent call last):
  File "/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/comm/ucx.py", line 391, in read
    await self.ep.recv(each_frame)
  File "/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/ucp/core.py", line 725, in recv
    ret = await comm.tag_recv(self._ep, buffer, nbytes, tag, name=log)
ucp._libs.exceptions.UCXCanceled: <[Recv #009] ep: 0x7fe7002fe200, tag: 0x4d788f1b3c4cb168, nbytes: 100000000, type: <class 'rmm._lib.device_buffer.DeviceBuffer'>>: 

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/worker.py", line 2066, in gather_dep
    response = await get_data_from_worker(
  File "/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/worker.py", line 2892, in get_data_from_worker
    response = await send_recv(
  File "/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/core.py", line 1024, in send_recv
    response = await comm.read(deserializers=deserializers)
  File "/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/comm/ucx.py", line 397, in read
    raise CommClosedError(
distributed.comm.core.CommClosedError: Connection closed by writer.
Inner exception: UCXCanceled("<[Recv #009] ep: 0x7fe7002fe200, tag: 0x4d788f1b3c4cb168, nbytes: 100000000, type: <class 'rmm._lib.device_buffer.DeviceBuffer'>>: ")
[dgx13:72241:0:72241] Caught signal 11 (Segmentation fault: address not mapped to object at address 0x448)
==== backtrace (tid:  72241) ====
 0  /datasets/pentschev/miniconda3/envs/gdf/lib/libucs.so.0(ucs_handle_error+0x2d4) [0x7f2921dcd6b4]
 1  /datasets/pentschev/miniconda3/envs/gdf/lib/libucs.so.0(+0x2d88f) [0x7f2921dcd88f]
 2  /datasets/pentschev/miniconda3/envs/gdf/lib/libucs.so.0(+0x2dbb4) [0x7f2921dcdbb4]
 3  /lib/x86_64-linux-gnu/libpthread.so.0(+0x12980) [0x7f29c4c90980]
 4  /datasets/pentschev/miniconda3/envs/gdf/lib/libucp.so.0(ucp_mem_type_unpack+0x17) [0x7f29240861b7]
 5  /datasets/pentschev/miniconda3/envs/gdf/lib/libucp.so.0(ucp_rndv_data_handler+0x508) [0x7f29240af638]
 6  /datasets/pentschev/miniconda3/envs/gdf/lib/libuct.so.0(+0x1f0ff) [0x7f2921b850ff]
 7  /datasets/pentschev/miniconda3/envs/gdf/lib/libuct.so.0(+0x1f674) [0x7f2921b85674]
 8  /datasets/pentschev/miniconda3/envs/gdf/lib/libuct.so.0(+0x21a78) [0x7f2921b87a78]
 9  /datasets/pentschev/miniconda3/envs/gdf/lib/libucs.so.0(ucs_event_set_wait+0xb9) [0x7f2921dd78a9]
10  /datasets/pentschev/miniconda3/envs/gdf/lib/libuct.so.0(uct_tcp_iface_progress+0x7b) [0x7f2921b87b1b]
11  /datasets/pentschev/miniconda3/envs/gdf/lib/libucp.so.0(ucp_worker_progress+0x6a) [0x7f2924082f5a]
12  /datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/ucp/_libs/ucx_api.cpython-38-x86_64-linux-gnu.so(+0x272d9) [0x7f292432f2d9]
13  /datasets/pentschev/miniconda3/envs/gdf/bin/python(+0x12e343) [0x56272f8d4343]
14  /datasets/pentschev/miniconda3/envs/gdf/bin/python(PyObject_Call+0x24a) [0x56272f8df1fa]
15  /datasets/pentschev/miniconda3/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x680b) [0x56272f8c5b8b]
16  /datasets/pentschev/miniconda3/envs/gdf/bin/python(_PyEval_EvalCodeWithName+0x2f1) [0x56272f8be2f1]
17  /datasets/pentschev/miniconda3/envs/gdf/bin/python(_PyFunction_Vectorcall+0x19c) [0x56272f8cf93c]
18  /datasets/pentschev/miniconda3/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x6d5) [0x56272f8bfa55]
19  /datasets/pentschev/miniconda3/envs/gdf/bin/python(+0x13e1e8) [0x56272f8e41e8]
20  /datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/lib-dynload/_asyncio.cpython-38-x86_64-linux-gnu.so(+0x7003) [0x7f294359b003]
21  /datasets/pentschev/miniconda3/envs/gdf/bin/python(_PyObject_MakeTpCall+0x3db) [0x56272f8c830b]
22  /datasets/pentschev/miniconda3/envs/gdf/bin/python(+0xe0b07) [0x56272f886b07]
23  /datasets/pentschev/miniconda3/envs/gdf/bin/python(+0x120f96) [0x56272f8c6f96]
24  /datasets/pentschev/miniconda3/envs/gdf/bin/python(PyVectorcall_Call+0x7a) [0x56272f8dd1ea]
25  /datasets/pentschev/miniconda3/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x5df8) [0x56272f8c5178]
26  /datasets/pentschev/miniconda3/envs/gdf/bin/python(_PyFunction_Vectorcall+0x106) [0x56272f8cf8a6]
27  /datasets/pentschev/miniconda3/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x6d5) [0x56272f8bfa55]
28  /datasets/pentschev/miniconda3/envs/gdf/bin/python(_PyFunction_Vectorcall+0x106) [0x56272f8cf8a6]
29  /datasets/pentschev/miniconda3/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x6d5) [0x56272f8bfa55]
30  /datasets/pentschev/miniconda3/envs/gdf/bin/python(_PyFunction_Vectorcall+0x106) [0x56272f8cf8a6]
31  /datasets/pentschev/miniconda3/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x6d5) [0x56272f8bfa55]
32  /datasets/pentschev/miniconda3/envs/gdf/bin/python(_PyFunction_Vectorcall+0x106) [0x56272f8cf8a6]
33  /datasets/pentschev/miniconda3/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x6d5) [0x56272f8bfa55]
34  /datasets/pentschev/miniconda3/envs/gdf/bin/python(_PyEval_EvalCodeWithName+0x2f1) [0x56272f8be2f1]
35  /datasets/pentschev/miniconda3/envs/gdf/bin/python(_PyFunction_Vectorcall+0x19c) [0x56272f8cf93c]
36  /datasets/pentschev/miniconda3/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x4b7b) [0x56272f8c3efb]
37  /datasets/pentschev/miniconda3/envs/gdf/bin/python(_PyEval_EvalCodeWithName+0x2f1) [0x56272f8be2f1]
38  /datasets/pentschev/miniconda3/envs/gdf/bin/python(_PyFunction_Vectorcall+0x19c) [0x56272f8cf93c]
39  /datasets/pentschev/miniconda3/envs/gdf/bin/python(+0x136e8c) [0x56272f8dce8c]
40  /datasets/pentschev/miniconda3/envs/gdf/bin/python(_PyObject_FastCallDict+0x282) [0x56272f8c7a92]
41  /datasets/pentschev/miniconda3/envs/gdf/bin/python(+0x1ee049) [0x56272f994049]
42  /datasets/pentschev/miniconda3/envs/gdf/bin/python(PyObject_Call+0x2d3) [0x56272f8df283]
43  /datasets/pentschev/miniconda3/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x205e) [0x56272f8c13de]
44  /datasets/pentschev/miniconda3/envs/gdf/bin/python(_PyFunction_Vectorcall+0x106) [0x56272f8cf8a6]
45  /datasets/pentschev/miniconda3/envs/gdf/bin/python(+0x136e8c) [0x56272f8dce8c]
46  /datasets/pentschev/miniconda3/envs/gdf/bin/python(PyObject_Call+0x24a) [0x56272f8df1fa]
47  /datasets/pentschev/miniconda3/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x205e) [0x56272f8c13de]
48  /datasets/pentschev/miniconda3/envs/gdf/bin/python(_PyFunction_Vectorcall+0x106) [0x56272f8cf8a6]
49  /datasets/pentschev/miniconda3/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x6d5) [0x56272f8bfa55]
50  /datasets/pentschev/miniconda3/envs/gdf/bin/python(_PyEval_EvalCodeWithName+0x2f1) [0x56272f8be2f1]
51  /datasets/pentschev/miniconda3/envs/gdf/bin/python(_PyFunction_Vectorcall+0x19c) [0x56272f8cf93c]
52  /datasets/pentschev/miniconda3/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x6d5) [0x56272f8bfa55]
53  /datasets/pentschev/miniconda3/envs/gdf/bin/python(_PyFunction_Vectorcall+0x106) [0x56272f8cf8a6]
54  /datasets/pentschev/miniconda3/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x3a9) [0x56272f8bf729]
55  /datasets/pentschev/miniconda3/envs/gdf/bin/python(_PyEval_EvalCodeWithName+0x2f1) [0x56272f8be2f1]
56  /datasets/pentschev/miniconda3/envs/gdf/bin/python(_PyFunction_Vectorcall+0x19c) [0x56272f8cf93c]
57  /datasets/pentschev/miniconda3/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x11bf) [0x56272f8c053f]
58  /datasets/pentschev/miniconda3/envs/gdf/bin/python(_PyEval_EvalCodeWithName+0x2f1) [0x56272f8be2f1]
59  /datasets/pentschev/miniconda3/envs/gdf/bin/python(PyEval_EvalCodeEx+0x39) [0x56272f970e99]
60  /datasets/pentschev/miniconda3/envs/gdf/bin/python(PyEval_EvalCode+0x1b) [0x56272f970e5b]
61  /datasets/pentschev/miniconda3/envs/gdf/bin/python(+0x1eb7f9) [0x56272f9917f9]
=================================
[dgx13:72239:0:72239] Caught signal 11 (Segmentation fault: address not mapped to object at address 0x448)
==== backtrace (tid:  72239) ====
 0  /datasets/pentschev/miniconda3/envs/gdf/lib/libucs.so.0(ucs_handle_error+0x2d4) [0x7f21202cd6b4]
 1  /datasets/pentschev/miniconda3/envs/gdf/lib/libucs.so.0(+0x2d88f) [0x7f21202cd88f]
 2  /datasets/pentschev/miniconda3/envs/gdf/lib/libucs.so.0(+0x2dbb4) [0x7f21202cdbb4]
 3  /lib/x86_64-linux-gnu/libpthread.so.0(+0x12980) [0x7f21b312c980]
 4  /datasets/pentschev/miniconda3/envs/gdf/lib/libucp.so.0(ucp_mem_type_unpack+0x17) [0x7f21205491b7]
 5  /datasets/pentschev/miniconda3/envs/gdf/lib/libucp.so.0(ucp_rndv_data_handler+0x508) [0x7f2120572638]
 6  /datasets/pentschev/miniconda3/envs/gdf/lib/libuct.so.0(+0x1f0ff) [0x7f21200850ff]
 7  /datasets/pentschev/miniconda3/envs/gdf/lib/libuct.so.0(+0x1f674) [0x7f2120085674]
 8  /datasets/pentschev/miniconda3/envs/gdf/lib/libuct.so.0(+0x21a78) [0x7f2120087a78]
 9  /datasets/pentschev/miniconda3/envs/gdf/lib/libucs.so.0(ucs_event_set_wait+0xb9) [0x7f21202d78a9]
10  /datasets/pentschev/miniconda3/envs/gdf/lib/libuct.so.0(uct_tcp_iface_progress+0x7b) [0x7f2120087b1b]
11  /datasets/pentschev/miniconda3/envs/gdf/lib/libucp.so.0(ucp_worker_progress+0x6a) [0x7f2120545f5a]
12  /datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/ucp/_libs/ucx_api.cpython-38-x86_64-linux-gnu.so(+0x272d9) [0x7f21207f22d9]
13  /datasets/pentschev/miniconda3/envs/gdf/bin/python(+0x12e343) [0x55b377123343]
14  /datasets/pentschev/miniconda3/envs/gdf/bin/python(PyObject_Call+0x24a) [0x55b37712e1fa]
15  /datasets/pentschev/miniconda3/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x680b) [0x55b377114b8b]
16  /datasets/pentschev/miniconda3/envs/gdf/bin/python(_PyEval_EvalCodeWithName+0x2f1) [0x55b37710d2f1]
17  /datasets/pentschev/miniconda3/envs/gdf/bin/python(_PyFunction_Vectorcall+0x19c) [0x55b37711e93c]
18  /datasets/pentschev/miniconda3/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x6d5) [0x55b37710ea55]
19  /datasets/pentschev/miniconda3/envs/gdf/bin/python(_PyFunction_Vectorcall+0x106) [0x55b37711e8a6]
20  /datasets/pentschev/miniconda3/envs/gdf/bin/python(+0x136c36) [0x55b37712bc36]
21  /datasets/pentschev/miniconda3/envs/gdf/bin/python(+0x23565a) [0x55b37722a65a]
22  /datasets/pentschev/miniconda3/envs/gdf/bin/python(+0xe0b07) [0x55b3770d5b07]
23  /datasets/pentschev/miniconda3/envs/gdf/bin/python(+0x120f96) [0x55b377115f96]
24  /datasets/pentschev/miniconda3/envs/gdf/bin/python(PyVectorcall_Call+0x7a) [0x55b37712c1ea]
25  /datasets/pentschev/miniconda3/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x5df8) [0x55b377114178]
26  /datasets/pentschev/miniconda3/envs/gdf/bin/python(_PyFunction_Vectorcall+0x106) [0x55b37711e8a6]
27  /datasets/pentschev/miniconda3/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x6d5) [0x55b37710ea55]
28  /datasets/pentschev/miniconda3/envs/gdf/bin/python(_PyFunction_Vectorcall+0x106) [0x55b37711e8a6]
29  /datasets/pentschev/miniconda3/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x6d5) [0x55b37710ea55]
30  /datasets/pentschev/miniconda3/envs/gdf/bin/python(_PyFunction_Vectorcall+0x106) [0x55b37711e8a6]
31  /datasets/pentschev/miniconda3/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x6d5) [0x55b37710ea55]
32  /datasets/pentschev/miniconda3/envs/gdf/bin/python(_PyFunction_Vectorcall+0x106) [0x55b37711e8a6]
33  /datasets/pentschev/miniconda3/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x6d5) [0x55b37710ea55]
34  /datasets/pentschev/miniconda3/envs/gdf/bin/python(_PyEval_EvalCodeWithName+0x2f1) [0x55b37710d2f1]
35  /datasets/pentschev/miniconda3/envs/gdf/bin/python(_PyFunction_Vectorcall+0x19c) [0x55b37711e93c]
36  /datasets/pentschev/miniconda3/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x4b7b) [0x55b377112efb]
37  /datasets/pentschev/miniconda3/envs/gdf/bin/python(_PyEval_EvalCodeWithName+0x2f1) [0x55b37710d2f1]
38  /datasets/pentschev/miniconda3/envs/gdf/bin/python(_PyFunction_Vectorcall+0x19c) [0x55b37711e93c]
39  /datasets/pentschev/miniconda3/envs/gdf/bin/python(+0x136e8c) [0x55b37712be8c]
40  /datasets/pentschev/miniconda3/envs/gdf/bin/python(_PyObject_FastCallDict+0x282) [0x55b377116a92]
41  /datasets/pentschev/miniconda3/envs/gdf/bin/python(+0x1ee049) [0x55b3771e3049]
42  /datasets/pentschev/miniconda3/envs/gdf/bin/python(PyObject_Call+0x2d3) [0x55b37712e283]
43  /datasets/pentschev/miniconda3/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x205e) [0x55b3771103de]
44  /datasets/pentschev/miniconda3/envs/gdf/bin/python(_PyFunction_Vectorcall+0x106) [0x55b37711e8a6]
45  /datasets/pentschev/miniconda3/envs/gdf/bin/python(+0x136e8c) [0x55b37712be8c]
46  /datasets/pentschev/miniconda3/envs/gdf/bin/python(PyObject_Call+0x24a) [0x55b37712e1fa]
47  /datasets/pentschev/miniconda3/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x205e) [0x55b3771103de]
48  /datasets/pentschev/miniconda3/envs/gdf/bin/python(_PyFunction_Vectorcall+0x106) [0x55b37711e8a6]
49  /datasets/pentschev/miniconda3/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x6d5) [0x55b37710ea55]
50  /datasets/pentschev/miniconda3/envs/gdf/bin/python(_PyEval_EvalCodeWithName+0x2f1) [0x55b37710d2f1]
51  /datasets/pentschev/miniconda3/envs/gdf/bin/python(_PyFunction_Vectorcall+0x19c) [0x55b37711e93c]
52  /datasets/pentschev/miniconda3/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x6d5) [0x55b37710ea55]
53  /datasets/pentschev/miniconda3/envs/gdf/bin/python(_PyFunction_Vectorcall+0x106) [0x55b37711e8a6]
54  /datasets/pentschev/miniconda3/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x3a9) [0x55b37710e729]
55  /datasets/pentschev/miniconda3/envs/gdf/bin/python(_PyEval_EvalCodeWithName+0x2f1) [0x55b37710d2f1]
56  /datasets/pentschev/miniconda3/envs/gdf/bin/python(_PyFunction_Vectorcall+0x19c) [0x55b37711e93c]
57  /datasets/pentschev/miniconda3/envs/gdf/bin/python(_PyEval_EvalFrameDefault+0x11bf) [0x55b37710f53f]
58  /datasets/pentschev/miniconda3/envs/gdf/bin/python(_PyEval_EvalCodeWithName+0x2f1) [0x55b37710d2f1]
59  /datasets/pentschev/miniconda3/envs/gdf/bin/python(PyEval_EvalCodeEx+0x39) [0x55b3771bfe99]
60  /datasets/pentschev/miniconda3/envs/gdf/bin/python(PyEval_EvalCode+0x1b) [0x55b3771bfe5b]
61  /datasets/pentschev/miniconda3/envs/gdf/bin/python(+0x1eb7f9) [0x55b3771e07f9]
=================================
2023-04-18 22:45:16,637 - distributed.worker - ERROR - failed during get data with ucx://127.0.0.1:35043 -> ucx://127.0.0.1:47423
Traceback (most recent call last):
  File "/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/comm/ucx.py", line 318, in write
    await self.ep.send(
  File "/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/ucp/core.py", line 650, in send
    return await comm.tag_send(self._ep, buffer, nbytes, tag, name=log)
  File "/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/ucp/comm.py", line 55, in tag_send
    return _call_ucx_api(
  File "/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/ucp/comm.py", line 31, in _call_ucx_api
    req = func(*args, **kwargs)
  File "ucp/_libs/transfer_tag.pyx", line 90, in ucp._libs.ucx_api.tag_send_nb
  File "ucp/_libs/ucx_request.pyx", line 111, in ucp._libs.ucx_api._handle_status
ucp._libs.exceptions.UCXError: <[Send #004] ep: 0x7fe7002fe340, tag: 0xbe538cad9d31900b, nbytes: 56, type: <class 'bytes'>>: Endpoint timeout

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/worker.py", line 1792, in get_data
    compressed = await comm.write(msg, serializers=serializers)
  File "/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/comm/ucx.py", line 337, in write
    raise CommClosedError("While writing, the connection was closed")
distributed.comm.core.CommClosedError: While writing, the connection was closed
2023-04-18 22:45:16,643 - distributed.worker - ERROR - failed during get data with ucx://127.0.0.1:52483 -> ucx://127.0.0.1:58499
Traceback (most recent call last):
  File "/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/comm/ucx.py", line 333, in write
    await self.ep.send(each_frame)
  File "/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/ucp/core.py", line 650, in send
    return await comm.tag_send(self._ep, buffer, nbytes, tag, name=log)
ucp._libs.exceptions.UCXError: <[Send #007] ep: 0x7f5df0876300, tag: 0x312585fdb24d704, nbytes: 100000000, type: <class 'cudf.core.buffer.buffer.Buffer'>>: Endpoint timeout

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/worker.py", line 1792, in get_data
    compressed = await comm.write(msg, serializers=serializers)
  File "/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/comm/ucx.py", line 337, in write
    raise CommClosedError("While writing, the connection was closed")
distributed.comm.core.CommClosedError: While writing, the connection was closed
2023-04-18 22:45:16,643 - distributed.worker - ERROR - Worker stream died during communication: ucx://127.0.0.1:58499
Traceback (most recent call last):
  File "/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/comm/ucx.py", line 391, in read
    await self.ep.recv(each_frame)
  File "/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/ucp/core.py", line 725, in recv
    ret = await comm.tag_recv(self._ep, buffer, nbytes, tag, name=log)
ucp._libs.exceptions.UCXError: <[Recv #007] ep: 0x7f5df08761c0, tag: 0x3c0b1139af9a08d8, nbytes: 100000000, type: <class 'rmm._lib.device_buffer.DeviceBuffer'>>: Endpoint timeout

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/worker.py", line 2066, in gather_dep
    response = await get_data_from_worker(
  File "/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/worker.py", line 2892, in get_data_from_worker
    response = await send_recv(
  File "/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/core.py", line 1024, in send_recv
    response = await comm.read(deserializers=deserializers)
  File "/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/comm/ucx.py", line 397, in read
    raise CommClosedError(
distributed.comm.core.CommClosedError: Connection closed by writer.
Inner exception: UCXError("<[Recv #007] ep: 0x7f5df08761c0, tag: 0x3c0b1139af9a08d8, nbytes: 100000000, type: <class 'rmm._lib.device_buffer.DeviceBuffer'>>: Endpoint timeout")
2023-04-18 22:45:16,645 - distributed.worker - ERROR - Worker stream died during communication: ucx://127.0.0.1:47423
Traceback (most recent call last):
  File "/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/comm/ucx.py", line 391, in read
    await self.ep.recv(each_frame)
  File "/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/ucp/core.py", line 725, in recv
    ret = await comm.tag_recv(self._ep, buffer, nbytes, tag, name=log)
ucp._libs.exceptions.UCXError: <[Recv #007] ep: 0x7fe7002fe180, tag: 0x1c7a725a4215f06, nbytes: 100000000, type: <class 'rmm._lib.device_buffer.DeviceBuffer'>>: Endpoint timeout

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/worker.py", line 2066, in gather_dep
    response = await get_data_from_worker(
  File "/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/worker.py", line 2892, in get_data_from_worker
    response = await send_recv(
  File "/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/core.py", line 1024, in send_recv
    response = await comm.read(deserializers=deserializers)
  File "/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/comm/ucx.py", line 397, in read
    raise CommClosedError(
distributed.comm.core.CommClosedError: Connection closed by writer.
Inner exception: UCXError("<[Recv #007] ep: 0x7fe7002fe180, tag: 0x1c7a725a4215f06, nbytes: 100000000, type: <class 'rmm._lib.device_buffer.DeviceBuffer'>>: Endpoint timeout")
2023-04-18 22:45:16,646 - distributed.worker - ERROR - failed during get data with ucx://127.0.0.1:35043 -> ucx://127.0.0.1:58499
Traceback (most recent call last):
  File "/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/comm/ucx.py", line 349, in read
    await self.ep.recv(msg)
  File "/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/ucp/core.py", line 725, in recv
    ret = await comm.tag_recv(self._ep, buffer, nbytes, tag, name=log)
ucp._libs.exceptions.UCXCanceled: <[Recv #006] ep: 0x7fe7002fe380, tag: 0xe96c793440ab64bb, nbytes: 16, type: <class 'numpy.ndarray'>>: 

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/worker.py", line 1793, in get_data
    response = await comm.read(deserializers=serializers)
  File "/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/comm/ucx.py", line 367, in read
    raise CommClosedError(
distributed.comm.core.CommClosedError: Connection closed by writer.
Inner exception: UCXCanceled("<[Recv #006] ep: 0x7fe7002fe380, tag: 0xe96c793440ab64bb, nbytes: 16, type: <class 'numpy.ndarray'>>: ")
2023-04-18 22:45:16,647 - distributed.worker - ERROR - Worker stream died during communication: ucx://127.0.0.1:58499
Traceback (most recent call last):
  File "/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/worker.py", line 2066, in gather_dep
    response = await get_data_from_worker(
  File "/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/worker.py", line 2907, in get_data_from_worker
    await comm.write("OK")
  File "/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/comm/ucx.py", line 289, in write
    raise CommClosedError("Endpoint is closed -- unable to send message")
distributed.comm.core.CommClosedError: Endpoint is closed -- unable to send message
2023-04-18 22:45:16,663 - distributed.worker - ERROR - Worker stream died during communication: ucx://127.0.0.1:54897
Traceback (most recent call last):
  File "/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/comm/ucx.py", line 349, in read
    await self.ep.recv(msg)
  File "/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/ucp/core.py", line 725, in recv
    ret = await comm.tag_recv(self._ep, buffer, nbytes, tag, name=log)
ucp._libs.exceptions.UCXCanceled: <[Recv #003] ep: 0x7fe7002fe1c0, tag: 0x412bfb18bffe5dbf, nbytes: 16, type: <class 'numpy.ndarray'>>: 

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/worker.py", line 2066, in gather_dep
    response = await get_data_from_worker(
  File "/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/worker.py", line 2892, in get_data_from_worker
    response = await send_recv(
  File "/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/core.py", line 1024, in send_recv
    response = await comm.read(deserializers=deserializers)
  File "/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/comm/ucx.py", line 367, in read
    raise CommClosedError(
distributed.comm.core.CommClosedError: Connection closed by writer.
Inner exception: UCXCanceled("<[Recv #003] ep: 0x7fe7002fe1c0, tag: 0x412bfb18bffe5dbf, nbytes: 16, type: <class 'numpy.ndarray'>>: ")
2023-04-18 22:45:16,681 - distributed.worker - ERROR - failed during get data with ucx://127.0.0.1:49777 -> ucx://127.0.0.1:54897
Traceback (most recent call last):
  File "/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/comm/ucx.py", line 333, in write
    await self.ep.send(each_frame)
  File "/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/ucp/core.py", line 650, in send
    return await comm.tag_send(self._ep, buffer, nbytes, tag, name=log)
ucp._libs.exceptions.UCXError: <[Send #007] ep: 0x7f8740de93c0, tag: 0xd8dee689a77ba571, nbytes: 100000000, type: <class 'cudf.core.buffer.buffer.Buffer'>>: Endpoint timeout

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/worker.py", line 1792, in get_data
    compressed = await comm.write(msg, serializers=serializers)
  File "/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/comm/ucx.py", line 337, in write
    raise CommClosedError("While writing, the connection was closed")
distributed.comm.core.CommClosedError: While writing, the connection was closed
2023-04-18 22:45:16,687 - distributed.nanny - WARNING - Restarting worker
2023-04-18 22:45:16,697 - distributed.worker - ERROR - Worker stream died during communication: ucx://127.0.0.1:58499
Traceback (most recent call last):
  File "/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/comm/ucx.py", line 349, in read
    await self.ep.recv(msg)
  File "/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/ucp/core.py", line 725, in recv
    ret = await comm.tag_recv(self._ep, buffer, nbytes, tag, name=log)
ucp._libs.exceptions.UCXCanceled: <[Recv #003] ep: 0x7f8740de9240, tag: 0x130ff64de8b007b2, nbytes: 16, type: <class 'numpy.ndarray'>>: 

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/worker.py", line 2066, in gather_dep
    response = await get_data_from_worker(
  File "/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/worker.py", line 2892, in get_data_from_worker
    response = await send_recv(
  File "/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/core.py", line 1024, in send_recv
    response = await comm.read(deserializers=deserializers)
  File "/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/comm/ucx.py", line 367, in read
    raise CommClosedError(
distributed.comm.core.CommClosedError: Connection closed by writer.
Inner exception: UCXCanceled("<[Recv #003] ep: 0x7f8740de9240, tag: 0x130ff64de8b007b2, nbytes: 16, type: <class 'numpy.ndarray'>>: ")
2023-04-18 22:45:16,698 - distributed.worker - ERROR - Worker stream died during communication: ucx://127.0.0.1:54897
Traceback (most recent call last):
  File "/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/comm/ucx.py", line 349, in read
    await self.ep.recv(msg)
  File "/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/ucp/core.py", line 725, in recv
    ret = await comm.tag_recv(self._ep, buffer, nbytes, tag, name=log)
ucp._libs.exceptions.UCXCanceled: <[Recv #003] ep: 0x7f8740de9200, tag: 0x6027401bb68fc235, nbytes: 16, type: <class 'numpy.ndarray'>>: 

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/worker.py", line 2066, in gather_dep
    response = await get_data_from_worker(
  File "/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/worker.py", line 2892, in get_data_from_worker
    response = await send_recv(
  File "/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/core.py", line 1024, in send_recv
    response = await comm.read(deserializers=deserializers)
  File "/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/comm/ucx.py", line 367, in read
    raise CommClosedError(
distributed.comm.core.CommClosedError: Connection closed by writer.
Inner exception: UCXCanceled("<[Recv #003] ep: 0x7f8740de9200, tag: 0x6027401bb68fc235, nbytes: 16, type: <class 'numpy.ndarray'>>: ")
2023-04-18 22:45:16,749 - distributed.nanny - WARNING - Restarting worker
2023-04-18 22:45:16,760 - distributed.worker - ERROR - failed during get data with ucx://127.0.0.1:47881 -> ucx://127.0.0.1:58499
Traceback (most recent call last):
  File "/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/comm/ucx.py", line 333, in write
    await self.ep.send(each_frame)
  File "/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/ucp/core.py", line 650, in send
    return await comm.tag_send(self._ep, buffer, nbytes, tag, name=log)
ucp._libs.exceptions.UCXError: <[Send #007] ep: 0x7ff3540b8380, tag: 0x83837978b3ee246f, nbytes: 100000000, type: <class 'cudf.core.buffer.buffer.Buffer'>>: Endpoint timeout

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/worker.py", line 1792, in get_data
    compressed = await comm.write(msg, serializers=serializers)
  File "/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/comm/ucx.py", line 337, in write
    raise CommClosedError("While writing, the connection was closed")
distributed.comm.core.CommClosedError: While writing, the connection was closed
2023-04-18 22:45:16,761 - distributed.worker - ERROR - Worker stream died during communication: ucx://127.0.0.1:58499
Traceback (most recent call last):
  File "/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/comm/ucx.py", line 391, in read
    await self.ep.recv(each_frame)
  File "/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/ucp/core.py", line 725, in recv
    ret = await comm.tag_recv(self._ep, buffer, nbytes, tag, name=log)
ucp._libs.exceptions.UCXError: <[Recv #007] ep: 0x7ff3540b8240, tag: 0x636f63ea3a78c643, nbytes: 100000000, type: <class 'rmm._lib.device_buffer.DeviceBuffer'>>: Endpoint timeout

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/worker.py", line 2066, in gather_dep
    response = await get_data_from_worker(
  File "/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/worker.py", line 2892, in get_data_from_worker
    response = await send_recv(
  File "/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/core.py", line 1024, in send_recv
    response = await comm.read(deserializers=deserializers)
  File "/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/comm/ucx.py", line 397, in read
    raise CommClosedError(
distributed.comm.core.CommClosedError: Connection closed by writer.
Inner exception: UCXError("<[Recv #007] ep: 0x7ff3540b8240, tag: 0x636f63ea3a78c643, nbytes: 100000000, type: <class 'rmm._lib.device_buffer.DeviceBuffer'>>: Endpoint timeout")
2023-04-18 22:45:16,762 - distributed.worker - ERROR - failed during get data with ucx://127.0.0.1:52483 -> ucx://127.0.0.1:54897
Traceback (most recent call last):
  File "/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/comm/ucx.py", line 333, in write
    await self.ep.send(each_frame)
  File "/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/ucp/core.py", line 650, in send
    return await comm.tag_send(self._ep, buffer, nbytes, tag, name=log)
ucp._libs.exceptions.UCXError: <[Send #007] ep: 0x7f5df08763c0, tag: 0x57991d5f47e94c2a, nbytes: 100000000, type: <class 'cudf.core.buffer.buffer.Buffer'>>: Endpoint timeout

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/worker.py", line 1792, in get_data
    compressed = await comm.write(msg, serializers=serializers)
  File "/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/comm/ucx.py", line 337, in write
    raise CommClosedError("While writing, the connection was closed")
distributed.comm.core.CommClosedError: While writing, the connection was closed
2023-04-18 22:45:16,762 - distributed.worker - ERROR - Worker stream died during communication: ucx://127.0.0.1:54897
Traceback (most recent call last):
  File "/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/comm/ucx.py", line 391, in read
    await self.ep.recv(each_frame)
  File "/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/ucp/core.py", line 725, in recv
    ret = await comm.tag_recv(self._ep, buffer, nbytes, tag, name=log)
ucp._libs.exceptions.UCXCanceled: <[Recv #010] ep: 0x7ff3540b8200, tag: 0x31e61fbe83338fa4, nbytes: 50000000, type: <class 'rmm._lib.device_buffer.DeviceBuffer'>>: 

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/worker.py", line 2066, in gather_dep
    response = await get_data_from_worker(
  File "/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/worker.py", line 2892, in get_data_from_worker
    response = await send_recv(
  File "/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/core.py", line 1024, in send_recv
    response = await comm.read(deserializers=deserializers)
  File "/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/comm/ucx.py", line 397, in read
    raise CommClosedError(
distributed.comm.core.CommClosedError: Connection closed by writer.
Inner exception: UCXCanceled("<[Recv #010] ep: 0x7ff3540b8200, tag: 0x31e61fbe83338fa4, nbytes: 50000000, type: <class 'rmm._lib.device_buffer.DeviceBuffer'>>: ")
2023-04-18 22:45:16,764 - distributed.worker - ERROR - Worker stream died during communication: ucx://127.0.0.1:54897
Traceback (most recent call last):
  File "/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/comm/ucx.py", line 391, in read
    await self.ep.recv(each_frame)
  File "/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/ucp/core.py", line 725, in recv
    ret = await comm.tag_recv(self._ep, buffer, nbytes, tag, name=log)
ucp._libs.exceptions.UCXError: <[Recv #007] ep: 0x7f5df0876240, tag: 0x941b74f3fb3a22ce, nbytes: 100000000, type: <class 'rmm._lib.device_buffer.DeviceBuffer'>>: Endpoint timeout

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/worker.py", line 2066, in gather_dep
    response = await get_data_from_worker(
  File "/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/worker.py", line 2892, in get_data_from_worker
    response = await send_recv(
  File "/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/core.py", line 1024, in send_recv
    response = await comm.read(deserializers=deserializers)
  File "/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/utils.py", line 752, in wrapper
    return await func(*args, **kwargs)
  File "/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/comm/ucx.py", line 397, in read
    raise CommClosedError(
distributed.comm.core.CommClosedError: Connection closed by writer.
Inner exception: UCXError("<[Recv #007] ep: 0x7f5df0876240, tag: 0x941b74f3fb3a22ce, nbytes: 100000000, type: <class 'rmm._lib.device_buffer.DeviceBuffer'>>: Endpoint timeout")
2023-04-18 22:45:16,798 - distributed.nanny - WARNING - Restarting worker
2023-04-18 22:45:18,255 - distributed.diskutils - ERROR - Failed to clean up lingering worker directories in path: %s 
Traceback (most recent call last):
  File "/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/diskutils.py", line 268, in new_work_dir
    self._purge_leftovers()
  File "/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/diskutils.py", line 199, in _purge_leftovers
    if self._check_lock_or_purge(path):
  File "/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/diskutils.py", line 234, in _check_lock_or_purge
    lock.acquire()
  File "/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/locket/__init__.py", line 198, in acquire
    self._lock.acquire(self._timeout, self._retry_period)
  File "/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/locket/__init__.py", line 118, in acquire
    lock.acquire(timeout, retry_period)
  File "/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/locket/__init__.py", line 158, in acquire
    fileobj = open(self._path, "wb")
PermissionError: [Errno 13] Permission denied: '/tmp/dask-worker-space/worker-usav5jtm.dirlock'
2023-04-18 22:45:18,257 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-04-18 22:45:18,257 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-04-18 22:45:18,497 - distributed.diskutils - ERROR - Failed to clean up lingering worker directories in path: %s 
Traceback (most recent call last):
  File "/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/diskutils.py", line 268, in new_work_dir
    self._purge_leftovers()
  File "/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/diskutils.py", line 199, in _purge_leftovers
    if self._check_lock_or_purge(path):
  File "/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/diskutils.py", line 234, in _check_lock_or_purge
    lock.acquire()
  File "/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/locket/__init__.py", line 198, in acquire
    self._lock.acquire(self._timeout, self._retry_period)
  File "/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/locket/__init__.py", line 118, in acquire
    lock.acquire(timeout, retry_period)
  File "/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/locket/__init__.py", line 158, in acquire
    fileobj = open(self._path, "wb")
PermissionError: [Errno 13] Permission denied: '/tmp/dask-worker-space/worker-usav5jtm.dirlock'
2023-04-18 22:45:18,498 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-04-18 22:45:18,498 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-04-18 22:45:18,501 - distributed.diskutils - ERROR - Failed to clean up lingering worker directories in path: %s 
Traceback (most recent call last):
  File "/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/diskutils.py", line 268, in new_work_dir
    self._purge_leftovers()
  File "/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/diskutils.py", line 199, in _purge_leftovers
    if self._check_lock_or_purge(path):
  File "/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/diskutils.py", line 234, in _check_lock_or_purge
    lock.acquire()
  File "/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/locket/__init__.py", line 198, in acquire
    self._lock.acquire(self._timeout, self._retry_period)
  File "/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/locket/__init__.py", line 118, in acquire
    lock.acquire(timeout, retry_period)
  File "/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/locket/__init__.py", line 158, in acquire
    fileobj = open(self._path, "wb")
PermissionError: [Errno 13] Permission denied: '/tmp/dask-worker-space/worker-usav5jtm.dirlock'
2023-04-18 22:45:18,502 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-04-18 22:45:18,502 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2023-04-18 22:45:18,587 - distributed.diskutils - ERROR - Failed to clean up lingering worker directories in path: %s 
Traceback (most recent call last):
  File "/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/diskutils.py", line 268, in new_work_dir
    self._purge_leftovers()
  File "/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/diskutils.py", line 199, in _purge_leftovers
    if self._check_lock_or_purge(path):
  File "/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/distributed/diskutils.py", line 234, in _check_lock_or_purge
    lock.acquire()
  File "/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/locket/__init__.py", line 198, in acquire
    self._lock.acquire(self._timeout, self._retry_period)
  File "/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/locket/__init__.py", line 118, in acquire
    lock.acquire(timeout, retry_period)
  File "/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/site-packages/locket/__init__.py", line 158, in acquire
    fileobj = open(self._path, "wb")
PermissionError: [Errno 13] Permission denied: '/tmp/dask-worker-space/worker-usav5jtm.dirlock'
2023-04-18 22:45:18,588 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2023-04-18 22:45:18,588 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
/datasets/pentschev/miniconda3/envs/gdf/lib/python3.8/multiprocessing/resource_tracker.py:216: UserWarning: resource_tracker: There appear to be 48 leaked semaphore objects to clean up at shutdown
  warnings.warn('resource_tracker: There appear to be %d '
